{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6343fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import talos as ta\n",
    "from talos.model.early_stopper import early_stopper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext tensorboard\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11bc838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"C:/Users/Marze/OneDrive/Dokumenty/Jarek/Magisterka/Dane_do_uczenia_M.csv\", encoding=\"utf-8\")\n",
    "del train_df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46afdada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000212232.1</th>\n",
       "      <th>ENSG00000238741.1</th>\n",
       "      <th>ENSG00000252481.1</th>\n",
       "      <th>ENSG00000239002.3</th>\n",
       "      <th>ENSG00000212443.1</th>\n",
       "      <th>ENSG00000274012.1</th>\n",
       "      <th>ENSG00000252010.1</th>\n",
       "      <th>ENSG00000202198.1</th>\n",
       "      <th>ENSG00000251791.1</th>\n",
       "      <th>ENSG00000202058.1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000241475.1</th>\n",
       "      <th>ENSG00000274618.1</th>\n",
       "      <th>ENSG00000227293.1</th>\n",
       "      <th>ENSG00000253526.1</th>\n",
       "      <th>ENSG00000270654.1</th>\n",
       "      <th>ENSG00000271394.1</th>\n",
       "      <th>ENSG00000265423.1</th>\n",
       "      <th>ENSG00000253165.1</th>\n",
       "      <th>ENSG00000201901.1</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.356617</td>\n",
       "      <td>31.768974</td>\n",
       "      <td>27.356617</td>\n",
       "      <td>5.294829</td>\n",
       "      <td>8.824715</td>\n",
       "      <td>6.645010e+02</td>\n",
       "      <td>2.647415</td>\n",
       "      <td>4.235863e+02</td>\n",
       "      <td>7.059772</td>\n",
       "      <td>16.766959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>M0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.695633</td>\n",
       "      <td>1.086954</td>\n",
       "      <td>6.521724</td>\n",
       "      <td>2.173908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.758692e+03</td>\n",
       "      <td>1.086954</td>\n",
       "      <td>5.434770e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>M0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.185177</td>\n",
       "      <td>77.002713</td>\n",
       "      <td>7.475992</td>\n",
       "      <td>4.485595</td>\n",
       "      <td>8.971190</td>\n",
       "      <td>2.775836e+03</td>\n",
       "      <td>2.242797</td>\n",
       "      <td>2.609121e+02</td>\n",
       "      <td>6.728392</td>\n",
       "      <td>10.466388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.747599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.747599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>M0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.157930</td>\n",
       "      <td>17.431612</td>\n",
       "      <td>6.536855</td>\n",
       "      <td>2.178952</td>\n",
       "      <td>2.905269</td>\n",
       "      <td>2.338741e+02</td>\n",
       "      <td>3.631586</td>\n",
       "      <td>6.827382e+01</td>\n",
       "      <td>1.452634</td>\n",
       "      <td>1.452634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>M0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29912.168049</td>\n",
       "      <td>21631.677176</td>\n",
       "      <td>9554.333460</td>\n",
       "      <td>20332.131551</td>\n",
       "      <td>5136.495208</td>\n",
       "      <td>1.255850e+06</td>\n",
       "      <td>19221.760289</td>\n",
       "      <td>1.926818e+06</td>\n",
       "      <td>5198.182500</td>\n",
       "      <td>2655.637935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>953.068666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.562431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.367843</td>\n",
       "      <td>64.771657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.374585</td>\n",
       "      <td>M0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENSG00000212232.1  ENSG00000238741.1  ENSG00000252481.1  ENSG00000239002.3  \\\n",
       "0          27.356617          31.768974          27.356617           5.294829   \n",
       "1           8.695633           1.086954           6.521724           2.173908   \n",
       "2          20.185177          77.002713           7.475992           4.485595   \n",
       "3          18.157930          17.431612           6.536855           2.178952   \n",
       "4       29912.168049       21631.677176        9554.333460       20332.131551   \n",
       "\n",
       "   ENSG00000212443.1  ENSG00000274012.1  ENSG00000252010.1  ENSG00000202198.1  \\\n",
       "0           8.824715       6.645010e+02           2.647415       4.235863e+02   \n",
       "1           0.000000       1.758692e+03           1.086954       5.434770e+01   \n",
       "2           8.971190       2.775836e+03           2.242797       2.609121e+02   \n",
       "3           2.905269       2.338741e+02           3.631586       6.827382e+01   \n",
       "4        5136.495208       1.255850e+06       19221.760289       1.926818e+06   \n",
       "\n",
       "   ENSG00000251791.1  ENSG00000202058.1  ...  ENSG00000241475.1  \\\n",
       "0           7.059772          16.766959  ...           0.000000   \n",
       "1           0.000000           0.000000  ...           0.000000   \n",
       "2           6.728392          10.466388  ...           0.000000   \n",
       "3           1.452634           1.452634  ...           0.726317   \n",
       "4        5198.182500        2655.637935  ...           0.000000   \n",
       "\n",
       "   ENSG00000274618.1  ENSG00000227293.1  ENSG00000253526.1  ENSG00000270654.1  \\\n",
       "0           0.000000                0.0           0.000000                0.0   \n",
       "1           0.000000                0.0           0.000000                0.0   \n",
       "2           0.747599                0.0           0.747599                0.0   \n",
       "3           0.000000                0.0           0.000000                0.0   \n",
       "4         953.068666                0.0          20.562431                0.0   \n",
       "\n",
       "   ENSG00000271394.1  ENSG00000265423.1  ENSG00000253165.1  ENSG00000201901.1  \\\n",
       "0           0.000000           0.000000                0.0           0.000000   \n",
       "1           0.000000           0.000000                0.0           0.000000   \n",
       "2           0.747599           0.000000                0.0           0.000000   \n",
       "3           0.000000           0.000000                0.0           0.000000   \n",
       "4         269.367843          64.771657                0.0         123.374585   \n",
       "\n",
       "   scale  \n",
       "0     M0  \n",
       "1     M0  \n",
       "2     M0  \n",
       "3     M0  \n",
       "4     M0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12749254",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['scale'].loc[(train_df['scale'] == 'M0')] = 0\n",
    "train_df['scale'].loc[(train_df['scale'] == 'M1')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c331308",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.loc[(train_df['scale']!='MX')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70af0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=42,stratify=train_df['scale'])\n",
    "#test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42,stratify=test_df['scale'])\n",
    "\n",
    "\n",
    "train_label=train_df['scale']\n",
    "test_label=test_df['scale']\n",
    "#val_label=val_df['scale']\n",
    "del train_df['scale']\n",
    "del test_df['scale']\n",
    "#del val_df['scale']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a11fa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96bf7b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e43830d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d496a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c166a",
   "metadata": {},
   "source": [
    "## 1.2 Standaryzacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eafe28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_df=scaler.fit_transform(train_df)\n",
    "test_df=scaler.fit_transform(test_df)\n",
    "#val_df=scaler.fit_transform(val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24251a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23532639, -0.28536286, -0.29189695, ..., -0.20273415,\n",
       "        -0.13658188, -0.25716709],\n",
       "       [-0.23488914, -0.28412701, -0.28766847, ..., -0.20273415,\n",
       "        -0.13658188, -0.25716709],\n",
       "       [-0.23513615, -0.28194648, -0.28119849, ..., -0.1127296 ,\n",
       "        -0.13658188, -0.18291094],\n",
       "       ...,\n",
       "       [-0.23560858, -0.28411483, -0.29158105, ..., -0.20273415,\n",
       "        -0.07110588, -0.25716709],\n",
       "       [13.92769305,  3.11477926,  6.81130447, ..., -0.05473062,\n",
       "        -0.13658188,  1.2895196 ],\n",
       "       [-0.23495945, -0.28021459, -0.28164044, ..., -0.20273415,\n",
       "        -0.07405669, -0.25716709]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a14023e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568, 110)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "510b4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=np.asarray(train_label).astype(np.int)\n",
    "test_label=np.asarray(test_label).astype(np.int)\n",
    "#val_label=np.asarray(val_label).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26659d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2422e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67033fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=train_label.reshape(-1,1)\n",
    "test_label=test_label.reshape(-1,1)\n",
    "#val_label=val_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6564502b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb32e8a",
   "metadata": {},
   "source": [
    "# 2 Moduł TALOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32e057c",
   "metadata": {},
   "source": [
    "## 2.1 Słownik parametrów do wypróbowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d970ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dobor Gammy i alfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "734e1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron':[55,110,220], \n",
    "     'hidden_neuron':[50,100,150],\n",
    "\n",
    "     'hidden_layers':[1,3,5,7,9],  \n",
    "\n",
    "     \n",
    "    'epochs': [100000], # never touch it\n",
    "\n",
    "\n",
    "    'last_activation': ['sigmoid'], #never touch it\n",
    "\n",
    "\n",
    "    'batch_size': [32],\n",
    "\n",
    "    'lr':[0.001],\n",
    "    \n",
    "    'kernel_regularizer_l1':[0.0001],#[0,0.001,0.0001],\n",
    "    'kernel_regularizer_l2':[0.0001],#[0,0.001,0.0001],\n",
    "    'bias_regularizer':[0.0001],#[0,0.001,0.0001],\n",
    "    'activity_regularizer':[0.0001],#[0,0.001,0.0001],\n",
    "\n",
    "#    'batc_normalization':[False,True],\n",
    "#    'dropout': [0,0.2,0.4],\n",
    "    'dropout': [0],\n",
    "    \n",
    "    'optimizer': ['rmsprop','adam','adadelta','adamax','nadam','adagrad'],\n",
    "    #'kernel_initializer': ['orthogonal','identity','zeros','ones','uniform'],\n",
    "    'kernel_initializer': ['orthogonal'],\n",
    "    #'activation_layer':['sigmoid','tanh','selu','elu','relu'],\n",
    "    'activation_layer':['relu'],\n",
    "    #'batc_normalization':[False,True]\n",
    "    'batc_normalization':[False],\n",
    "\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e94d6",
   "metadata": {},
   "source": [
    "## 2.22 Weights for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a569ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weights for each class so that we can balance the data\n",
    "weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                            classes=np.unique(train_label),\n",
    "                                            y=train_label.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f45fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58921162, 3.30232558])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d5003a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numerai_model(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    print(params)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    ## initial layer\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1],\n",
    "                    activation='relu',\n",
    "               \n",
    "                    kernel_initializer = params['kernel_initializer'],\n",
    "                    kernel_regularizer=keras.regularizers.l1_l2(l1=params['kernel_regularizer_l1'],\n",
    "                                                                l2=params['kernel_regularizer_l2']),\n",
    "                    bias_regularizer=keras.regularizers.l2(params['bias_regularizer']),\n",
    "                    activity_regularizer=keras.regularizers.l2(params['activity_regularizer'])\n",
    "                   ))\n",
    "    if params['batc_normalization']==True:\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "    if params['dropout']!=0:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    ## hidden layers\n",
    "    for i in range(params['hidden_layers']):\n",
    "        print (f\"adding layer {i+1}\")\n",
    "        model.add(Dense(params['hidden_neuron'], activation='relu',\n",
    "                    kernel_initializer=params['kernel_initializer'],\n",
    "                        kernel_regularizer=keras.regularizers.l1_l2(l1=params['kernel_regularizer_l1'],\n",
    "                                                                    l2=params['kernel_regularizer_l2']),\n",
    "                    bias_regularizer=keras.regularizers.l2(params['bias_regularizer']),\n",
    "                    activity_regularizer=keras.regularizers.l2(params['activity_regularizer'])\n",
    "                       ))\n",
    "        if params['batc_normalization']==True:\n",
    "            model.add(BatchNormalization())\n",
    "            \n",
    "        if params['dropout']!=0:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    \n",
    "    ## final layer\n",
    "    model.add(Dense(1, activation=params['last_activation'],\n",
    "                    kernel_initializer=params['kernel_initializer'],\n",
    "                   kernel_regularizer=keras.regularizers.l1_l2(l1=params['kernel_regularizer_l1'],\n",
    "                                                               l2=params['kernel_regularizer_l2']),\n",
    "                    bias_regularizer=keras.regularizers.l2(params['bias_regularizer']),\n",
    "                    activity_regularizer=keras.regularizers.l2(params['activity_regularizer'])\n",
    "                   ))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=params['optimizer'],\n",
    "                  #tf.keras.optimizers.Adamax(learning_rate=params['lr']),\n",
    "                  metrics=[tfa.metrics.FBetaScore(num_classes=1, beta=1.0, threshold=0.5),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),])\n",
    "    \n",
    "  \n",
    "    history = model.fit(x_train, y_train, \n",
    "                        validation_data=[x_val, y_val],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        epochs=params['epochs'],\n",
    "                        verbose=0,\n",
    "                        class_weight={0 : 0.58921162,\n",
    "                                      1 : 3.30232558},\n",
    "                        callbacks = [\n",
    "                                     EarlyStopping(monitor='val_loss',\n",
    "                                        min_delta=0.01,\n",
    "                                        patience=50, mode='min',verbose=1,\n",
    "                                                      restore_best_weights=True)\n",
    "                                    ] #,ta.live(),\n",
    "                        )\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba0f365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                            classes=np.unique(train_label),\n",
    "                                            y=train_label.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8b305f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58921162, 3.30232558])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1883c",
   "metadata": {},
   "source": [
    "## 2.3 Przeprowadzam skan, używając parametrów i funkcji wyżej\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444d5b15",
   "metadata": {},
   "source": [
    "##  3. Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78cd5c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▏         | 237/270 [42:07<05:39, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adamax'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A999231B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9916F80D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 178.\n",
      "Epoch 00228: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▌         | 238/270 [42:23<06:29, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'nadam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D10D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A995389EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Epoch 00124: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|██████████████████████████████████████████████████████████████████████▊         | 239/270 [42:35<06:16, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adagrad'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CE5DDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A997D4ED38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 00076: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████         | 240/270 [42:43<05:24, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9916F8708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D45D0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 00067: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▍        | 241/270 [42:51<04:53, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98A250708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A999231B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 109.\n",
      "Epoch 00159: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▋        | 242/270 [43:06<05:20, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adadelta'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D333AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98FDFDF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 243/270 [43:13<04:33, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adamax'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A996734438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98FDFD4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 115.\n",
      "Epoch 00165: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▎       | 244/270 [43:28<04:57, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'nadam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CE5DF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D2B1F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Epoch 00115: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▌       | 245/270 [43:40<04:57, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adagrad'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D4F5DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D7888B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▉       | 246/270 [43:47<04:08, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D78B9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D0045E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Epoch 00103: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████▏      | 247/270 [43:59<04:10, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9953FC3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9990760D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Epoch 00139: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▍      | 248/270 [44:14<04:27, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adadelta'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9FDCBAC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A999076F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▊      | 249/270 [44:22<03:47, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adamax'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A992C52E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D004A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 129.\n",
      "Epoch 00179: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████      | 250/270 [44:40<04:18, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'nadam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98FCB0A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A989FFED38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Epoch 00110: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 251/270 [44:54<04:12, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 7, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adagrad'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98FE08A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9916F8C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 443.\n",
      "Epoch 00493: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▋     | 252/270 [45:36<06:32, 21.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9992310D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98BB5DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 00076: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████▉     | 253/270 [45:45<05:05, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98BBB3E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D45DB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 00063: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▎    | 254/270 [45:53<03:59, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adadelta'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99920F9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D788678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 255/270 [46:00<03:09, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adamax'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9991FAA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9953FCA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Epoch 00138: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|███████████████████████████████████████████████████████████████████████████▊    | 256/270 [46:12<02:54, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'nadam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D10D5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D26D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 00081: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████▏   | 257/270 [46:23<02:34, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adagrad'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A989FFECA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A992F7A0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 258/270 [46:30<02:04, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B6E34C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9990761F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 00082: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▋   | 259/270 [46:40<01:55, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98BBB3288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9918DA9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Epoch 00112: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████████████████████████████████████   | 260/270 [46:53<01:51, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adadelta'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A996AF6F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9FDCBAF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▎  | 261/270 [47:01<01:31, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adamax'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9FDAF4558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D6FA948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 161.\n",
      "Epoch 00211: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 262/270 [47:20<01:42, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'nadam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D2B1438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9916F88B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Epoch 00115: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▉  | 263/270 [47:35<01:33, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 100, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adagrad'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D89B708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D10D678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 00101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▏ | 264/270 [47:46<01:16, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99920FA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D89B8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Epoch 00088: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▌ | 265/270 [47:58<01:03, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D004A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99920F438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Epoch 00136: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|██████████████████████████████████████████████████████████████████████████████▊ | 266/270 [48:16<00:56, 14.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adadelta'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CE5D828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A995389EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████ | 267/270 [48:25<00:37, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adamax'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98FE08798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A995389828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 152.\n",
      "Epoch 00202: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████▍| 268/270 [48:47<00:30, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'nadam'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997B47048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D2B1C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Epoch 00133: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 269/270 [49:05<00:16, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 220, 'hidden_layers': 9, 'hidden_neuron': 150, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001, 'optimizer': 'adagrad'}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "adding layer 4\n",
      "adding layer 5\n",
      "adding layer 6\n",
      "adding layer 7\n",
      "adding layer 8\n",
      "adding layer 9\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A995389B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D45D288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 667.\n",
      "Epoch 00717: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 270/270 [50:12<00:00, 11.16s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t = ta.Scan(x=train_df, y=train_label,\n",
    "            x_val=test_df, y_val=test_label,\n",
    "            model=numerai_model,\n",
    "            params=p,  \n",
    "            experiment_name='Predykcja klasy M - Weighted binary cross-entropy (nowe)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "028ef827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/STUDIA/ROK_II/Magisterka/Modele/Dane pierwotne/M/Predykcja klasy M - Weighted binary cross-entropy (nowe)/050622223819.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a002c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stare_wart=df['val_fbeta_score']\n",
    "nowe_wart=[]\n",
    "for x in stare_wart:\n",
    "    wart=x.replace('[','')\n",
    "    wart=wart.replace(']','')\n",
    "    wart=float(wart)\n",
    "    nowe_wart.append(wart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0f081bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32352942,\n",
       " 0.33333334,\n",
       " 0.0,\n",
       " 0.32432434,\n",
       " 0.37837836,\n",
       " 0.2769231,\n",
       " 0.4,\n",
       " 0.19354838,\n",
       " 0.25974026,\n",
       " 0.3157895,\n",
       " 0.32432434,\n",
       " 0.27480918,\n",
       " 0.29752067,\n",
       " 0.1764706,\n",
       " 0.0,\n",
       " 0.3888889,\n",
       " 0.3380282,\n",
       " 0.27480918,\n",
       " 0.23529413,\n",
       " 0.35897437,\n",
       " 0.2531646,\n",
       " 0.38095242,\n",
       " 0.43243244,\n",
       " 0.26470587,\n",
       " 0.3,\n",
       " 0.18750001,\n",
       " 0.19047621,\n",
       " 0.34146345,\n",
       " 0.25742576,\n",
       " 0.25196853,\n",
       " 0.18750001,\n",
       " 0.35897437,\n",
       " 0.3007519,\n",
       " 0.32432434,\n",
       " 0.38095242,\n",
       " 0.27906978,\n",
       " 0.23529413,\n",
       " 0.30769232,\n",
       " 0.26829267,\n",
       " 0.29411766,\n",
       " 0.35897437,\n",
       " 0.2769231,\n",
       " 0.18750001,\n",
       " 0.3111111,\n",
       " 0.0,\n",
       " 0.3137255,\n",
       " 0.27027026,\n",
       " 0.2635659,\n",
       " 0.296875,\n",
       " 0.3157895,\n",
       " 0.125,\n",
       " 0.3157895,\n",
       " 0.29411766,\n",
       " 0.2769231,\n",
       " 0.30769232,\n",
       " 0.29230767,\n",
       " 0.26993865,\n",
       " 0.25,\n",
       " 0.29268292,\n",
       " 0.2769231,\n",
       " 0.27777776,\n",
       " 0.29007635,\n",
       " 0.0,\n",
       " 0.22857143,\n",
       " 0.24489795,\n",
       " 0.27067667,\n",
       " 0.2608696,\n",
       " 0.28368795,\n",
       " 0.25925925,\n",
       " 0.13333334,\n",
       " 0.29370627,\n",
       " 0.2769231,\n",
       " 0.2797203,\n",
       " 0.2781457,\n",
       " 0.28025478,\n",
       " 0.28571427,\n",
       " 0.28965515,\n",
       " 0.27692306,\n",
       " 0.2797203,\n",
       " 0.28571427,\n",
       " 0.0,\n",
       " 0.2857143,\n",
       " 0.28965515,\n",
       " 0.27067667,\n",
       " 0.27868852,\n",
       " 0.27777776,\n",
       " 0.26388887,\n",
       " 0.28235295,\n",
       " 0.28571427,\n",
       " 0.2769231,\n",
       " 0.3529412,\n",
       " 0.3157895,\n",
       " 0.27142859,\n",
       " 0.3157895,\n",
       " 0.3636364,\n",
       " 0.26771656,\n",
       " 0.31481484,\n",
       " 0.19354838,\n",
       " 0.06896552,\n",
       " 0.29411766,\n",
       " 0.36842105,\n",
       " 0.3157895,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.2835821,\n",
       " 0.35,\n",
       " 0.3157895,\n",
       " 0.2962963,\n",
       " 0.21621622,\n",
       " 0.2702703,\n",
       " 0.0,\n",
       " 0.35,\n",
       " 0.3333333,\n",
       " 0.26562497,\n",
       " 0.35,\n",
       " 0.36842105,\n",
       " 0.26666668,\n",
       " 0.25287357,\n",
       " 0.24242425,\n",
       " 0.2635659,\n",
       " 0.26804122,\n",
       " 0.35,\n",
       " 0.0,\n",
       " 0.2978723,\n",
       " 0.3157895,\n",
       " 0.2769231,\n",
       " 0.12903225,\n",
       " 0.26666668,\n",
       " 0.0,\n",
       " 0.3125,\n",
       " 0.33333334,\n",
       " 0.07407407,\n",
       " 0.31007752,\n",
       " 0.18750001,\n",
       " 0.0,\n",
       " 0.3,\n",
       " 0.34146345,\n",
       " 0.2769231,\n",
       " 0.2909091,\n",
       " 0.30303034,\n",
       " 0.0,\n",
       " 0.2702703,\n",
       " 0.4285714,\n",
       " 0.2769231,\n",
       " 0.35897437,\n",
       " 0.29197082,\n",
       " 0.26143792,\n",
       " 0.2857143,\n",
       " 0.33333334,\n",
       " 0.0,\n",
       " 0.26666668,\n",
       " 0.29197082,\n",
       " 0.08000001,\n",
       " 0.21052632,\n",
       " 0.35897437,\n",
       " 0.2769231,\n",
       " 0.29197082,\n",
       " 0.28965515,\n",
       " 0.0,\n",
       " 0.3188406,\n",
       " 0.2580645,\n",
       " 0.2769231,\n",
       " 0.29166666,\n",
       " 0.29166666,\n",
       " 0.25,\n",
       " 0.3,\n",
       " 0.29166666,\n",
       " 0.27096775,\n",
       " 0.25714284,\n",
       " 0.29370627,\n",
       " 0.14814815,\n",
       " 0.3125,\n",
       " 0.28169015,\n",
       " 0.2769231,\n",
       " 0.27777776,\n",
       " 0.28368795,\n",
       " 0.0,\n",
       " 0.3157895,\n",
       " 0.27999997,\n",
       " 0.24561404,\n",
       " 0.4,\n",
       " 0.37209302,\n",
       " 0.27210882,\n",
       " 0.33333334,\n",
       " 0.40000004,\n",
       " 0.27480918,\n",
       " 0.27826086,\n",
       " 0.35897437,\n",
       " 0.0,\n",
       " 0.36842105,\n",
       " 0.2702703,\n",
       " 0.29411766,\n",
       " 0.29357797,\n",
       " 0.35,\n",
       " 0.2797203,\n",
       " 0.31428573,\n",
       " 0.36363634,\n",
       " 0.29411766,\n",
       " 0.3492064,\n",
       " 0.28776976,\n",
       " 0.07692307,\n",
       " 0.26315787,\n",
       " 0.25,\n",
       " 0.3007519,\n",
       " 0.2857143,\n",
       " 0.20000002,\n",
       " 0.24657534,\n",
       " 0.32432434,\n",
       " 0.40816328,\n",
       " 0.2769231,\n",
       " 0.28333333,\n",
       " 0.18750001,\n",
       " 0.0,\n",
       " 0.23529413,\n",
       " 0.18181817,\n",
       " 0.2769231,\n",
       " 0.24242425,\n",
       " 0.28368795,\n",
       " 0.0,\n",
       " 0.27272728,\n",
       " 0.32558143,\n",
       " 0.29230767,\n",
       " 0.20000002,\n",
       " 0.2962963,\n",
       " 0.22727273,\n",
       " 0.2988506,\n",
       " 0.20000002,\n",
       " 0.29850748,\n",
       " 0.20689656,\n",
       " 0.2898551,\n",
       " 0.0,\n",
       " 0.3157895,\n",
       " 0.37837836,\n",
       " 0.3030303,\n",
       " 0.28368795,\n",
       " 0.2781457,\n",
       " 0.26829267,\n",
       " 0.29411766,\n",
       " 0.2797203,\n",
       " 0.27397257,\n",
       " 0.2797203,\n",
       " 0.28169015,\n",
       " 0.29545456,\n",
       " 0.2682927,\n",
       " 0.29577464,\n",
       " 0.28571427,\n",
       " 0.27397257,\n",
       " 0.29577464,\n",
       " 0.26993865,\n",
       " 0.3157895,\n",
       " 0.2898551,\n",
       " 0.296875,\n",
       " 0.28571427,\n",
       " 0.28965515,\n",
       " 0.24657534,\n",
       " 0.29197082,\n",
       " 0.2781457,\n",
       " 0.26829267,\n",
       " 0.27777776,\n",
       " 0.29370627,\n",
       " 0.0,\n",
       " 0.2682927,\n",
       " 0.2781457,\n",
       " 0.27480918,\n",
       " 0.27586204,\n",
       " 0.29166666,\n",
       " 0.0,\n",
       " 0.21052632,\n",
       " 0.29370627,\n",
       " 0.24390244]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nowe_wart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "de5bb23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['val_fbeta_score']=nowe_wart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "da430680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df.sort_values('val_loss',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "03efbcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['round_epochs', 'loss', 'fbeta_score', 'precision', 'recall',\n",
       "       'val_loss', 'val_fbeta_score', 'val_precision', 'val_recall',\n",
       "       'activation_layer', 'activity_regularizer', 'batc_normalization',\n",
       "       'batch_size', 'bias_regularizer', 'dropout', 'epochs', 'first_neuron',\n",
       "       'hidden_layers', 'hidden_neuron', 'kernel_initializer',\n",
       "       'kernel_regularizer_l1', 'kernel_regularizer_l2', 'last_activation',\n",
       "       'lr', 'optimizer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "460f8c24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>...</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>256</td>\n",
       "      <td>0.590018</td>\n",
       "      <td>[0.45070425]</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.532891</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adamax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>115</td>\n",
       "      <td>0.587497</td>\n",
       "      <td>[0.3542857]</td>\n",
       "      <td>0.234848</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.575804</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>257</td>\n",
       "      <td>0.579288</td>\n",
       "      <td>[0.44660196]</td>\n",
       "      <td>0.309417</td>\n",
       "      <td>0.802326</td>\n",
       "      <td>0.584282</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adamax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>267</td>\n",
       "      <td>0.532578</td>\n",
       "      <td>[0.47142857]</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.584678</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>192</td>\n",
       "      <td>0.652091</td>\n",
       "      <td>[0.42105263]</td>\n",
       "      <td>0.276364</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.586155</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adamax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>51</td>\n",
       "      <td>2.096005</td>\n",
       "      <td>[0.2883895]</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>2.093452</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adagrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>51</td>\n",
       "      <td>2.102069</td>\n",
       "      <td>[0.27213112]</td>\n",
       "      <td>0.158397</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>2.102681</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.155738</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adadelta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>717</td>\n",
       "      <td>2.128711</td>\n",
       "      <td>[0.3218391]</td>\n",
       "      <td>0.192661</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>2.135359</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>220</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adagrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>51</td>\n",
       "      <td>2.217879</td>\n",
       "      <td>[0.02247191]</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>2.214797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adadelta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>51</td>\n",
       "      <td>2.324313</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.320987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>100000</td>\n",
       "      <td>220</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adadelta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "81            256  0.590018  [0.45070425]   0.323232  0.744186  0.532891   \n",
       "7             115  0.587497   [0.3542857]   0.234848  0.720930  0.575804   \n",
       "3             257  0.579288  [0.44660196]   0.309417  0.802326  0.584282   \n",
       "115           267  0.532578  [0.47142857]   0.340206  0.767442  0.584678   \n",
       "171           192  0.652091  [0.42105263]   0.276364  0.883721  0.586155   \n",
       "..            ...       ...           ...        ...       ...       ...   \n",
       "89             51  2.096005   [0.2883895]   0.171875  0.895349  2.093452   \n",
       "86             51  2.102069  [0.27213112]   0.158397  0.965116  2.102681   \n",
       "269           717  2.128711   [0.3218391]   0.192661  0.976744  2.135359   \n",
       "176            51  2.217879  [0.02247191]   0.333333  0.011628  2.214797   \n",
       "266            51  2.324313          [0.]   0.000000  0.000000  2.320987   \n",
       "\n",
       "     val_fbeta_score  val_precision  val_recall activation_layer  ...  epochs  \\\n",
       "81          0.285714       0.384615    0.227273             relu  ...  100000   \n",
       "7           0.193548       0.333333    0.136364             relu  ...  100000   \n",
       "3           0.324324       0.400000    0.272727             relu  ...  100000   \n",
       "115         0.368421       0.437500    0.318182             relu  ...  100000   \n",
       "171         0.312500       0.500000    0.227273             relu  ...  100000   \n",
       "..               ...            ...         ...              ...  ...     ...   \n",
       "89          0.276923       0.166667    0.818182             relu  ...  100000   \n",
       "86          0.263889       0.155738    0.863636             relu  ...  100000   \n",
       "269         0.243902       0.166667    0.454545             relu  ...  100000   \n",
       "176         0.000000       0.000000    0.000000             relu  ...  100000   \n",
       "266         0.000000       0.000000    0.000000             relu  ...  100000   \n",
       "\n",
       "     first_neuron  hidden_layers  hidden_neuron  kernel_initializer  \\\n",
       "81             55              9            100          orthogonal   \n",
       "7              55              1            100          orthogonal   \n",
       "3              55              1             50          orthogonal   \n",
       "115           110              3            100          orthogonal   \n",
       "171           110              9            100          orthogonal   \n",
       "..            ...            ...            ...                 ...   \n",
       "89             55              9            150          orthogonal   \n",
       "86             55              9            150          orthogonal   \n",
       "269           220              9            150          orthogonal   \n",
       "176           110              9            150          orthogonal   \n",
       "266           220              9            150          orthogonal   \n",
       "\n",
       "     kernel_regularizer_l1  kernel_regularizer_l2  last_activation     lr  \\\n",
       "81                  0.0001                 0.0001          sigmoid  0.001   \n",
       "7                   0.0001                 0.0001          sigmoid  0.001   \n",
       "3                   0.0001                 0.0001          sigmoid  0.001   \n",
       "115                 0.0001                 0.0001          sigmoid  0.001   \n",
       "171                 0.0001                 0.0001          sigmoid  0.001   \n",
       "..                     ...                    ...              ...    ...   \n",
       "89                  0.0001                 0.0001          sigmoid  0.001   \n",
       "86                  0.0001                 0.0001          sigmoid  0.001   \n",
       "269                 0.0001                 0.0001          sigmoid  0.001   \n",
       "176                 0.0001                 0.0001          sigmoid  0.001   \n",
       "266                 0.0001                 0.0001          sigmoid  0.001   \n",
       "\n",
       "    optimizer  \n",
       "81     adamax  \n",
       "7        adam  \n",
       "3      adamax  \n",
       "115      adam  \n",
       "171    adamax  \n",
       "..        ...  \n",
       "89    adagrad  \n",
       "86   adadelta  \n",
       "269   adagrad  \n",
       "176  adadelta  \n",
       "266  adadelta  \n",
       "\n",
       "[270 rows x 25 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "57ea1ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of hidden_layers')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'hidden_layers'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0b74d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of hidden_neuron')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'hidden_neuron'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "48b694c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of first_neuron')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'first_neuron'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "473f441e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of optimizer')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'optimizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "74c45771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df[df['optimizer']!='adagrad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "494d8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2[df2['optimizer']!='adadelta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c6fd195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of optimizer')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'optimizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df2.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce773f",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63abab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numerai_model(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    print(params)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    ## initial layer\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1],\n",
    "                    activation='relu',\n",
    "               \n",
    "                    kernel_initializer = params['kernel_initializer'],\n",
    "                    kernel_regularizer=keras.regularizers.l1_l2(l1=params['kernel_regularizer_l1'],\n",
    "                                                                l2=params['kernel_regularizer_l2']),\n",
    "                    bias_regularizer=keras.regularizers.l2(params['bias_regularizer']),\n",
    "                    activity_regularizer=keras.regularizers.l2(params['activity_regularizer'])\n",
    "                   ))\n",
    "    if params['batc_normalization']==True:\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "    if params['dropout']!=0:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    ## hidden layers\n",
    "    for i in range(params['hidden_layers']):\n",
    "        print (f\"adding layer {i+1}\")\n",
    "        model.add(Dense(params['hidden_neuron'], activation='relu',\n",
    "                    kernel_initializer=params['kernel_initializer'],\n",
    "                        kernel_regularizer=keras.regularizers.l1_l2(l1=params['kernel_regularizer_l1'],\n",
    "                                                                    l2=params['kernel_regularizer_l2']),\n",
    "                    bias_regularizer=keras.regularizers.l2(params['bias_regularizer']),\n",
    "                    activity_regularizer=keras.regularizers.l2(params['activity_regularizer'])\n",
    "                       ))\n",
    "        if params['batc_normalization']==True:\n",
    "            model.add(BatchNormalization())\n",
    "            \n",
    "        if params['dropout']!=0:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    \n",
    "    ## final layer\n",
    "    model.add(Dense(1, activation=params['last_activation'],\n",
    "                    kernel_initializer=params['kernel_initializer'],\n",
    "                   kernel_regularizer=keras.regularizers.l1_l2(l1=params['kernel_regularizer_l1'],\n",
    "                                                               l2=params['kernel_regularizer_l2']),\n",
    "                    bias_regularizer=keras.regularizers.l2(params['bias_regularizer']),\n",
    "                    activity_regularizer=keras.regularizers.l2(params['activity_regularizer'])\n",
    "                   ))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=params['lr']),\n",
    "                  metrics=[tfa.metrics.FBetaScore(num_classes=1, beta=1.0, threshold=0.5),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),])\n",
    "  \n",
    "  \n",
    "    history = model.fit(x_train, y_train, \n",
    "                        validation_data=[x_val, y_val],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        epochs=params['epochs'],\n",
    "                        verbose=0,\n",
    "                        class_weight={0 : 0.58921162,\n",
    "                                      1 : 3.30232558},\n",
    "                        callbacks = [\n",
    "                                     EarlyStopping(monitor='val_loss',\n",
    "                                        min_delta=0.01,\n",
    "                                        patience=50, mode='min',verbose=1,\n",
    "                                                      restore_best_weights=True)\n",
    "                                    ] #,ta.live(),\n",
    "                        )\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cec7da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron':[55],  #Done\n",
    "     'hidden_neuron':[50], #Done\n",
    "\n",
    "     'hidden_layers':[1,2,3],  \n",
    "\n",
    "     \n",
    "    'epochs': [100000], # never touch it\n",
    "\n",
    "\n",
    "    'last_activation': ['sigmoid'], #never touch it\n",
    "\n",
    "\n",
    "    'batch_size': [16,32,64],\n",
    "\n",
    "    'lr':[0.001],\n",
    "    \n",
    "    'kernel_regularizer_l1':[0.0001],#[0,0.001,0.0001],\n",
    "    'kernel_regularizer_l2':[0.0001],#[0,0.001,0.0001],\n",
    "    'bias_regularizer':[0.0001],#[0,0.001,0.0001],\n",
    "    'activity_regularizer':[0.0001],#[0,0.001,0.0001],\n",
    "\n",
    "#    'batc_normalization':[False,True],\n",
    "    'dropout': [0,0.2,0.4],\n",
    "  #  'dropout': [0],\n",
    "    \n",
    "  \n",
    "    #'kernel_initializer': ['orthogonal','identity','zeros','ones','uniform'],\n",
    "    'kernel_initializer': ['orthogonal'],\n",
    "    #'activation_layer':['sigmoid','tanh','selu','elu','relu'],\n",
    "    #'activation_layer':['relu'],\n",
    "    'batc_normalization':[False,True]\n",
    "    #'batc_normalization':[False],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f622789c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99151B9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D8D3708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 124.\n",
      "Epoch 00174: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                                 | 1/54 [00:13<11:59, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997B47288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A999076A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 127.\n",
      "Epoch 00177: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███                                                                                | 2/54 [00:28<12:20, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98A239798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A999076168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Epoch 00090: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▌                                                                              | 3/54 [00:37<10:10, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98A239AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98FCB0CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Epoch 00143: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████▏                                                                            | 4/54 [00:49<09:51, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B9FF8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CBFADC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 167.\n",
      "Epoch 00217: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▋                                                                           | 5/54 [01:07<11:30, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997E67708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CBFA288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 157.\n",
      "Epoch 00207: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▏                                                                         | 6/54 [01:25<12:25, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A999076798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98BB5DC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Epoch 00093: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▊                                                                        | 7/54 [01:33<10:20, 13.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99171A8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98EB8F5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 00081: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▎                                                                      | 8/54 [01:42<08:57, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997CE6E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CBFAF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Epoch 00112: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                     | 9/54 [01:53<08:39, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A989EDC828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98FDFD948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 114.\n",
      "Epoch 00164: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▏                                                                  | 10/54 [02:02<07:57, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99B58F828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98A239558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 127.\n",
      "Epoch 00177: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▋                                                                 | 11/54 [02:13<07:42, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99B58FEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99151BA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 137.\n",
      "Epoch 00187: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▏                                                               | 12/54 [02:24<07:36, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99B6E25E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99920F948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Epoch 00119: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▋                                                              | 13/54 [02:32<06:43,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CBFA948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A997E670D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 00082: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▎                                                            | 14/54 [02:38<05:50,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98FCB0708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99151B168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 106.\n",
      "Epoch 00156: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▊                                                           | 15/54 [02:48<06:01,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997E67D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CBFA678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 00085: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                         | 16/54 [02:54<05:14,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CBFA168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99B58FCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Epoch 00123: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▊                                                        | 17/54 [03:03<05:06,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A996AF6F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D770558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Epoch 00149: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████▎                                                      | 18/54 [03:13<05:18,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D3BA4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D8D3678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 129.\n",
      "Epoch 00179: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▊                                                     | 19/54 [03:21<04:59,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99151B1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99B58F9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 107.\n",
      "Epoch 00157: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▎                                                   | 20/54 [03:28<04:42,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A996987558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D3BA8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Epoch 00134: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▉                                                  | 21/54 [03:36<04:26,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98A2399D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CBFA0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 125.\n",
      "Epoch 00175: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▍                                                | 22/54 [03:44<04:18,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9942D7948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99B6E2438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 134.\n",
      "Epoch 00184: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▉                                               | 23/54 [03:53<04:19,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D3BA3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98A2390D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 120.\n",
      "Epoch 00170: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████▍                                             | 24/54 [04:02<04:18,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98FCB0F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D7704C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 00078: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▉                                            | 25/54 [04:07<03:37,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9942D7708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D7709D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Epoch 00102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▍                                          | 26/54 [04:13<03:17,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A999231A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A996748B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 111.\n",
      "Epoch 00161: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 27/54 [04:22<03:24,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99B58FF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98FF38948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Epoch 00098: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▌                                       | 28/54 [04:32<03:35,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A999076948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D37DE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 00067: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|████████████████████████████████████████████                                      | 29/54 [04:40<03:29,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98BB5D828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A997B35B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 00078: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▌                                    | 30/54 [04:51<03:36,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997CE6D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98FF38288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 00080: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████████████                                   | 31/54 [05:00<03:25,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D89B048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CBFA168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Epoch 00089: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████████▌                                 | 32/54 [05:10<03:27,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D7ED678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A997CF65E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Epoch 00136: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████████████████████████████████████████████████                                | 33/54 [05:27<04:04, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9914824C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D6FAB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Epoch 00108: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████▋                              | 34/54 [05:38<03:48, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D016F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99B58F708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 00055: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▏                            | 35/54 [05:46<03:17, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 16, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997B475E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D8D3E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 00058: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████▋                           | 36/54 [05:55<03:01, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99B58F678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98BBB3B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 00080: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████▏                         | 37/54 [06:03<02:37,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D78B798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99173DCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 00080: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▋                        | 38/54 [06:11<02:21,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CBFA678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A999347A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 00072: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████████████████████████████████████▏                      | 39/54 [06:19<02:12,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A996987F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A996AF6438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Epoch 00130: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▋                     | 40/54 [06:29<02:08,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A996AF6B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CEA6558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Epoch 00122: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████▎                   | 41/54 [06:41<02:08,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CEA6AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98FEEA4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Epoch 00135: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████▊                  | 42/54 [06:53<02:06, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98EB8FC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9942D7798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 174.\n",
      "Epoch 00224: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▎                | 43/54 [07:08<02:11, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98FF38A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D3BA678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Epoch 00115: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████▊               | 44/54 [07:18<01:54, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 32, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CBFA678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A999076CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 45/54 [07:26<01:31, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99B6E2558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99B58F948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 00082: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▊            | 46/54 [07:32<01:11,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98BB5DF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98FDFDEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Epoch 00094: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|███████████████████████████████████████████████████████████████████████▎          | 47/54 [07:38<00:58,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A989FEFE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98A569948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 00087: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████████████████████████████████████████████████▉         | 48/54 [07:46<00:48,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D37DAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98EB8F3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Epoch 00112: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████▍       | 49/54 [07:53<00:38,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D770708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D016B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Epoch 00127: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████████████▉      | 50/54 [08:02<00:32,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997CE6D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99A36D4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Epoch 00139: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████████████▍    | 51/54 [08:12<00:26,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D7ED558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99173D1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Epoch 00145: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▉   | 52/54 [08:20<00:17,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B54DCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D0161F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 00058: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████████▍ | 53/54 [08:26<00:07,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activity_regularizer': 0.0001, 'batc_normalization': True, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 3, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "adding layer 3\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9942D74C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98FEBFDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [08:33<00:00,  9.50s/it]\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=train_df, y=train_label,\n",
    "            x_val=test_df, y_val=test_label,\n",
    "            model=numerai_model,\n",
    "            params=p,  \n",
    "            experiment_name='Predykcja klasy M - Weighted binary cross-entropy (nowe)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ba58ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/STUDIA/ROK_II/Magisterka/Modele/Dane pierwotne/M/Predykcja klasy M - Weighted binary cross-entropy (nowe)/050622234653.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4a1e198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stare_wart=df['val_fbeta_score']\n",
    "nowe_wart=[]\n",
    "for x in stare_wart:\n",
    "    wart=x.replace('[','')\n",
    "    wart=wart.replace(']','')\n",
    "    wart=float(wart)\n",
    "    nowe_wart.append(wart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "98dcfe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['val_fbeta_score']=nowe_wart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0d6867b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values('val_loss',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b79386c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activity_regularizer</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>80</td>\n",
       "      <td>0.486337</td>\n",
       "      <td>[0.5198556]</td>\n",
       "      <td>0.376963</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>2.458508</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>0.172727</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>98</td>\n",
       "      <td>0.563983</td>\n",
       "      <td>[0.472441]</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>1.347379</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>94</td>\n",
       "      <td>0.378199</td>\n",
       "      <td>[0.7027027]</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>1.141914</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>130</td>\n",
       "      <td>0.605692</td>\n",
       "      <td>[0.41486067]</td>\n",
       "      <td>0.282700</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>1.039489</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>80</td>\n",
       "      <td>0.478975</td>\n",
       "      <td>[0.5877551]</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.991567</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>115</td>\n",
       "      <td>0.720001</td>\n",
       "      <td>[0.34355828]</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.980911</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>72</td>\n",
       "      <td>0.465840</td>\n",
       "      <td>[0.6428572]</td>\n",
       "      <td>0.487952</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.971022</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>87</td>\n",
       "      <td>0.363330</td>\n",
       "      <td>[0.7248908]</td>\n",
       "      <td>0.580420</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.962020</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>51</td>\n",
       "      <td>0.849010</td>\n",
       "      <td>[0.2763466]</td>\n",
       "      <td>0.173021</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.891425</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>51</td>\n",
       "      <td>0.846961</td>\n",
       "      <td>[0.26732674]</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.891040</td>\n",
       "      <td>0.302158</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>58</td>\n",
       "      <td>0.835495</td>\n",
       "      <td>[0.25822785]</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.857196</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>55</td>\n",
       "      <td>0.794694</td>\n",
       "      <td>[0.2673522]</td>\n",
       "      <td>0.171617</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.802564</td>\n",
       "      <td>0.300752</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>82</td>\n",
       "      <td>0.660335</td>\n",
       "      <td>[0.31078613]</td>\n",
       "      <td>0.184382</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.791348</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>156</td>\n",
       "      <td>0.633996</td>\n",
       "      <td>[0.31004366]</td>\n",
       "      <td>0.190860</td>\n",
       "      <td>0.825581</td>\n",
       "      <td>0.786602</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>161</td>\n",
       "      <td>0.680465</td>\n",
       "      <td>[0.31343284]</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.782613</td>\n",
       "      <td>0.291971</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>136</td>\n",
       "      <td>0.716466</td>\n",
       "      <td>[0.40119764]</td>\n",
       "      <td>0.270161</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.781074</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177</td>\n",
       "      <td>0.556001</td>\n",
       "      <td>[0.46268657]</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.763818</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112</td>\n",
       "      <td>0.660760</td>\n",
       "      <td>[0.3130755]</td>\n",
       "      <td>0.185996</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.758233</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>149</td>\n",
       "      <td>0.666511</td>\n",
       "      <td>[0.32712215]</td>\n",
       "      <td>0.198992</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>0.757846</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>139</td>\n",
       "      <td>0.653113</td>\n",
       "      <td>[0.45714283]</td>\n",
       "      <td>0.314410</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.757446</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81</td>\n",
       "      <td>0.684523</td>\n",
       "      <td>[0.30733946]</td>\n",
       "      <td>0.191429</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.757072</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>102</td>\n",
       "      <td>0.684124</td>\n",
       "      <td>[0.30592737]</td>\n",
       "      <td>0.183066</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.756089</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>0.571503</td>\n",
       "      <td>[0.39156625]</td>\n",
       "      <td>0.264228</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.752438</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>58</td>\n",
       "      <td>0.772725</td>\n",
       "      <td>[0.2906404]</td>\n",
       "      <td>0.184375</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.748110</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>67</td>\n",
       "      <td>0.640041</td>\n",
       "      <td>[0.44368604]</td>\n",
       "      <td>0.314010</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.746010</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>123</td>\n",
       "      <td>0.658676</td>\n",
       "      <td>[0.31174088]</td>\n",
       "      <td>0.188725</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.734592</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>184</td>\n",
       "      <td>0.598555</td>\n",
       "      <td>[0.39726028]</td>\n",
       "      <td>0.281553</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.732111</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>89</td>\n",
       "      <td>0.705003</td>\n",
       "      <td>[0.4217252]</td>\n",
       "      <td>0.290749</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.729436</td>\n",
       "      <td>0.273973</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>78</td>\n",
       "      <td>0.677702</td>\n",
       "      <td>[0.32719836]</td>\n",
       "      <td>0.198511</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.728226</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>0.613992</td>\n",
       "      <td>[0.37062934]</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.723371</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>80</td>\n",
       "      <td>0.688401</td>\n",
       "      <td>[0.33021805]</td>\n",
       "      <td>0.225532</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.716197</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>85</td>\n",
       "      <td>0.665592</td>\n",
       "      <td>[0.31759655]</td>\n",
       "      <td>0.194737</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.714897</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93</td>\n",
       "      <td>0.644430</td>\n",
       "      <td>[0.32207793]</td>\n",
       "      <td>0.207358</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.705500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>170</td>\n",
       "      <td>0.632279</td>\n",
       "      <td>[0.36809817]</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.700893</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>187</td>\n",
       "      <td>0.536753</td>\n",
       "      <td>[0.4736842]</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.698344</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>157</td>\n",
       "      <td>0.551235</td>\n",
       "      <td>[0.40816328]</td>\n",
       "      <td>0.261438</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.695325</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>175</td>\n",
       "      <td>0.606068</td>\n",
       "      <td>[0.39067054]</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.673926</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>82</td>\n",
       "      <td>0.449584</td>\n",
       "      <td>[0.56826574]</td>\n",
       "      <td>0.416216</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.671719</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>119</td>\n",
       "      <td>0.610830</td>\n",
       "      <td>[0.39664805]</td>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.825581</td>\n",
       "      <td>0.666710</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217</td>\n",
       "      <td>0.600242</td>\n",
       "      <td>[0.33714285]</td>\n",
       "      <td>0.223485</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.660769</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>224</td>\n",
       "      <td>0.629271</td>\n",
       "      <td>[0.39202657]</td>\n",
       "      <td>0.274419</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.641238</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>108</td>\n",
       "      <td>0.684390</td>\n",
       "      <td>[0.3409091]</td>\n",
       "      <td>0.225564</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.637354</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>0.613467</td>\n",
       "      <td>[0.3119266]</td>\n",
       "      <td>0.211618</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.636007</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>207</td>\n",
       "      <td>0.595492</td>\n",
       "      <td>[0.35555556]</td>\n",
       "      <td>0.244541</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.634221</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>78</td>\n",
       "      <td>0.613812</td>\n",
       "      <td>[0.5201465]</td>\n",
       "      <td>0.379679</td>\n",
       "      <td>0.825581</td>\n",
       "      <td>0.621019</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>179</td>\n",
       "      <td>0.549710</td>\n",
       "      <td>[0.42477876]</td>\n",
       "      <td>0.284585</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.620092</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>164</td>\n",
       "      <td>0.555070</td>\n",
       "      <td>[0.42809364]</td>\n",
       "      <td>0.300469</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.613129</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>127</td>\n",
       "      <td>0.605966</td>\n",
       "      <td>[0.47719297]</td>\n",
       "      <td>0.341709</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.607879</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>122</td>\n",
       "      <td>0.632549</td>\n",
       "      <td>[0.4761905]</td>\n",
       "      <td>0.327511</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.594997</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>135</td>\n",
       "      <td>0.673498</td>\n",
       "      <td>[0.46394977]</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.590229</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>177</td>\n",
       "      <td>0.564290</td>\n",
       "      <td>[0.39007092]</td>\n",
       "      <td>0.280612</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.587422</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>134</td>\n",
       "      <td>0.578106</td>\n",
       "      <td>[0.44696972]</td>\n",
       "      <td>0.331461</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.570737</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>145</td>\n",
       "      <td>0.582077</td>\n",
       "      <td>[0.43934426]</td>\n",
       "      <td>0.305936</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.545080</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>112</td>\n",
       "      <td>0.553971</td>\n",
       "      <td>[0.46268657]</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.519484</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "36            80  0.486337   [0.5198556]   0.376963  0.837209  2.458508   \n",
       "27            98  0.563983    [0.472441]   0.357143  0.697674  1.347379   \n",
       "46            94  0.378199   [0.7027027]   0.573529  0.906977  1.141914   \n",
       "39           130  0.605692  [0.41486067]   0.282700  0.779070  1.039489   \n",
       "37            80  0.478975   [0.5877551]   0.452830  0.837209  0.991567   \n",
       "43           115  0.720001  [0.34355828]   0.233333  0.651163  0.980911   \n",
       "38            72  0.465840   [0.6428572]   0.487952  0.941860  0.971022   \n",
       "47            87  0.363330   [0.7248908]   0.580420  0.965116  0.962020   \n",
       "44            51  0.849010   [0.2763466]   0.173021  0.686047  0.891425   \n",
       "53            51  0.846961  [0.26732674]   0.169811  0.627907  0.891040   \n",
       "35            58  0.835495  [0.25822785]   0.165049  0.593023  0.857196   \n",
       "34            55  0.794694   [0.2673522]   0.171617  0.604651  0.802564   \n",
       "13            82  0.660335  [0.31078613]   0.184382  0.988372  0.791348   \n",
       "14           156  0.633996  [0.31004366]   0.190860  0.825581  0.786602   \n",
       "26           161  0.680465  [0.31343284]   0.186667  0.976744  0.782613   \n",
       "32           136  0.716466  [0.40119764]   0.270161  0.779070  0.781074   \n",
       "1            177  0.556001  [0.46268657]   0.340659  0.720930  0.763818   \n",
       "8            112  0.660760   [0.3130755]   0.185996  0.988372  0.758233   \n",
       "17           149  0.666511  [0.32712215]   0.198992  0.918605  0.757846   \n",
       "50           139  0.653113  [0.45714283]   0.314410  0.837209  0.757446   \n",
       "7             81  0.684523  [0.30733946]   0.191429  0.779070  0.757072   \n",
       "25           102  0.684124  [0.30592737]   0.183066  0.930233  0.756089   \n",
       "0            174  0.571503  [0.39156625]   0.264228  0.755814  0.752438   \n",
       "52            58  0.772725   [0.2906404]   0.184375  0.686047  0.748110   \n",
       "28            67  0.640041  [0.44368604]   0.314010  0.755814  0.746010   \n",
       "16           123  0.658676  [0.31174088]   0.188725  0.895349  0.734592   \n",
       "22           184  0.598555  [0.39726028]   0.281553  0.674419  0.732111   \n",
       "31            89  0.705003   [0.4217252]   0.290749  0.767442  0.729436   \n",
       "24            78  0.677702  [0.32719836]   0.198511  0.930233  0.728226   \n",
       "2             90  0.613992  [0.37062934]   0.265000  0.616279  0.723371   \n",
       "30            80  0.688401  [0.33021805]   0.225532  0.616279  0.716197   \n",
       "15            85  0.665592  [0.31759655]   0.194737  0.860465  0.714897   \n",
       "6             93  0.644430  [0.32207793]   0.207358  0.720930  0.705500   \n",
       "23           170  0.632279  [0.36809817]   0.250000  0.697674  0.700893   \n",
       "11           187  0.536753   [0.4736842]   0.350000  0.732558  0.698344   \n",
       "19           157  0.551235  [0.40816328]   0.261438  0.930233  0.695325   \n",
       "21           175  0.606068  [0.39067054]   0.260700  0.779070  0.673926   \n",
       "45            82  0.449584  [0.56826574]   0.416216  0.895349  0.671719   \n",
       "12           119  0.610830  [0.39664805]   0.261029  0.825581  0.666710   \n",
       "4            217  0.600242  [0.33714285]   0.223485  0.686047  0.660769   \n",
       "42           224  0.629271  [0.39202657]   0.274419  0.686047  0.641238   \n",
       "33           108  0.684390   [0.3409091]   0.225564  0.697674  0.637354   \n",
       "3            143  0.613467   [0.3119266]   0.211618  0.593023  0.636007   \n",
       "5            207  0.595492  [0.35555556]   0.244541  0.651163  0.634221   \n",
       "29            78  0.613812   [0.5201465]   0.379679  0.825581  0.621019   \n",
       "18           179  0.549710  [0.42477876]   0.284585  0.837209  0.620092   \n",
       "9            164  0.555070  [0.42809364]   0.300469  0.744186  0.613129   \n",
       "49           127  0.605966  [0.47719297]   0.341709  0.790698  0.607879   \n",
       "40           122  0.632549   [0.4761905]   0.327511  0.872093  0.594997   \n",
       "41           135  0.673498  [0.46394977]   0.317597  0.860465  0.590229   \n",
       "10           177  0.564290  [0.39007092]   0.280612  0.639535  0.587422   \n",
       "20           134  0.578106  [0.44696972]   0.331461  0.686047  0.570737   \n",
       "51           145  0.582077  [0.43934426]   0.305936  0.779070  0.545080   \n",
       "48           112  0.553971  [0.46268657]   0.340659  0.720930  0.519484   \n",
       "\n",
       "    val_fbeta_score  val_precision  val_recall  activity_regularizer  ...  \\\n",
       "36         0.287879       0.172727    0.863636                0.0001  ...   \n",
       "27         0.283582       0.169643    0.863636                0.0001  ...   \n",
       "46         0.193548       0.333333    0.136364                0.0001  ...   \n",
       "39         0.296296       0.176991    0.909091                0.0001  ...   \n",
       "37         0.242424       0.363636    0.181818                0.0001  ...   \n",
       "43         0.294118       0.175439    0.909091                0.0001  ...   \n",
       "38         0.225806       0.175000    0.318182                0.0001  ...   \n",
       "47         0.214286       0.500000    0.136364                0.0001  ...   \n",
       "44         0.295775       0.175000    0.954545                0.0001  ...   \n",
       "53         0.302158       0.179487    0.954545                0.0001  ...   \n",
       "35         0.289855       0.172414    0.909091                0.0001  ...   \n",
       "34         0.300752       0.180180    0.909091                0.0001  ...   \n",
       "13         0.289855       0.172414    0.909091                0.0001  ...   \n",
       "14         0.333333       0.428571    0.272727                0.0001  ...   \n",
       "26         0.291971       0.173913    0.909091                0.0001  ...   \n",
       "32         0.245283       0.154762    0.590909                0.0001  ...   \n",
       "1          0.325581       0.333333    0.318182                0.0001  ...   \n",
       "8          0.283688       0.168067    0.909091                0.0001  ...   \n",
       "17         0.285714       0.171171    0.863636                0.0001  ...   \n",
       "50         0.236842       0.166667    0.409091                0.0001  ...   \n",
       "7          0.283688       0.168067    0.909091                0.0001  ...   \n",
       "25         0.289855       0.172414    0.909091                0.0001  ...   \n",
       "0          0.342857       0.250000    0.545455                0.0001  ...   \n",
       "52         0.293333       0.207547    0.500000                0.0001  ...   \n",
       "28         0.269231       0.233333    0.318182                0.0001  ...   \n",
       "16         0.363636       0.363636    0.363636                0.0001  ...   \n",
       "22         0.354839       0.275000    0.500000                0.0001  ...   \n",
       "31         0.273973       0.196078    0.454545                0.0001  ...   \n",
       "24         0.296296       0.176991    0.909091                0.0001  ...   \n",
       "2          0.358974       0.411765    0.318182                0.0001  ...   \n",
       "30         0.282609       0.185714    0.590909                0.0001  ...   \n",
       "15         0.292308       0.175926    0.863636                0.0001  ...   \n",
       "6          0.312500       0.202703    0.681818                0.0001  ...   \n",
       "23         0.416667       0.384615    0.454545                0.0001  ...   \n",
       "11         0.352941       0.310345    0.409091                0.0001  ...   \n",
       "19         0.187500       0.300000    0.136364                0.0001  ...   \n",
       "21         0.400000       0.444444    0.363636                0.0001  ...   \n",
       "45         0.137931       0.285714    0.090909                0.0001  ...   \n",
       "12         0.378378       0.466667    0.318182                0.0001  ...   \n",
       "4          0.333333       0.428571    0.272727                0.0001  ...   \n",
       "42         0.264151       0.225806    0.318182                0.0001  ...   \n",
       "33         0.250000       0.400000    0.181818                0.0001  ...   \n",
       "3          0.294118       0.416667    0.227273                0.0001  ...   \n",
       "5          0.342857       0.461538    0.272727                0.0001  ...   \n",
       "29         0.176471       0.250000    0.136364                0.0001  ...   \n",
       "18         0.263158       0.312500    0.227273                0.0001  ...   \n",
       "9          0.358974       0.411765    0.318182                0.0001  ...   \n",
       "49         0.137931       0.285714    0.090909                0.0001  ...   \n",
       "40         0.235294       0.333333    0.181818                0.0001  ...   \n",
       "41         0.181818       0.272727    0.136364                0.0001  ...   \n",
       "10         0.270270       0.333333    0.227273                0.0001  ...   \n",
       "20         0.333333       0.350000    0.318182                0.0001  ...   \n",
       "51         0.200000       0.375000    0.136364                0.0001  ...   \n",
       "48         0.153846       0.500000    0.090909                0.0001  ...   \n",
       "\n",
       "    dropout  epochs  first_neuron  hidden_layers  hidden_neuron  \\\n",
       "36      0.0  100000            55              1             50   \n",
       "27      0.0  100000            55              1             50   \n",
       "46      0.0  100000            55              2             50   \n",
       "39      0.2  100000            55              1             50   \n",
       "37      0.0  100000            55              2             50   \n",
       "43      0.4  100000            55              2             50   \n",
       "38      0.0  100000            55              3             50   \n",
       "47      0.0  100000            55              3             50   \n",
       "44      0.4  100000            55              3             50   \n",
       "53      0.4  100000            55              3             50   \n",
       "35      0.4  100000            55              3             50   \n",
       "34      0.4  100000            55              2             50   \n",
       "13      0.2  100000            55              2             50   \n",
       "14      0.2  100000            55              3             50   \n",
       "26      0.4  100000            55              3             50   \n",
       "32      0.2  100000            55              3             50   \n",
       "1       0.0  100000            55              2             50   \n",
       "8       0.4  100000            55              3             50   \n",
       "17      0.4  100000            55              3             50   \n",
       "50      0.2  100000            55              3             50   \n",
       "7       0.4  100000            55              2             50   \n",
       "25      0.4  100000            55              2             50   \n",
       "0       0.0  100000            55              1             50   \n",
       "52      0.4  100000            55              2             50   \n",
       "28      0.0  100000            55              2             50   \n",
       "16      0.4  100000            55              2             50   \n",
       "22      0.2  100000            55              2             50   \n",
       "31      0.2  100000            55              2             50   \n",
       "24      0.4  100000            55              1             50   \n",
       "2       0.0  100000            55              3             50   \n",
       "30      0.2  100000            55              1             50   \n",
       "15      0.4  100000            55              1             50   \n",
       "6       0.4  100000            55              1             50   \n",
       "23      0.2  100000            55              3             50   \n",
       "11      0.0  100000            55              3             50   \n",
       "19      0.0  100000            55              2             50   \n",
       "21      0.2  100000            55              1             50   \n",
       "45      0.0  100000            55              1             50   \n",
       "12      0.2  100000            55              1             50   \n",
       "4       0.2  100000            55              2             50   \n",
       "42      0.4  100000            55              1             50   \n",
       "33      0.4  100000            55              1             50   \n",
       "3       0.2  100000            55              1             50   \n",
       "5       0.2  100000            55              3             50   \n",
       "29      0.0  100000            55              3             50   \n",
       "18      0.0  100000            55              1             50   \n",
       "9       0.0  100000            55              1             50   \n",
       "49      0.2  100000            55              2             50   \n",
       "40      0.2  100000            55              2             50   \n",
       "41      0.2  100000            55              3             50   \n",
       "10      0.0  100000            55              2             50   \n",
       "20      0.0  100000            55              3             50   \n",
       "51      0.4  100000            55              1             50   \n",
       "48      0.2  100000            55              1             50   \n",
       "\n",
       "    kernel_initializer  kernel_regularizer_l1  kernel_regularizer_l2  \\\n",
       "36          orthogonal                 0.0001                 0.0001   \n",
       "27          orthogonal                 0.0001                 0.0001   \n",
       "46          orthogonal                 0.0001                 0.0001   \n",
       "39          orthogonal                 0.0001                 0.0001   \n",
       "37          orthogonal                 0.0001                 0.0001   \n",
       "43          orthogonal                 0.0001                 0.0001   \n",
       "38          orthogonal                 0.0001                 0.0001   \n",
       "47          orthogonal                 0.0001                 0.0001   \n",
       "44          orthogonal                 0.0001                 0.0001   \n",
       "53          orthogonal                 0.0001                 0.0001   \n",
       "35          orthogonal                 0.0001                 0.0001   \n",
       "34          orthogonal                 0.0001                 0.0001   \n",
       "13          orthogonal                 0.0001                 0.0001   \n",
       "14          orthogonal                 0.0001                 0.0001   \n",
       "26          orthogonal                 0.0001                 0.0001   \n",
       "32          orthogonal                 0.0001                 0.0001   \n",
       "1           orthogonal                 0.0001                 0.0001   \n",
       "8           orthogonal                 0.0001                 0.0001   \n",
       "17          orthogonal                 0.0001                 0.0001   \n",
       "50          orthogonal                 0.0001                 0.0001   \n",
       "7           orthogonal                 0.0001                 0.0001   \n",
       "25          orthogonal                 0.0001                 0.0001   \n",
       "0           orthogonal                 0.0001                 0.0001   \n",
       "52          orthogonal                 0.0001                 0.0001   \n",
       "28          orthogonal                 0.0001                 0.0001   \n",
       "16          orthogonal                 0.0001                 0.0001   \n",
       "22          orthogonal                 0.0001                 0.0001   \n",
       "31          orthogonal                 0.0001                 0.0001   \n",
       "24          orthogonal                 0.0001                 0.0001   \n",
       "2           orthogonal                 0.0001                 0.0001   \n",
       "30          orthogonal                 0.0001                 0.0001   \n",
       "15          orthogonal                 0.0001                 0.0001   \n",
       "6           orthogonal                 0.0001                 0.0001   \n",
       "23          orthogonal                 0.0001                 0.0001   \n",
       "11          orthogonal                 0.0001                 0.0001   \n",
       "19          orthogonal                 0.0001                 0.0001   \n",
       "21          orthogonal                 0.0001                 0.0001   \n",
       "45          orthogonal                 0.0001                 0.0001   \n",
       "12          orthogonal                 0.0001                 0.0001   \n",
       "4           orthogonal                 0.0001                 0.0001   \n",
       "42          orthogonal                 0.0001                 0.0001   \n",
       "33          orthogonal                 0.0001                 0.0001   \n",
       "3           orthogonal                 0.0001                 0.0001   \n",
       "5           orthogonal                 0.0001                 0.0001   \n",
       "29          orthogonal                 0.0001                 0.0001   \n",
       "18          orthogonal                 0.0001                 0.0001   \n",
       "9           orthogonal                 0.0001                 0.0001   \n",
       "49          orthogonal                 0.0001                 0.0001   \n",
       "40          orthogonal                 0.0001                 0.0001   \n",
       "41          orthogonal                 0.0001                 0.0001   \n",
       "10          orthogonal                 0.0001                 0.0001   \n",
       "20          orthogonal                 0.0001                 0.0001   \n",
       "51          orthogonal                 0.0001                 0.0001   \n",
       "48          orthogonal                 0.0001                 0.0001   \n",
       "\n",
       "   last_activation     lr  \n",
       "36         sigmoid  0.001  \n",
       "27         sigmoid  0.001  \n",
       "46         sigmoid  0.001  \n",
       "39         sigmoid  0.001  \n",
       "37         sigmoid  0.001  \n",
       "43         sigmoid  0.001  \n",
       "38         sigmoid  0.001  \n",
       "47         sigmoid  0.001  \n",
       "44         sigmoid  0.001  \n",
       "53         sigmoid  0.001  \n",
       "35         sigmoid  0.001  \n",
       "34         sigmoid  0.001  \n",
       "13         sigmoid  0.001  \n",
       "14         sigmoid  0.001  \n",
       "26         sigmoid  0.001  \n",
       "32         sigmoid  0.001  \n",
       "1          sigmoid  0.001  \n",
       "8          sigmoid  0.001  \n",
       "17         sigmoid  0.001  \n",
       "50         sigmoid  0.001  \n",
       "7          sigmoid  0.001  \n",
       "25         sigmoid  0.001  \n",
       "0          sigmoid  0.001  \n",
       "52         sigmoid  0.001  \n",
       "28         sigmoid  0.001  \n",
       "16         sigmoid  0.001  \n",
       "22         sigmoid  0.001  \n",
       "31         sigmoid  0.001  \n",
       "24         sigmoid  0.001  \n",
       "2          sigmoid  0.001  \n",
       "30         sigmoid  0.001  \n",
       "15         sigmoid  0.001  \n",
       "6          sigmoid  0.001  \n",
       "23         sigmoid  0.001  \n",
       "11         sigmoid  0.001  \n",
       "19         sigmoid  0.001  \n",
       "21         sigmoid  0.001  \n",
       "45         sigmoid  0.001  \n",
       "12         sigmoid  0.001  \n",
       "4          sigmoid  0.001  \n",
       "42         sigmoid  0.001  \n",
       "33         sigmoid  0.001  \n",
       "3          sigmoid  0.001  \n",
       "5          sigmoid  0.001  \n",
       "29         sigmoid  0.001  \n",
       "18         sigmoid  0.001  \n",
       "9          sigmoid  0.001  \n",
       "49         sigmoid  0.001  \n",
       "40         sigmoid  0.001  \n",
       "41         sigmoid  0.001  \n",
       "10         sigmoid  0.001  \n",
       "20         sigmoid  0.001  \n",
       "51         sigmoid  0.001  \n",
       "48         sigmoid  0.001  \n",
       "\n",
       "[54 rows x 23 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "997676de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of hidden_layers')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'hidden_layers'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "178079c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of batch_size')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'batch_size'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "34b014ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of dropout')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'dropout'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3d26e6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of batc_normalization')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'batc_normalization'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250767e",
   "metadata": {},
   "source": [
    "## Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f733338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron':[55],  #Done\n",
    "     'hidden_neuron':[50], #Done\n",
    "\n",
    "     'hidden_layers':[1], #Done  \n",
    "\n",
    "     \n",
    "    'epochs': [100000], # never touch it\n",
    "\n",
    "\n",
    "    'last_activation': ['sigmoid'], #never touch it\n",
    "\n",
    "\n",
    "    'batch_size': [64], #Done\n",
    "\n",
    "    'lr':[0.001,0.0001,0.00001],\n",
    "    \n",
    "    'kernel_regularizer_l1':[0.0001],#[0,0.001,0.0001],\n",
    "    'kernel_regularizer_l2':[0.0001],#[0,0.001,0.0001],\n",
    "    'bias_regularizer':[0.0001],#[0,0.001,0.0001],\n",
    "    'activity_regularizer':[0.0001],#[0,0.001,0.0001],\n",
    "\n",
    "    #'dropout': [0,0.1,0.2,0.3,0.4],\n",
    "    'dropout': [0],\n",
    "    \n",
    "  \n",
    "    'kernel_initializer': ['orthogonal','identity','zeros','ones','uniform'],\n",
    "\n",
    "    'activation_layer':['sigmoid','tanh','selu','elu','relu'],\n",
    " \n",
    "    'batc_normalization':[False], #Done\n",
    " \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9725295c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 3095.\n",
      "Epoch 03145: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 15%|████████████                                                                      | 11/75 [03:27<47:43, 44.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'sigmoid', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B54DE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98963A438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 13306.\n",
      "Epoch 13356: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 16%|████████████▋                                                                  | 12/75 [10:04<2:39:34, 151.97s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'sigmoid', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98EB8FEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98B54DF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 00059: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 17%|█████████████▋                                                                 | 13/75 [10:08<1:50:37, 107.06s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'sigmoid', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9FC8810D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98963A438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Epoch 00114: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 19%|██████████████▉                                                                 | 14/75 [10:13<1:17:36, 76.33s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'sigmoid', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98970C8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98963A828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|████████████████▍                                                                 | 15/75 [10:16<54:22, 54.37s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98963ADC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9FE1C2B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 135.\n",
      "Epoch 00185: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 21%|█████████████████▍                                                                | 16/75 [10:24<39:33, 40.24s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9FDAD8318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D37D3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 23%|██████████████████▌                                                               | 17/75 [10:27<28:12, 29.19s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99151B168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A997E67EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Epoch 00127: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 24%|███████████████████▋                                                              | 18/75 [10:33<21:01, 22.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98EB8FEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99DBEB3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 142.\n",
      "Epoch 00192: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|████████████████████▊                                                             | 19/75 [10:41<16:35, 17.78s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B54DC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99DBEB0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 103.\n",
      "Epoch 00153: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 27%|█████████████████████▊                                                            | 20/75 [10:47<13:10, 14.37s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99DBEB9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9FE1C25E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 138.\n",
      "Epoch 00188: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|██████████████████████▉                                                           | 21/75 [10:55<11:03, 12.29s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D37D0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9881EDCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 29%|████████████████████████                                                          | 22/75 [10:58<08:31,  9.65s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D37DDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98A239B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 31%|█████████████████████████▏                                                        | 23/75 [11:02<06:44,  7.79s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98EB22D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99DBEB558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 32%|██████████████████████████▏                                                       | 24/75 [11:05<05:31,  6.49s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A996AA5168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99DBEB8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1885.\n",
      "Epoch 01935: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 33%|███████████████████████████▎                                                      | 25/75 [12:04<18:25, 22.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A994351798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98970CD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 3081.\n",
      "Epoch 03131: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 35%|████████████████████████████▍                                                     | 26/75 [13:37<35:38, 43.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9917DF5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99DBEB8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 13357.\n",
      "Epoch 13407: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 36%|████████████████████████████▍                                                  | 27/75 [20:11<1:58:55, 148.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D5EE798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99DBEB3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 00058: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 37%|█████████████████████████████▍                                                 | 28/75 [20:15<1:22:22, 105.17s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9943519D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CDE35E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Epoch 00122: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 39%|███████████████████████████████▋                                                  | 29/75 [20:20<57:43, 75.29s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98EB8F8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9FE1C2C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|████████████████████████████████▊                                                 | 30/75 [20:24<40:18, 53.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98717F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9943519D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 123.\n",
      "Epoch 00173: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 41%|█████████████████████████████████▉                                                | 31/75 [20:31<29:08, 39.73s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A993FFAD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98963A0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 43%|██████████████████████████████████▉                                               | 32/75 [20:34<20:40, 28.86s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B54D0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99B6145E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 44%|████████████████████████████████████                                              | 33/75 [20:38<14:52, 21.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9942D7798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98BB5DC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 159.\n",
      "Epoch 00209: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|█████████████████████████████████████▏                                            | 34/75 [20:46<11:49, 17.30s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99B614678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9FE1C24C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Epoch 00148: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 47%|██████████████████████████████████████▎                                           | 35/75 [20:52<09:20, 14.01s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98EB8F8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9917DF948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 153.\n",
      "Epoch 00203: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 48%|███████████████████████████████████████▎                                          | 36/75 [21:00<07:54, 12.18s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CEA6318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CDE39D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 49%|████████████████████████████████████████▍                                         | 37/75 [21:04<06:03,  9.57s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9FF5310D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9FDAD8318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 51%|█████████████████████████████████████████▌                                        | 38/75 [21:07<04:46,  7.75s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997B24168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98B54DD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 52%|██████████████████████████████████████████▋                                       | 39/75 [21:11<03:53,  6.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98717F318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D5EEF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1774.\n",
      "Epoch 01824: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 53%|███████████████████████████████████████████▋                                      | 40/75 [22:06<12:16, 21.04s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B54D828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9881ED948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 3060.\n",
      "Epoch 03110: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 55%|████████████████████████████████████████████▊                                     | 41/75 [23:38<24:02, 42.43s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98963A438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CC15288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 13302.\n",
      "Epoch 13352: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 56%|████████████████████████████████████████████▏                                  | 42/75 [30:14<1:21:40, 148.50s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9FF531DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98A2395E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 00057: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 57%|██████████████████████████████████████████████▍                                  | 43/75 [30:18<56:01, 105.05s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A993FFAD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CDE3678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Epoch 00128: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 59%|████████████████████████████████████████████████                                  | 44/75 [30:23<38:52, 75.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D37D948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99DBEB318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|█████████████████████████████████████████████████▏                                | 45/75 [30:27<26:51, 53.72s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997D0FC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99408D288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Epoch 00105: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 61%|██████████████████████████████████████████████████▎                               | 46/75 [30:32<18:54, 39.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9FC881678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D5EEDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Epoch 00143: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 63%|███████████████████████████████████████████████████▍                              | 47/75 [30:38<13:38, 29.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98970CD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D5EEF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 103.\n",
      "Epoch 00153: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 64%|████████████████████████████████████████████████████▍                             | 48/75 [30:45<10:04, 22.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B54DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98963A048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 143.\n",
      "Epoch 00193: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|█████████████████████████████████████████████████████▌                            | 49/75 [30:52<07:46, 17.96s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B54D1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99DBEB5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 114.\n",
      "Epoch 00164: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 50/75 [30:59<06:05, 14.61s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9916FFEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D5EEF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 134.\n",
      "Epoch 00184: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|███████████████████████████████████████████████████████▊                          | 51/75 [31:06<04:58, 12.43s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98963ACA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9881ED288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|████████████████████████████████████████████████████████▊                         | 52/75 [31:10<03:44,  9.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9FE09EE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98CDE3828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 71%|█████████████████████████████████████████████████████████▉                        | 53/75 [31:13<02:53,  7.86s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9943519D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99408DA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 72%|███████████████████████████████████████████████████████████                       | 54/75 [31:17<02:17,  6.56s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9929915E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9FC80F288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1871.\n",
      "Epoch 01921: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 73%|████████████████████████████████████████████████████████████▏                     | 55/75 [32:15<07:22, 22.12s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B672CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98B54D9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 3065.\n",
      "Epoch 03115: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 75%|█████████████████████████████████████████████████████████████▏                    | 56/75 [33:49<13:46, 43.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98EB8F9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A997B249D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 13324.\n",
      "Epoch 13374: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 76%|█████████████████████████████████████████████████████████████▌                   | 57/75 [40:24<44:41, 148.96s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9941E3C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A997B240D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 00058: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 77%|██████████████████████████████████████████████████████████████▋                  | 58/75 [40:27<29:51, 105.39s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98B6721F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9941E3EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Epoch 00108: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 79%|████████████████████████████████████████████████████████████████▌                 | 59/75 [40:33<20:05, 75.33s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'elu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997B24828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9FC80F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 60/75 [40:36<13:26, 53.80s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9881EDCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9941E3EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 109.\n",
      "Epoch 00159: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 61/75 [40:43<09:15, 39.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98717F828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98B672B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 83%|███████████████████████████████████████████████████████████████████▊              | 62/75 [40:46<06:14, 28.81s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'orthogonal', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9941E3E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98963AF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 63/75 [40:50<04:14, 21.22s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98BB5DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98717FF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 00067: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 85%|█████████████████████████████████████████████████████████████████████▉            | 64/75 [40:54<02:56, 16.05s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98963AD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99933BD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 112.\n",
      "Epoch 00162: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 87%|███████████████████████████████████████████████████████████████████████           | 65/75 [41:01<02:12, 13.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98963A558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99933B318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 152.\n",
      "Epoch 00202: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 66/75 [41:08<01:44, 11.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A996926C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98963A048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 89%|█████████████████████████████████████████████████████████████████████████▎        | 67/75 [41:12<01:13,  9.19s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A99933B828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A99DBEB3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▎       | 68/75 [41:15<00:52,  7.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'zeros', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98970CA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A996A3A3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 69/75 [41:19<00:37,  6.30s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98963AE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98970C828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1891.\n",
      "Epoch 01941: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▌     | 70/75 [42:18<01:50, 22.00s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A9881ED288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98D5EEE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 3072.\n",
      "Epoch 03122: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▋    | 71/75 [43:51<02:53, 43.34s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'ones', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98CC15948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A996A3A9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 13305.\n",
      "Epoch 13355: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████▊   | 72/75 [50:24<07:25, 148.41s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A98D016828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A98970C798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 00060: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████▊  | 73/75 [50:28<03:30, 105.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A996926E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9917DF4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Epoch 00108: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 99%|████████████████████████████████████████████████████████████████████████████████▉ | 74/75 [50:33<01:15, 75.07s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'relu', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'uniform', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 1e-05}\n",
      "adding layer 1\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002A997C6A318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002A9969260D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [50:37<00:00, 40.50s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=train_df, y=train_label,\n",
    "            x_val=test_df, y_val=test_label,\n",
    "            model=numerai_model,\n",
    "            params=p,  \n",
    "            experiment_name='Predykcja klasy M - Weighted binary cross-entropy (nowe)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6c5eb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/STUDIA/ROK_II/Magisterka/Modele/Dane pierwotne/M/Predykcja klasy M - Weighted binary cross-entropy (nowe)/050722004321.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e8b0e981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>0.592331</td>\n",
       "      <td>[0.36585367]</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.658958</td>\n",
       "      <td>[0.4]</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181</td>\n",
       "      <td>0.677652</td>\n",
       "      <td>[0.31716418]</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.710377</td>\n",
       "      <td>[0.29850748]</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>0.748390</td>\n",
       "      <td>[0.29038113]</td>\n",
       "      <td>0.172043</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.767352</td>\n",
       "      <td>[0.2898551]</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>0.627819</td>\n",
       "      <td>[0.31439397]</td>\n",
       "      <td>0.187783</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.661901</td>\n",
       "      <td>[0.28571427]</td>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "      <td>0.672291</td>\n",
       "      <td>[0.28975263]</td>\n",
       "      <td>0.170833</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.670327</td>\n",
       "      <td>[0.3007519]</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3122</td>\n",
       "      <td>0.749368</td>\n",
       "      <td>[0.26153845]</td>\n",
       "      <td>0.150709</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.752426</td>\n",
       "      <td>[0.26993865]</td>\n",
       "      <td>0.156028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>ones</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>13355</td>\n",
       "      <td>0.896214</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.822566</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>ones</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>60</td>\n",
       "      <td>0.611656</td>\n",
       "      <td>[0.31119546]</td>\n",
       "      <td>0.185941</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.694541</td>\n",
       "      <td>[0.2962963]</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>108</td>\n",
       "      <td>0.642046</td>\n",
       "      <td>[0.3016158]</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.654796</td>\n",
       "      <td>[0.29197082]</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>51</td>\n",
       "      <td>0.713911</td>\n",
       "      <td>[0.2643857]</td>\n",
       "      <td>0.152603</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.715935</td>\n",
       "      <td>[0.27329195]</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "0            141  0.592331  [0.36585367]   0.247934  0.697674  0.658958   \n",
       "1            181  0.677652  [0.31716418]   0.188889  0.988372  0.710377   \n",
       "2            206  0.748390  [0.29038113]   0.172043  0.930233  0.767352   \n",
       "3             67  0.627819  [0.31439397]   0.187783  0.965116  0.661901   \n",
       "4            137  0.672291  [0.28975263]   0.170833  0.953488  0.670327   \n",
       "..           ...       ...           ...        ...       ...       ...   \n",
       "70          3122  0.749368  [0.26153845]   0.150709  0.988372  0.752426   \n",
       "71         13355  0.896214          [0.]   0.000000  0.000000  0.822566   \n",
       "72            60  0.611656  [0.31119546]   0.185941  0.953488  0.694541   \n",
       "73           108  0.642046   [0.3016158]   0.178344  0.976744  0.654796   \n",
       "74            51  0.713911   [0.2643857]   0.152603  0.988372  0.715935   \n",
       "\n",
       "   val_fbeta_score  val_precision  val_recall activation_layer  ...  dropout  \\\n",
       "0            [0.4]       0.444444    0.363636          sigmoid  ...        0   \n",
       "1     [0.29850748]       0.178571    0.909091          sigmoid  ...        0   \n",
       "2      [0.2898551]       0.172414    0.909091          sigmoid  ...        0   \n",
       "3     [0.28571427]       0.180723    0.681818          sigmoid  ...        0   \n",
       "4      [0.3007519]       0.180180    0.909091          sigmoid  ...        0   \n",
       "..             ...            ...         ...              ...  ...      ...   \n",
       "70    [0.26993865]       0.156028    1.000000             relu  ...        0   \n",
       "71            [0.]       0.000000    0.000000             relu  ...        0   \n",
       "72     [0.2962963]       0.176991    0.909091             relu  ...        0   \n",
       "73    [0.29197082]       0.173913    0.909091             relu  ...        0   \n",
       "74    [0.27329195]       0.158273    1.000000             relu  ...        0   \n",
       "\n",
       "    epochs  first_neuron  hidden_layers  hidden_neuron  kernel_initializer  \\\n",
       "0   100000            55              1             50          orthogonal   \n",
       "1   100000            55              1             50          orthogonal   \n",
       "2   100000            55              1             50          orthogonal   \n",
       "3   100000            55              1             50            identity   \n",
       "4   100000            55              1             50            identity   \n",
       "..     ...           ...            ...            ...                 ...   \n",
       "70  100000            55              1             50                ones   \n",
       "71  100000            55              1             50                ones   \n",
       "72  100000            55              1             50             uniform   \n",
       "73  100000            55              1             50             uniform   \n",
       "74  100000            55              1             50             uniform   \n",
       "\n",
       "    kernel_regularizer_l1  kernel_regularizer_l2  last_activation       lr  \n",
       "0                  0.0001                 0.0001          sigmoid  0.00100  \n",
       "1                  0.0001                 0.0001          sigmoid  0.00010  \n",
       "2                  0.0001                 0.0001          sigmoid  0.00001  \n",
       "3                  0.0001                 0.0001          sigmoid  0.00100  \n",
       "4                  0.0001                 0.0001          sigmoid  0.00010  \n",
       "..                    ...                    ...              ...      ...  \n",
       "70                 0.0001                 0.0001          sigmoid  0.00010  \n",
       "71                 0.0001                 0.0001          sigmoid  0.00001  \n",
       "72                 0.0001                 0.0001          sigmoid  0.00100  \n",
       "73                 0.0001                 0.0001          sigmoid  0.00010  \n",
       "74                 0.0001                 0.0001          sigmoid  0.00001  \n",
       "\n",
       "[75 rows x 24 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8870ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values('val_loss',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bf46a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stare_wart=df['val_fbeta_score']\n",
    "nowe_wart=[]\n",
    "for x in stare_wart:\n",
    "    wart=x.replace('[','')\n",
    "    wart=wart.replace(']','')\n",
    "    wart=float(wart)\n",
    "    nowe_wart.append(wart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c0de7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['val_fbeta_score']=nowe_wart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1fe1f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13356</td>\n",
       "      <td>0.896150</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.822645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>ones</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>13355</td>\n",
       "      <td>0.896214</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.822566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>ones</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>13352</td>\n",
       "      <td>0.895954</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.822309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>selu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>ones</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>13374</td>\n",
       "      <td>0.892291</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>elu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>ones</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13407</td>\n",
       "      <td>0.886114</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.813588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>ones</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>192</td>\n",
       "      <td>0.560562</td>\n",
       "      <td>[0.41447368]</td>\n",
       "      <td>0.288991</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.608270</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>173</td>\n",
       "      <td>0.569226</td>\n",
       "      <td>[0.3806452]</td>\n",
       "      <td>0.263393</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.586448</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>selu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>193</td>\n",
       "      <td>0.554448</td>\n",
       "      <td>[0.4164038]</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.560349</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>elu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>209</td>\n",
       "      <td>0.544065</td>\n",
       "      <td>[0.4043127]</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.541987</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>selu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>185</td>\n",
       "      <td>0.565713</td>\n",
       "      <td>[0.40701756]</td>\n",
       "      <td>0.291457</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.530179</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>orthogonal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "11         13356  0.896150          [0.]   0.000000  0.000000  0.822645   \n",
       "71         13355  0.896214          [0.]   0.000000  0.000000  0.822566   \n",
       "41         13352  0.895954          [0.]   0.000000  0.000000  0.822309   \n",
       "56         13374  0.892291          [0.]   0.000000  0.000000  0.818881   \n",
       "26         13407  0.886114          [0.]   0.000000  0.000000  0.813588   \n",
       "..           ...       ...           ...        ...       ...       ...   \n",
       "18           192  0.560562  [0.41447368]   0.288991  0.732558  0.608270   \n",
       "30           173  0.569226   [0.3806452]   0.263393  0.686047  0.586448   \n",
       "48           193  0.554448   [0.4164038]   0.285714  0.767442  0.560349   \n",
       "33           209  0.544065   [0.4043127]   0.263158  0.872093  0.541987   \n",
       "15           185  0.565713  [0.40701756]   0.291457  0.674419  0.530179   \n",
       "\n",
       "    val_fbeta_score  val_precision  val_recall activation_layer  ...  dropout  \\\n",
       "11         0.000000       0.000000    0.000000          sigmoid  ...        0   \n",
       "71         0.000000       0.000000    0.000000             relu  ...        0   \n",
       "41         0.000000       0.000000    0.000000             selu  ...        0   \n",
       "56         0.000000       0.000000    0.000000              elu  ...        0   \n",
       "26         0.000000       0.000000    0.000000             tanh  ...        0   \n",
       "..              ...            ...         ...              ...  ...      ...   \n",
       "18         0.350000       0.388889    0.318182             tanh  ...        0   \n",
       "30         0.250000       0.400000    0.181818             selu  ...        0   \n",
       "48         0.368421       0.437500    0.318182              elu  ...        0   \n",
       "33         0.388889       0.500000    0.318182             selu  ...        0   \n",
       "15         0.235294       0.333333    0.181818             tanh  ...        0   \n",
       "\n",
       "    epochs  first_neuron  hidden_layers  hidden_neuron  kernel_initializer  \\\n",
       "11  100000            55              1             50                ones   \n",
       "71  100000            55              1             50                ones   \n",
       "41  100000            55              1             50                ones   \n",
       "56  100000            55              1             50                ones   \n",
       "26  100000            55              1             50                ones   \n",
       "..     ...           ...            ...            ...                 ...   \n",
       "18  100000            55              1             50            identity   \n",
       "30  100000            55              1             50          orthogonal   \n",
       "48  100000            55              1             50            identity   \n",
       "33  100000            55              1             50            identity   \n",
       "15  100000            55              1             50          orthogonal   \n",
       "\n",
       "    kernel_regularizer_l1  kernel_regularizer_l2  last_activation       lr  \n",
       "11                 0.0001                 0.0001          sigmoid  0.00001  \n",
       "71                 0.0001                 0.0001          sigmoid  0.00001  \n",
       "41                 0.0001                 0.0001          sigmoid  0.00001  \n",
       "56                 0.0001                 0.0001          sigmoid  0.00001  \n",
       "26                 0.0001                 0.0001          sigmoid  0.00001  \n",
       "..                    ...                    ...              ...      ...  \n",
       "18                 0.0001                 0.0001          sigmoid  0.00100  \n",
       "30                 0.0001                 0.0001          sigmoid  0.00100  \n",
       "48                 0.0001                 0.0001          sigmoid  0.00100  \n",
       "33                 0.0001                 0.0001          sigmoid  0.00100  \n",
       "15                 0.0001                 0.0001          sigmoid  0.00100  \n",
       "\n",
       "[75 rows x 24 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "caa23a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of kernel_initializer')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_initializer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ac4ac88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of activation_layer')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'activation_layer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2f800331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of lr')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'lr'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1d8f2",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7122ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def numerai_model(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    print(params)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    ## initial layer\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1],\n",
    "                    activation='relu',\n",
    "               \n",
    "                    kernel_initializer = params['kernel_initializer'],\n",
    "                    kernel_regularizer=keras.regularizers.l1_l2(l1=params['kernel_regularizer_l1'],\n",
    "                                                                l2=params['kernel_regularizer_l2']),\n",
    "                    bias_regularizer=keras.regularizers.l2(params['bias_regularizer']),\n",
    "                    activity_regularizer=keras.regularizers.l2(params['activity_regularizer'])\n",
    "                   ))\n",
    "    if params['batc_normalization']==True:\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "    if params['dropout']!=0:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    ## hidden layers\n",
    "    for i in range(params['hidden_layers']):\n",
    "        print (f\"adding layer {i+1}\")\n",
    "        model.add(Dense(params['hidden_neuron'], activation='relu',\n",
    "                    kernel_initializer=params['kernel_initializer'],\n",
    "                        kernel_regularizer=keras.regularizers.l1_l2(l1=params['kernel_regularizer_l1'],\n",
    "                                                                    l2=params['kernel_regularizer_l2']),\n",
    "                    bias_regularizer=keras.regularizers.l2(params['bias_regularizer']),\n",
    "                    activity_regularizer=keras.regularizers.l2(params['activity_regularizer'])\n",
    "                       ))\n",
    "        if params['batc_normalization']==True:\n",
    "            model.add(BatchNormalization())\n",
    "            \n",
    "        if params['dropout']!=0:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    \n",
    "    ## final layer\n",
    "    model.add(Dense(1, activation=params['last_activation'],\n",
    "                    kernel_initializer=params['kernel_initializer'],\n",
    "                   kernel_regularizer=keras.regularizers.l1_l2(l1=params['kernel_regularizer_l1'],\n",
    "                                                               l2=params['kernel_regularizer_l2']),\n",
    "                    bias_regularizer=keras.regularizers.l2(params['bias_regularizer']),\n",
    "                    activity_regularizer=keras.regularizers.l2(params['activity_regularizer'])\n",
    "                   ))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=params['lr']),\n",
    "                  metrics=[tfa.metrics.FBetaScore(num_classes=1, beta=1.0, threshold=0.5),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),])\n",
    "  \n",
    "  \n",
    "    history = model.fit(x_train, y_train, \n",
    "                        validation_data=[x_val, y_val],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        epochs=params['epochs'],\n",
    "                        verbose=0,\n",
    "                        class_weight={0 : 0.58921162,\n",
    "                                      1 : 3.30232558},\n",
    "                        callbacks = [\n",
    "                                     EarlyStopping(monitor='val_loss',\n",
    "                                        min_delta=0.01,\n",
    "                                        patience=50, mode='min',verbose=1,\n",
    "                                                      restore_best_weights=True)\n",
    "                                    ] #,ta.live(),\n",
    "                        )\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07c695af",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron':[55],  #Done\n",
    "     'hidden_neuron':[50], #Done\n",
    "\n",
    "     'hidden_layers':[1], #Done  \n",
    "\n",
    "     \n",
    "    'epochs': [100000], # never touch it\n",
    "\n",
    "\n",
    "    'last_activation': ['sigmoid'], #never touch it\n",
    "\n",
    "\n",
    "    'batch_size': [64], #Done\n",
    "\n",
    "    'lr':[0.01,0.001,0.0001],\n",
    "    \n",
    "    'kernel_regularizer_l1':[0,0.001,0.0001],\n",
    "    'kernel_regularizer_l2':[0,0.001,0.0001],\n",
    "    'bias_regularizer':[0,0.001,0.0001],\n",
    "    'activity_regularizer':[0,0.001,0.0001],\n",
    "\n",
    "  #  'dropout': [0,0.1,0.2,0.3,0.4],\n",
    "  'dropout': [0,0.1],\n",
    "\n",
    "  \n",
    "    'kernel_initializer': ['identity'],\n",
    "\n",
    "    'activation_layer':['tanh'],\n",
    " \n",
    "    'batc_normalization':[False], #Done\n",
    " \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad9b0b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/486 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Epoch 83: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                                 | 1/486 [00:06<55:48,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 68: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                 | 2/486 [00:11<46:23,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 109.\n",
      "Epoch 159: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                                                                 | 3/486 [00:19<54:43,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 81: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                                 | 4/486 [00:24<49:03,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 143.\n",
      "Epoch 193: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                                 | 5/486 [00:34<58:24,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 137.\n",
      "Epoch 187: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                               | 6/486 [00:43<1:04:10,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 63: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▏                                                                                | 7/486 [00:47<54:08,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 143.\n",
      "Epoch 193: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                              | 8/486 [00:58<1:03:51,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Epoch 136: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▍                                                                              | 9/486 [01:07<1:04:55,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                               | 10/486 [01:12<58:27,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 111.\n",
      "Epoch 161: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▊                                                                             | 11/486 [01:21<1:00:53,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Epoch 92: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██                                                                               | 12/486 [01:26<55:50,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 67: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▏                                                                              | 13/486 [01:31<51:06,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 129.\n",
      "Epoch 179: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                              | 14/486 [01:41<58:00,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 321.\n",
      "Epoch 371: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                            | 15/486 [01:58<1:20:43, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 64: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                            | 16/486 [02:02<1:06:52,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 124.\n",
      "Epoch 174: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▊                                                                            | 17/486 [02:11<1:07:34,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Epoch 108: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▉                                                                            | 18/486 [02:18<1:01:50,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 72: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                             | 19/486 [02:22<54:03,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 73: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                             | 20/486 [02:27<48:45,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Epoch 126: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▌                                                                             | 21/486 [02:34<50:20,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Epoch 100: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▋                                                                             | 22/486 [02:40<49:38,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 72: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▊                                                                             | 23/486 [02:47<49:31,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 144.\n",
      "Epoch 194: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████                                                                             | 24/486 [02:57<59:27,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Epoch 56: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▏                                                                            | 25/486 [03:01<50:59,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Epoch 62: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▎                                                                            | 26/486 [03:06<45:52,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Epoch 131: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▌                                                                            | 27/486 [03:13<48:54,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 71: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                            | 28/486 [03:18<45:18,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Epoch 69: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                            | 29/486 [03:24<44:56,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Epoch 148: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████                                                                            | 30/486 [03:32<49:38,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 79: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▏                                                                           | 31/486 [03:37<46:22,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 71: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▎                                                                           | 32/486 [03:42<43:28,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 154.\n",
      "Epoch 204: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▌                                                                           | 33/486 [03:53<54:14,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 58: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▋                                                                           | 34/486 [03:57<47:40,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 82: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▊                                                                           | 35/486 [04:02<45:31,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Epoch 148: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████                                                                           | 36/486 [04:14<57:54,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Epoch 91: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▏                                                                          | 37/486 [04:20<53:40,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 108.\n",
      "Epoch 158: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▎                                                                          | 38/486 [04:28<56:38,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Epoch 89: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▌                                                                          | 39/486 [04:34<52:47,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                          | 40/486 [04:39<48:00,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 138.\n",
      "Epoch 188: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▊                                                                          | 41/486 [04:49<55:44,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 279.\n",
      "Epoch 329: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████▊                                                                        | 42/486 [05:05<1:14:31, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Epoch 88: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████▉                                                                        | 43/486 [05:11<1:04:43,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 121.\n",
      "Epoch 171: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▏                                                                       | 44/486 [05:21<1:06:36,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 80: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▌                                                                         | 45/486 [05:26<59:04,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 63: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▋                                                                         | 46/486 [05:31<51:31,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Epoch 93: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▊                                                                         | 47/486 [05:38<50:27,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Epoch 130: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 48/486 [05:45<51:32,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 68: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▏                                                                        | 49/486 [05:50<46:29,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 225.\n",
      "Epoch 275: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▏                                                                      | 50/486 [06:04<1:02:30,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 140.\n",
      "Epoch 190: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                      | 51/486 [06:14<1:05:33,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Epoch 66: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▋                                                                        | 52/486 [06:19<56:23,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 61: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▊                                                                        | 53/486 [06:23<49:21,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Epoch 135: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████                                                                        | 54/486 [06:31<51:14,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 58: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▏                                                                       | 55/486 [06:37<49:23,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 68: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▎                                                                       | 56/486 [06:42<44:04,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 101.\n",
      "Epoch 151: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▌                                                                       | 57/486 [06:50<47:58,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 73: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▋                                                                       | 58/486 [06:55<44:17,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 185.\n",
      "Epoch 235: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▊                                                                       | 59/486 [07:08<58:32,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 120.\n",
      "Epoch 170: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▊                                                                     | 60/486 [07:19<1:05:09,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 79: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▏                                                                      | 61/486 [07:24<55:45,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Epoch 66: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▎                                                                      | 62/486 [07:29<49:21,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Epoch 121: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▌                                                                      | 63/486 [07:36<49:23,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 80: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▋                                                                      | 64/486 [07:42<48:04,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 128.\n",
      "Epoch 178: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▊                                                                      | 65/486 [07:52<53:51,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Epoch 124: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████                                                                      | 66/486 [07:58<51:17,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 77: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▏                                                                     | 67/486 [08:03<45:53,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 143.\n",
      "Epoch 193: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                     | 68/486 [08:13<51:16,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 327.\n",
      "Epoch 377: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▏                                                                   | 69/486 [08:29<1:09:45, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Epoch 113: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▍                                                                   | 70/486 [08:35<1:02:21,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Epoch 129: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▊                                                                     | 71/486 [08:42<56:58,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Epoch 122: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████                                                                     | 72/486 [08:48<52:14,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 52: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▏                                                                    | 73/486 [08:51<43:38,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 68: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▎                                                                    | 74/486 [08:56<39:19,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "Epoch 121: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▌                                                                    | 75/486 [09:02<40:18,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 63: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▋                                                                    | 76/486 [09:06<37:05,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Epoch 105: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▊                                                                    | 77/486 [09:12<38:00,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 123.\n",
      "Epoch 173: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████                                                                    | 78/486 [09:21<44:02,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 53: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▏                                                                   | 79/486 [09:25<39:02,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 61: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                   | 80/486 [09:29<35:49,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Epoch 141: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▌                                                                   | 81/486 [09:36<39:47,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 61: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▋                                                                   | 82/486 [09:41<36:36,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                   | 83/486 [09:45<34:37,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 126.\n",
      "Epoch 176: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████                                                                   | 84/486 [09:54<41:58,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 75: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████▏                                                                  | 85/486 [09:59<39:10,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Epoch 105: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▎                                                                  | 86/486 [10:05<39:40,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 149.\n",
      "Epoch 199: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▌                                                                  | 87/486 [10:15<47:31,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 81: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▋                                                                  | 88/486 [10:20<43:25,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 81: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▊                                                                  | 89/486 [10:25<40:17,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Epoch 149: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████                                                                  | 90/486 [10:33<43:30,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 79: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▏                                                                 | 91/486 [10:38<40:11,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Epoch 137: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▎                                                                 | 92/486 [10:45<42:40,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Epoch 104: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▌                                                                 | 93/486 [10:51<41:26,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 71: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▋                                                                 | 94/486 [10:56<38:24,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 147.\n",
      "Epoch 197: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                                 | 95/486 [11:06<46:10,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 268.\n",
      "Epoch 318: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▌                                                               | 96/486 [11:21<1:00:32,  9.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 72: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 97/486 [11:25<50:51,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 107.\n",
      "Epoch 157: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▎                                                                | 98/486 [11:33<50:33,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Epoch 125: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                | 99/486 [11:39<48:05,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▍                                                               | 100/486 [11:43<40:24,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 72: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▋                                                               | 101/486 [11:47<36:44,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Epoch 134: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▊                                                               | 102/486 [11:55<39:51,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Epoch 69: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▉                                                               | 103/486 [12:00<38:01,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Epoch 150: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████                                                               | 104/486 [12:08<42:40,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 170.\n",
      "Epoch 220: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▎                                                              | 105/486 [12:20<52:23,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 58: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▍                                                              | 106/486 [12:25<46:06,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 71: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▌                                                              | 107/486 [12:31<42:48,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 101.\n",
      "Epoch 151: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▊                                                              | 108/486 [12:40<46:04,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 55: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▉                                                              | 109/486 [12:46<44:19,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 121.\n",
      "Epoch 171: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████                                                              | 110/486 [12:55<47:34,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Epoch 128: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▎                                                             | 111/486 [13:02<45:53,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Epoch 126: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▍                                                             | 112/486 [13:08<44:11,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 140.\n",
      "Epoch 190: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▌                                                             | 113/486 [13:20<52:23,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Epoch 149: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▊                                                             | 114/486 [13:28<51:23,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 52: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████████████▉                                                             | 115/486 [13:32<44:44,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 114.\n",
      "Epoch 164: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████                                                             | 116/486 [13:42<48:39,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Epoch 131: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▎                                                            | 117/486 [13:50<48:57,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                            | 118/486 [13:55<42:39,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 101.\n",
      "Epoch 151: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▌                                                            | 119/486 [14:02<43:45,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Epoch 141: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████▊                                                            | 120/486 [14:09<43:14,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Epoch 64: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████▉                                                            | 121/486 [14:13<37:32,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 149.\n",
      "Epoch 199: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████                                                            | 122/486 [14:22<43:06,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 309.\n",
      "Epoch 359: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████▋                                                          | 123/486 [14:44<1:09:28, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Epoch 109: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▍                                                           | 124/486 [14:50<59:06,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 131.\n",
      "Epoch 181: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▌                                                           | 125/486 [14:59<56:57,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 188.\n",
      "Epoch 238: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▋                                                           | 126/486 [15:10<59:27,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Epoch 54: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▉                                                           | 127/486 [15:13<48:16,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                           | 128/486 [15:18<41:28,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Epoch 138: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▏                                                          | 129/486 [15:29<49:40,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Epoch 56: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▍                                                          | 130/486 [15:33<41:50,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 173.\n",
      "Epoch 223: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▌                                                          | 131/486 [15:43<47:02,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 175.\n",
      "Epoch 225: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▋                                                          | 132/486 [15:53<50:17,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Epoch 56: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▉                                                          | 133/486 [16:00<46:22,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Epoch 61: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████                                                          | 134/486 [16:04<39:44,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Epoch 134: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▏                                                         | 135/486 [16:11<40:09,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 67: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▍                                                         | 136/486 [16:15<35:40,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 73: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▌                                                         | 137/486 [16:20<33:13,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 106.\n",
      "Epoch 156: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                         | 138/486 [16:28<37:12,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 55: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██████████████████████▉                                                         | 139/486 [16:32<33:09,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 184.\n",
      "Epoch 234: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████                                                         | 140/486 [16:44<42:48,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 164.\n",
      "Epoch 214: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▏                                                        | 141/486 [16:54<47:58,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 52: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▎                                                        | 142/486 [16:59<41:38,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Epoch 86: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▌                                                        | 143/486 [17:05<39:36,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 141.\n",
      "Epoch 191: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▋                                                        | 144/486 [17:15<44:18,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Epoch 91: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▊                                                        | 145/486 [17:22<42:53,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 114.\n",
      "Epoch 164: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████                                                        | 146/486 [17:34<50:36,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Epoch 123: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▏                                                       | 147/486 [17:41<47:12,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 67: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                       | 148/486 [17:48<45:04,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 159.\n",
      "Epoch 209: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████▌                                                       | 149/486 [17:57<47:01,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 255.\n",
      "Epoch 305: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████▋                                                       | 150/486 [18:13<59:52, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Epoch 72: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████▊                                                       | 151/486 [18:18<49:00,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 125.\n",
      "Epoch 175: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████                                                       | 152/486 [18:28<52:04,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Epoch 105: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▏                                                      | 153/486 [18:35<47:06,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Epoch 58: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▎                                                      | 154/486 [18:41<43:40,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 67: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▌                                                      | 155/486 [18:48<40:59,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Epoch 149: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▋                                                      | 156/486 [18:56<41:57,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Epoch 65: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▊                                                      | 157/486 [19:01<37:12,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 152.\n",
      "Epoch 202: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████                                                      | 158/486 [19:12<45:15,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 115.\n",
      "Epoch 165: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▏                                                     | 159/486 [19:24<50:54,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▎                                                     | 160/486 [19:31<46:01,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "Epoch 78: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▌                                                     | 161/486 [19:36<40:15,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Epoch 128: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▋                                                     | 162/486 [19:48<47:18,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 55: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████████████▊                                                     | 163/486 [19:52<39:29,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Epoch 138: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████████████▉                                                     | 164/486 [20:03<46:13,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 180.\n",
      "Epoch 230: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▏                                                    | 165/486 [20:14<49:24,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 63: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▎                                                    | 166/486 [20:20<44:46,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 157.\n",
      "Epoch 207: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▍                                                    | 167/486 [20:31<47:37,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 162.\n",
      "Epoch 212: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████████████████▋                                                    | 168/486 [20:41<49:28,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 53: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████████████████▊                                                    | 169/486 [20:47<44:57,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Epoch 142: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████████████████▉                                                    | 170/486 [20:55<43:08,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 163.\n",
      "Epoch 213: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▏                                                   | 171/486 [21:06<47:11,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▎                                                   | 172/486 [21:12<42:47,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 132.\n",
      "Epoch 182: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▍                                                   | 173/486 [21:21<43:56,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 265.\n",
      "Epoch 315: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▋                                                   | 174/486 [21:34<50:44,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 71: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▊                                                   | 175/486 [21:38<41:34,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 206.\n",
      "Epoch 256: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▉                                                   | 176/486 [21:49<46:47,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 789.\n",
      "Epoch 839: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▍                                                 | 177/486 [22:20<1:20:42, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Epoch 69: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|████████████████████████████▌                                                 | 178/486 [22:24<1:02:22, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 101.\n",
      "Epoch 151: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▍                                                  | 179/486 [22:31<53:55, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 250.\n",
      "Epoch 300: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▋                                                  | 180/486 [22:43<56:03, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Epoch 83: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▊                                                  | 181/486 [22:47<45:43,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 137.\n",
      "Epoch 187: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▉                                                  | 182/486 [22:55<43:59,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 162.\n",
      "Epoch 212: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████                                                  | 183/486 [23:04<44:25,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Epoch 91: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▎                                                 | 184/486 [23:09<37:53,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 203.\n",
      "Epoch 253: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▍                                                 | 185/486 [23:19<41:42,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 218.\n",
      "Epoch 268: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▌                                                 | 186/486 [23:30<45:00,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 52: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▊                                                 | 187/486 [23:33<36:15,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 118.\n",
      "Epoch 168: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|██████████████████████████████▉                                                 | 188/486 [23:40<36:08,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 165.\n",
      "Epoch 215: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████                                                 | 189/486 [23:49<38:24,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 77: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▎                                                | 190/486 [23:53<32:51,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 112.\n",
      "Epoch 162: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▍                                                | 191/486 [24:00<33:29,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 165.\n",
      "Epoch 215: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▌                                                | 192/486 [24:10<36:39,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 158.\n",
      "Epoch 208: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▊                                                | 193/486 [24:18<38:38,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 122.\n",
      "Epoch 172: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▉                                                | 194/486 [24:26<37:58,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 183.\n",
      "Epoch 233: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                | 195/486 [24:36<40:32,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▎                                               | 196/486 [24:40<35:18,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 115.\n",
      "Epoch 165: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▍                                               | 197/486 [24:48<35:12,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 174.\n",
      "Epoch 224: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▌                                               | 198/486 [24:57<38:12,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 73: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▊                                               | 199/486 [25:01<32:29,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 103.\n",
      "Epoch 153: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▉                                               | 200/486 [25:08<32:29,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 193.\n",
      "Epoch 243: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████                                               | 201/486 [25:18<37:05,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Epoch 95: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▎                                              | 202/486 [25:23<32:49,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 174.\n",
      "Epoch 224: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▍                                              | 203/486 [25:33<36:32,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 595.\n",
      "Epoch 645: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████████████████████████████████▋                                             | 204/486 [25:58<1:00:23, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 103.\n",
      "Epoch 153: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▋                                              | 205/486 [26:05<52:05, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 111.\n",
      "Epoch 161: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▉                                              | 206/486 [26:12<46:33,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 183.\n",
      "Epoch 233: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████                                              | 207/486 [26:22<46:18,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 55: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▏                                             | 208/486 [26:25<37:04,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 194.\n",
      "Epoch 244: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▍                                             | 209/486 [26:36<39:54,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 177.\n",
      "Epoch 227: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▌                                             | 210/486 [26:45<40:55,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Epoch 118: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▋                                             | 211/486 [26:51<36:25,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 229.\n",
      "Epoch 279: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████████████████████▉                                             | 212/486 [27:02<41:17,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 179.\n",
      "Epoch 229: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████                                             | 213/486 [27:14<44:14,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Epoch 54: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▏                                            | 214/486 [27:17<35:34,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 206.\n",
      "Epoch 256: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▍                                            | 215/486 [27:28<40:09,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 140.\n",
      "Epoch 190: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▌                                            | 216/486 [27:37<39:18,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 68: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████▋                                            | 217/486 [27:40<32:18,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Epoch 149: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████▉                                            | 218/486 [27:47<31:04,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 160.\n",
      "Epoch 210: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████                                            | 219/486 [27:55<32:53,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▏                                           | 220/486 [28:00<29:09,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 151.\n",
      "Epoch 201: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▍                                           | 221/486 [28:08<31:12,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 158.\n",
      "Epoch 208: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▌                                           | 222/486 [28:17<32:56,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 75: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▋                                           | 223/486 [28:21<28:08,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Epoch 108: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▊                                           | 224/486 [28:26<26:15,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 142.\n",
      "Epoch 192: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████                                           | 225/486 [28:33<28:38,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Epoch 113: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▏                                          | 226/486 [28:39<27:03,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 170.\n",
      "Epoch 220: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▎                                          | 227/486 [28:48<30:27,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 216.\n",
      "Epoch 266: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▌                                          | 228/486 [29:10<49:11, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Epoch 71: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▋                                          | 229/486 [29:14<39:26,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 147.\n",
      "Epoch 197: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▊                                          | 230/486 [29:22<38:15,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 788.\n",
      "Epoch 838: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|█████████████████████████████████████                                         | 231/486 [29:53<1:05:55, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 82: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▏                                         | 232/486 [29:57<51:33, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 120.\n",
      "Epoch 170: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▎                                         | 233/486 [30:05<45:33, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 242.\n",
      "Epoch 292: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▌                                         | 234/486 [30:17<46:35, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Epoch 65: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▋                                         | 235/486 [30:20<37:09,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 150.\n",
      "Epoch 200: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|██████████████████████████████████████▊                                         | 236/486 [30:32<39:59,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 160.\n",
      "Epoch 210: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████                                         | 237/486 [30:40<38:57,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Epoch 91: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▏                                        | 238/486 [30:45<32:57,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 121.\n",
      "Epoch 171: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▎                                        | 239/486 [30:53<32:20,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 216.\n",
      "Epoch 266: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▌                                        | 240/486 [31:03<35:51,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "Epoch 83: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▋                                        | 241/486 [31:08<30:24,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 151.\n",
      "Epoch 201: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▊                                        | 242/486 [31:16<31:40,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 156.\n",
      "Epoch 206: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                        | 243/486 [31:25<32:37,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 53: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▏                                       | 244/486 [31:29<26:48,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Epoch 123: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▎                                       | 245/486 [31:34<25:48,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 179.\n",
      "Epoch 229: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▍                                       | 246/486 [31:44<29:45,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Epoch 88: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▋                                       | 247/486 [31:49<26:23,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 129.\n",
      "Epoch 179: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▊                                       | 248/486 [31:57<28:01,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 206.\n",
      "Epoch 256: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▉                                       | 249/486 [32:08<32:29,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 52: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████████████████████████████████████████▏                                      | 250/486 [32:11<26:41,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Epoch 125: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▎                                      | 251/486 [32:18<25:51,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 151.\n",
      "Epoch 201: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▍                                      | 252/486 [32:27<29:04,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 85: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▋                                      | 253/486 [32:32<25:50,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 146.\n",
      "Epoch 196: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▊                                      | 254/486 [32:41<28:13,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 198.\n",
      "Epoch 248: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▉                                      | 255/486 [32:51<31:55,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 81: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▏                                     | 256/486 [32:56<27:31,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 124.\n",
      "Epoch 174: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▎                                     | 257/486 [33:04<28:22,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 651.\n",
      "Epoch 701: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▍                                     | 258/486 [33:32<51:52, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▋                                     | 259/486 [33:37<42:01, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 180.\n",
      "Epoch 230: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▊                                     | 260/486 [33:47<40:48, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 175.\n",
      "Epoch 225: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████▉                                     | 261/486 [33:57<39:43, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Epoch 74: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▏                                    | 262/486 [34:02<32:31,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 161.\n",
      "Epoch 211: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▎                                    | 263/486 [34:11<33:08,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 151.\n",
      "Epoch 201: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▍                                    | 264/486 [34:22<35:40,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "Epoch 104: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▌                                    | 265/486 [34:28<30:56,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 225.\n",
      "Epoch 275: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▊                                    | 266/486 [34:40<34:36,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 239.\n",
      "Epoch 289: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▉                                    | 267/486 [34:52<37:41, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████                                    | 268/486 [34:56<30:55,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 155.\n",
      "Epoch 205: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▎                                   | 269/486 [35:06<31:34,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 184.\n",
      "Epoch 234: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▍                                   | 270/486 [35:16<33:12,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Epoch 117: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▌                                   | 271/486 [35:22<29:04,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Epoch 124: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▊                                   | 272/486 [35:27<26:23,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 146.\n",
      "Epoch 196: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▉                                   | 273/486 [35:36<27:09,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 85: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████                                   | 274/486 [35:40<23:35,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 129.\n",
      "Epoch 179: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▎                                  | 275/486 [35:48<24:35,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 160.\n",
      "Epoch 210: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▍                                  | 276/486 [35:56<26:20,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Epoch 112: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▌                                  | 277/486 [36:02<24:01,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Epoch 132: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▊                                  | 278/486 [36:08<23:01,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 170.\n",
      "Epoch 220: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▉                                  | 279/486 [36:17<25:34,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Epoch 98: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████                                  | 280/486 [36:24<24:19,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 144.\n",
      "Epoch 194: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▎                                 | 281/486 [36:32<25:24,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 225.\n",
      "Epoch 275: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▍                                 | 282/486 [36:43<29:04,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Epoch 88: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▌                                 | 283/486 [36:48<24:57,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 177.\n",
      "Epoch 227: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▋                                 | 284/486 [36:57<27:02,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 779.\n",
      "Epoch 829: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████▉                                 | 285/486 [37:28<49:44, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 91.\n",
      "Epoch 141: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████                                 | 286/486 [37:34<41:08, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 135.\n",
      "Epoch 185: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▏                                | 287/486 [37:42<36:39, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 263.\n",
      "Epoch 313: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▍                                | 288/486 [37:55<38:00, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 59: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▌                                | 289/486 [37:59<29:57,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 146.\n",
      "Epoch 196: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▋                                | 290/486 [38:10<32:08,  9.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 173.\n",
      "Epoch 223: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▉                                | 291/486 [38:20<31:53,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████                                | 292/486 [38:25<27:14,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 169.\n",
      "Epoch 219: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▏                               | 293/486 [38:34<27:57,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 225.\n",
      "Epoch 275: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▍                               | 294/486 [38:46<30:32,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Epoch 86: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▌                               | 295/486 [38:50<25:37,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 126.\n",
      "Epoch 176: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▋                               | 296/486 [38:58<25:12,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 187.\n",
      "Epoch 237: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▉                               | 297/486 [39:08<26:55,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Epoch 134: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████████████████████████████                               | 298/486 [39:20<29:32,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 107.\n",
      "Epoch 157: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▏                              | 299/486 [39:27<27:30,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 148.\n",
      "Epoch 198: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▍                              | 300/486 [39:36<27:15,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 75: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▌                              | 301/486 [39:40<22:58,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 153.\n",
      "Epoch 203: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▋                              | 302/486 [39:49<24:14,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 524.\n",
      "Epoch 574: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▉                              | 303/486 [40:12<37:29, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Epoch 54: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████                              | 304/486 [40:15<29:18,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 105.\n",
      "Epoch 155: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▏                             | 305/486 [40:22<26:55,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 159.\n",
      "Epoch 209: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▎                             | 306/486 [40:31<26:58,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 82: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▌                             | 307/486 [40:36<22:51,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 104.\n",
      "Epoch 154: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▋                             | 308/486 [40:43<22:18,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 165.\n",
      "Epoch 215: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████▊                             | 309/486 [40:53<23:53,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Epoch 114: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████                             | 310/486 [40:58<21:42,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 167.\n",
      "Epoch 217: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▏                            | 311/486 [41:08<23:34,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 718.\n",
      "Epoch 768: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▎                            | 312/486 [41:38<42:31, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Epoch 111: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▌                            | 313/486 [41:44<34:30, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 109.\n",
      "Epoch 159: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████████████████████████████▋                            | 314/486 [41:51<30:30, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 178.\n",
      "Epoch 228: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████████████████████████████▊                            | 315/486 [42:01<29:52, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 53: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████                            | 316/486 [42:05<23:50,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 156.\n",
      "Epoch 206: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▏                           | 317/486 [42:14<24:17,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 185.\n",
      "Epoch 235: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▎                           | 318/486 [42:24<25:32,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Epoch 130: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▌                           | 319/486 [42:36<27:25,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 144.\n",
      "Epoch 194: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▋                           | 320/486 [42:45<26:27,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 277.\n",
      "Epoch 327: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▊                           | 321/486 [43:07<36:22, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Epoch 98: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████                           | 322/486 [43:12<29:36, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 138.\n",
      "Epoch 188: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████▏                          | 323/486 [43:21<27:38, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 145.\n",
      "Epoch 195: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▎                          | 324/486 [43:29<26:26,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Epoch 54: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▍                          | 325/486 [43:33<21:00,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Epoch 132: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▋                          | 326/486 [43:39<19:36,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 140.\n",
      "Epoch 190: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▊                          | 327/486 [43:47<19:54,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Epoch 54: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▉                          | 328/486 [43:50<16:32,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 124.\n",
      "Epoch 174: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▏                         | 329/486 [43:58<17:28,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 155.\n",
      "Epoch 205: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▎                         | 330/486 [44:07<18:58,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 57: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▍                         | 331/486 [44:10<15:52,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Epoch 137: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▋                         | 332/486 [44:16<15:53,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 127.\n",
      "Epoch 177: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████████████████████████████████████████████████████▊                         | 333/486 [44:24<16:54,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 81: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████████████████████████████████████████████████████▉                         | 334/486 [44:28<15:01,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 141.\n",
      "Epoch 191: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▏                        | 335/486 [44:36<16:37,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Epoch 108: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▎                        | 336/486 [44:42<15:29,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 76: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▍                        | 337/486 [44:46<13:57,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 111.\n",
      "Epoch 161: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▋                        | 338/486 [44:53<15:02,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 288.\n",
      "Epoch 338: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▊                        | 339/486 [45:07<20:30,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Epoch 75: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▉                        | 340/486 [45:11<17:20,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 149.\n",
      "Epoch 199: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▏                       | 341/486 [45:20<18:12,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Epoch 108: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▎                       | 342/486 [45:26<17:14,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 55: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▍                       | 343/486 [45:29<14:29,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 147.\n",
      "Epoch 197: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▋                       | 344/486 [45:38<16:00,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "Epoch 138: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▊                       | 345/486 [45:44<15:32,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Epoch 115: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▉                       | 346/486 [45:50<14:43,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 166.\n",
      "Epoch 216: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|█████████████████████████████████████████████████████████                       | 347/486 [45:59<16:34,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 172.\n",
      "Epoch 222: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▎                      | 348/486 [46:08<18:06,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 84: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▍                      | 349/486 [46:13<15:39,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 156.\n",
      "Epoch 206: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▌                      | 350/486 [46:22<16:50,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Epoch 147: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▊                      | 351/486 [46:28<16:15,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 59: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▉                      | 352/486 [46:32<13:48,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Epoch 119: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████                      | 353/486 [46:38<13:27,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 172.\n",
      "Epoch 222: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▎                     | 354/486 [46:47<15:40,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Epoch 106: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▍                     | 355/486 [46:53<14:26,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 194.\n",
      "Epoch 244: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▌                     | 356/486 [47:03<16:53,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 180.\n",
      "Epoch 230: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▊                     | 357/486 [47:13<18:13,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████▉                     | 358/486 [47:17<14:51,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Epoch 145: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████                     | 359/486 [47:28<17:37,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 124.\n",
      "Epoch 174: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▎                    | 360/486 [47:36<17:16,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 67: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▍                    | 361/486 [47:40<14:31,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 137.\n",
      "Epoch 187: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▌                    | 362/486 [47:49<15:20,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████▊                    | 363/486 [47:54<13:54,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 82: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████▉                    | 364/486 [47:59<12:30,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 142.\n",
      "Epoch 192: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████                    | 365/486 [48:08<14:05,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 281.\n",
      "Epoch 331: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████▏                   | 366/486 [48:30<22:51, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Epoch 125: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▍                   | 367/486 [48:36<19:33,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Epoch 112: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▌                   | 368/486 [48:42<16:59,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Epoch 125: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▋                   | 369/486 [48:48<15:33,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 53: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▉                   | 370/486 [48:52<12:49,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 149.\n",
      "Epoch 199: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████                   | 371/486 [49:00<14:00,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Epoch 136: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▏                  | 372/486 [49:12<16:17,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Epoch 62: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▍                  | 373/486 [49:16<13:30,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 130.\n",
      "Epoch 180: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▌                  | 374/486 [49:24<14:08,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 149.\n",
      "Epoch 199: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▋                  | 375/486 [49:34<15:20,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▉                  | 376/486 [49:38<12:33,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 177.\n",
      "Epoch 227: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████                  | 377/486 [49:48<14:11,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 122.\n",
      "Epoch 172: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▏                 | 378/486 [49:56<14:09,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 379/486 [49:59<11:32,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 107.\n",
      "Epoch 157: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▌                 | 380/486 [50:06<11:42,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 141.\n",
      "Epoch 191: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▋                 | 381/486 [50:18<14:07,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 81: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|██████████████████████████████████████████████████████████████▉                 | 382/486 [50:22<12:02,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "Epoch 147: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████                 | 383/486 [50:29<11:46,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 182.\n",
      "Epoch 232: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▏                | 384/486 [50:38<13:04,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▎                | 385/486 [50:41<10:43,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "Epoch 139: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▌                | 386/486 [50:48<10:37,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 129.\n",
      "Epoch 179: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▋                | 387/486 [50:56<11:14,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 81: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▊                | 388/486 [51:00<09:55,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Epoch 91: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 389/486 [51:05<09:09,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 139.\n",
      "Epoch 189: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▏               | 390/486 [51:13<10:16,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▎               | 391/486 [51:17<09:02,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 150.\n",
      "Epoch 200: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▌               | 392/486 [51:26<10:17,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 298.\n",
      "Epoch 348: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▋               | 393/486 [51:39<13:36,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Epoch 63: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▊               | 394/486 [51:43<11:10,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 102.\n",
      "Epoch 152: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████████               | 395/486 [51:50<10:54,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████████▏              | 396/486 [51:57<10:25,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 57: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▎              | 397/486 [52:00<08:47,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 146.\n",
      "Epoch 196: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 398/486 [52:09<09:45,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 106.\n",
      "Epoch 156: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▋              | 399/486 [52:15<09:46,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Epoch 57: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▊              | 400/486 [52:19<08:17,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 132.\n",
      "Epoch 182: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████              | 401/486 [52:27<09:07,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 188.\n",
      "Epoch 238: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▏             | 402/486 [52:37<10:30,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 52: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▎             | 403/486 [52:40<08:41,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 110.\n",
      "Epoch 160: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▌             | 404/486 [52:48<08:57,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 124.\n",
      "Epoch 174: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▋             | 405/486 [52:56<09:25,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Epoch 66: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████▊             | 406/486 [53:00<08:05,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 107.\n",
      "Epoch 157: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████▉             | 407/486 [53:07<08:27,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 144.\n",
      "Epoch 194: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 408/486 [53:15<09:14,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "Epoch 113: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▎            | 409/486 [53:22<08:50,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 120.\n",
      "Epoch 170: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▍            | 410/486 [53:30<09:06,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 197.\n",
      "Epoch 247: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████▋            | 411/486 [53:40<10:18,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Epoch 52: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████▊            | 412/486 [53:44<08:24,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 132.\n",
      "Epoch 182: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████▉            | 413/486 [53:52<08:51,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 119.\n",
      "Epoch 169: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████▏           | 414/486 [54:00<08:56,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 67: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████▎           | 415/486 [54:04<07:36,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 168.\n",
      "Epoch 218: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▍           | 416/486 [54:14<08:37,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 102.\n",
      "Epoch 152: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▋           | 417/486 [54:21<08:26,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Epoch 117: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 418/486 [54:27<07:50,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 159.\n",
      "Epoch 209: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▉           | 419/486 [54:37<08:39,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 326.\n",
      "Epoch 376: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████████████████████████████████████▏          | 420/486 [54:56<12:23, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▎          | 421/486 [55:02<10:25,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 171.\n",
      "Epoch 221: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▍          | 422/486 [55:12<10:21,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Epoch 93: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▋          | 423/486 [55:17<08:44,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 85: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▊          | 424/486 [55:22<07:28,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 163.\n",
      "Epoch 213: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▉          | 425/486 [55:31<07:59,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 106.\n",
      "Epoch 156: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████          | 426/486 [55:38<07:41,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Epoch 98: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▎         | 427/486 [55:44<06:50,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 95.\n",
      "Epoch 145: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 428/486 [55:55<08:04,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 193.\n",
      "Epoch 243: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▌         | 429/486 [56:06<08:37,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Epoch 100: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▊         | 430/486 [56:11<07:25,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 117.\n",
      "Epoch 167: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|██████████████████████████████████████████████████████████████████████▉         | 431/486 [56:19<07:16,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 115.\n",
      "Epoch 165: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████         | 432/486 [56:31<08:07,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▎        | 433/486 [56:35<06:36,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Epoch 125: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▍        | 434/486 [56:40<06:02,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 130.\n",
      "Epoch 180: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▌        | 435/486 [56:48<06:07,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▊        | 436/486 [56:51<05:01,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 111.\n",
      "Epoch 161: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▉        | 437/486 [56:59<05:11,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 243.\n",
      "Epoch 293: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 438/486 [57:20<08:46, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▎       | 439/486 [57:24<06:47,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 102.\n",
      "Epoch 152: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▍       | 440/486 [57:30<06:13,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 135.\n",
      "Epoch 185: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▌       | 441/486 [57:38<06:03,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Epoch 65: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▊       | 442/486 [57:42<04:58,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 180.\n",
      "Epoch 230: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▉       | 443/486 [57:52<05:27,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Epoch 126: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████       | 444/486 [57:58<05:04,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Epoch 68: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▎      | 445/486 [58:02<04:18,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 131.\n",
      "Epoch 181: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▍      | 446/486 [58:10<04:30,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 296.\n",
      "Epoch 346: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 447/486 [58:24<05:45,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Epoch 99: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▋      | 448/486 [58:29<04:52,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "Epoch 122: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▉      | 449/486 [58:35<04:25,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████      | 450/486 [58:41<04:10,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▏     | 451/486 [58:44<03:24,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 181.\n",
      "Epoch 231: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 452/486 [58:54<04:01,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Epoch 131: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▌     | 453/486 [59:01<03:47,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▋     | 454/486 [59:05<03:13,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 244.\n",
      "Epoch 294: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████▉     | 455/486 [59:17<04:02,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 174.\n",
      "Epoch 224: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████     | 456/486 [59:26<04:10,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Epoch 53: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 457/486 [59:30<03:20,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 155.\n",
      "Epoch 205: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 458/486 [59:39<03:29,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 101.\n",
      "Epoch 151: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 459/486 [59:46<03:17,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 77: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|███████████████████████████████████████████████████████████████████████████▋    | 460/486 [59:50<02:46,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "Epoch 131: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|███████████████████████████████████████████████████████████████████████████▉    | 461/486 [59:56<02:40,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 129.\n",
      "Epoch 179: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████████████████████████████████████████████████▏   | 462/486 [1:00:05<02:46,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 85: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████████████████████████████████████████████████▎   | 463/486 [1:00:09<02:24,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 107.\n",
      "Epoch 157: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████████████████████████████████████████████████▍   | 464/486 [1:00:17<02:25,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 165.\n",
      "Epoch 215: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████▋   | 465/486 [1:00:28<02:49,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████▊   | 466/486 [1:00:32<02:13,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Epoch 146: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████▉   | 467/486 [1:00:39<02:08,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 121.\n",
      "Epoch 171: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|███████████████████████████████████████████████████████████████████████████   | 468/486 [1:00:46<02:07,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 73: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████▎  | 469/486 [1:00:51<01:46,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 115.\n",
      "Epoch 165: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████▍  | 470/486 [1:01:02<02:05,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "Epoch 82: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████▌  | 471/486 [1:01:07<01:42,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Epoch 99: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████▊  | 472/486 [1:01:12<01:29,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 156.\n",
      "Epoch 206: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████▉  | 473/486 [1:01:21<01:34,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 312.\n",
      "Epoch 362: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████  | 474/486 [1:01:37<01:55,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "Epoch 77: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████▏ | 475/486 [1:01:41<01:28,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "Epoch 142: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████▍ | 476/486 [1:01:48<01:17,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Epoch 133: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████▌ | 477/486 [1:01:55<01:06,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████▋ | 478/486 [1:01:58<00:49,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 121.\n",
      "Epoch 171: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|████████████████████████████████████████████████████████████████████████████▉ | 479/486 [1:02:06<00:47,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "Epoch 149: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████████████████████████████████████████████████████████████████████████ | 480/486 [1:02:17<00:49,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 80: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████████████████████████████████████████████████████████████████████████▏| 481/486 [1:02:22<00:35,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 148.\n",
      "Epoch 198: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████████████████████████████████████████████████████████████████████████▎| 482/486 [1:02:31<00:30,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 151.\n",
      "Epoch 201: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████████████████████████████████████████████████████████████████████████▌| 483/486 [1:02:40<00:24,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.01}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 79: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████████████████████████████████████████████████████████████████████████▋| 484/486 [1:02:45<00:14,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 157.\n",
      "Epoch 207: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████████████████████████████████████████████████████████████████████████▊| 485/486 [1:02:54<00:07,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.0001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.0001, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Epoch 143: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 486/486 [1:03:01<00:00,  7.78s/it]\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=train_df, y=train_label,\n",
    "            x_val=test_df, y_val=test_label,\n",
    "            model=numerai_model,\n",
    "            params=p,  \n",
    "            experiment_name='Predykcja klasy M - Weighted binary cross-entropy (nowe)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aba74c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/Marze/OneDrive/Dokumenty/Jarek/Magisterka/Predykcja klasy M - Weighted binary cross-entropy (nowe)/050722130358.csv\", encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88908f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>0.590803</td>\n",
       "      <td>[0.3099099]</td>\n",
       "      <td>0.183369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759110</td>\n",
       "      <td>[0.28776976]</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0.585176</td>\n",
       "      <td>[0.3121387]</td>\n",
       "      <td>0.187067</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>[0.27906978]</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159</td>\n",
       "      <td>0.628814</td>\n",
       "      <td>[0.30127043]</td>\n",
       "      <td>0.178495</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.634496</td>\n",
       "      <td>[0.3007519]</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>0.666929</td>\n",
       "      <td>[0.29347825]</td>\n",
       "      <td>0.173820</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.729283</td>\n",
       "      <td>[0.2962963]</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193</td>\n",
       "      <td>0.573849</td>\n",
       "      <td>[0.45652172]</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.627681</td>\n",
       "      <td>[0.39130437]</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>198</td>\n",
       "      <td>0.594316</td>\n",
       "      <td>[0.37383178]</td>\n",
       "      <td>0.233918</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.588491</td>\n",
       "      <td>[0.37837836]</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>201</td>\n",
       "      <td>0.739233</td>\n",
       "      <td>[0.28621906]</td>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>[0.2962963]</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>79</td>\n",
       "      <td>0.632147</td>\n",
       "      <td>[0.30659536]</td>\n",
       "      <td>0.181053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796001</td>\n",
       "      <td>[0.28169015]</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>207</td>\n",
       "      <td>0.552860</td>\n",
       "      <td>[0.4473684]</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>[0.37837836]</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>143</td>\n",
       "      <td>0.681076</td>\n",
       "      <td>[0.28621906]</td>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.667302</td>\n",
       "      <td>[0.29850748]</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "0              83  0.590803   [0.3099099]   0.183369  1.000000  0.759110   \n",
       "1              68  0.585176   [0.3121387]   0.187067  0.941860  0.635742   \n",
       "2             159  0.628814  [0.30127043]   0.178495  0.965116  0.634496   \n",
       "3              81  0.666929  [0.29347825]   0.173820  0.941860  0.729283   \n",
       "4             193  0.573849  [0.45652172]   0.428571  0.488372  0.627681   \n",
       "..            ...       ...           ...        ...       ...       ...   \n",
       "481           198  0.594316  [0.37383178]   0.233918  0.930233  0.588491   \n",
       "482           201  0.739233  [0.28621906]   0.168750  0.941860  0.737068   \n",
       "483            79  0.632147  [0.30659536]   0.181053  1.000000  0.796001   \n",
       "484           207  0.552860   [0.4473684]   0.311927  0.790698  0.619718   \n",
       "485           143  0.681076  [0.28621906]   0.168750  0.941860  0.667302   \n",
       "\n",
       "    val_fbeta_score  val_precision  val_recall activation_layer  ...  dropout  \\\n",
       "0      [0.28776976]       0.170940    0.909091             tanh  ...      0.0   \n",
       "1      [0.27906978]       0.187500    0.545455             tanh  ...      0.0   \n",
       "2       [0.3007519]       0.180180    0.909091             tanh  ...      0.0   \n",
       "3       [0.2962963]       0.176991    0.909091             tanh  ...      0.0   \n",
       "4      [0.39130437]       0.375000    0.409091             tanh  ...      0.0   \n",
       "..              ...            ...         ...              ...  ...      ...   \n",
       "481    [0.37837836]       0.466667    0.318182             tanh  ...      0.1   \n",
       "482     [0.2962963]       0.176991    0.909091             tanh  ...      0.1   \n",
       "483    [0.28169015]       0.166667    0.909091             tanh  ...      0.1   \n",
       "484    [0.37837836]       0.466667    0.318182             tanh  ...      0.1   \n",
       "485    [0.29850748]       0.178571    0.909091             tanh  ...      0.1   \n",
       "\n",
       "     epochs  first_neuron  hidden_layers  hidden_neuron  kernel_initializer  \\\n",
       "0    100000            55              1             50            identity   \n",
       "1    100000            55              1             50            identity   \n",
       "2    100000            55              1             50            identity   \n",
       "3    100000            55              1             50            identity   \n",
       "4    100000            55              1             50            identity   \n",
       "..      ...           ...            ...            ...                 ...   \n",
       "481  100000            55              1             50            identity   \n",
       "482  100000            55              1             50            identity   \n",
       "483  100000            55              1             50            identity   \n",
       "484  100000            55              1             50            identity   \n",
       "485  100000            55              1             50            identity   \n",
       "\n",
       "     kernel_regularizer_l1  kernel_regularizer_l2  last_activation      lr  \n",
       "0                   0.0000                 0.0000          sigmoid  0.0100  \n",
       "1                   0.0000                 0.0000          sigmoid  0.0010  \n",
       "2                   0.0000                 0.0000          sigmoid  0.0001  \n",
       "3                   0.0000                 0.0010          sigmoid  0.0100  \n",
       "4                   0.0000                 0.0010          sigmoid  0.0010  \n",
       "..                     ...                    ...              ...     ...  \n",
       "481                 0.0001                 0.0010          sigmoid  0.0010  \n",
       "482                 0.0001                 0.0010          sigmoid  0.0001  \n",
       "483                 0.0001                 0.0001          sigmoid  0.0100  \n",
       "484                 0.0001                 0.0001          sigmoid  0.0010  \n",
       "485                 0.0001                 0.0001          sigmoid  0.0001  \n",
       "\n",
       "[486 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a1e6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stare_wart=df['val_fbeta_score']\n",
    "nowe_wart=[]\n",
    "for x in stare_wart:\n",
    "    wart=x.replace('[','')\n",
    "    wart=wart.replace(']','')\n",
    "    wart=float(wart)\n",
    "    nowe_wart.append(wart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eb0d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['val_fbeta_score']=nowe_wart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79498780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values('val_loss',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b670816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>176</td>\n",
       "      <td>0.594405</td>\n",
       "      <td>[0.37572256]</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.485936</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>155</td>\n",
       "      <td>0.553286</td>\n",
       "      <td>[0.42253518]</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.497643</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>196</td>\n",
       "      <td>0.547030</td>\n",
       "      <td>[0.3970588]</td>\n",
       "      <td>0.251553</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.499840</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>123</td>\n",
       "      <td>0.551963</td>\n",
       "      <td>[0.42519683]</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.501804</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>201</td>\n",
       "      <td>0.546345</td>\n",
       "      <td>[0.43866172]</td>\n",
       "      <td>0.322404</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.508922</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>58</td>\n",
       "      <td>0.623023</td>\n",
       "      <td>[0.30852994]</td>\n",
       "      <td>0.182796</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.837089</td>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>70</td>\n",
       "      <td>0.592675</td>\n",
       "      <td>[0.3099099]</td>\n",
       "      <td>0.183369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842771</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>134</td>\n",
       "      <td>0.628879</td>\n",
       "      <td>[0.30859375]</td>\n",
       "      <td>0.185446</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>0.852728</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>72</td>\n",
       "      <td>0.724645</td>\n",
       "      <td>[0.3029197]</td>\n",
       "      <td>0.179654</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.875239</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>51</td>\n",
       "      <td>0.645601</td>\n",
       "      <td>[0.30490017]</td>\n",
       "      <td>0.180645</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.896576</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "295           176  0.594405  [0.37572256]   0.250000  0.755814  0.485936   \n",
       "304           155  0.553286  [0.42253518]   0.303030  0.697674  0.497643   \n",
       "397           196  0.547030   [0.3970588]   0.251553  0.941860  0.499840   \n",
       "244           123  0.551963  [0.42519683]   0.321429  0.627907  0.501804   \n",
       "241           201  0.546345  [0.43866172]   0.322404  0.686047  0.508922   \n",
       "..            ...       ...           ...        ...       ...       ...   \n",
       "153            58  0.623023  [0.30852994]   0.182796  0.988372  0.837089   \n",
       "432            70  0.592675   [0.3099099]   0.183369  1.000000  0.842771   \n",
       "297           134  0.628879  [0.30859375]   0.185446  0.918605  0.852728   \n",
       "18             72  0.724645   [0.3029197]   0.179654  0.965116  0.875239   \n",
       "99             51  0.645601  [0.30490017]   0.180645  0.976744  0.896576   \n",
       "\n",
       "     val_fbeta_score  val_precision  val_recall activation_layer  ...  \\\n",
       "295         0.312500       0.500000    0.227273             tanh  ...   \n",
       "304         0.285714       0.384615    0.227273             tanh  ...   \n",
       "397         0.388889       0.500000    0.318182             tanh  ...   \n",
       "244         0.342857       0.461538    0.272727             tanh  ...   \n",
       "241         0.378378       0.466667    0.318182             tanh  ...   \n",
       "..               ...            ...         ...              ...  ...   \n",
       "153         0.289855       0.172414    0.909091             tanh  ...   \n",
       "432         0.281690       0.166667    0.909091             tanh  ...   \n",
       "297         0.283688       0.168067    0.909091             tanh  ...   \n",
       "18          0.291667       0.172131    0.954545             tanh  ...   \n",
       "99          0.291667       0.172131    0.954545             tanh  ...   \n",
       "\n",
       "     dropout  epochs  first_neuron  hidden_layers  hidden_neuron  \\\n",
       "295      0.0  100000            55              1             50   \n",
       "304      0.1  100000            55              1             50   \n",
       "397      0.0  100000            55              1             50   \n",
       "244      0.1  100000            55              1             50   \n",
       "241      0.0  100000            55              1             50   \n",
       "..       ...     ...           ...            ...            ...   \n",
       "153      0.1  100000            55              1             50   \n",
       "432      0.0  100000            55              1             50   \n",
       "297      0.1  100000            55              1             50   \n",
       "18       0.0  100000            55              1             50   \n",
       "99       0.1  100000            55              1             50   \n",
       "\n",
       "     kernel_initializer  kernel_regularizer_l1  kernel_regularizer_l2  \\\n",
       "295            identity                 0.0001                 0.0001   \n",
       "304            identity                 0.0000                 0.0001   \n",
       "397            identity                 0.0001                 0.0000   \n",
       "244            identity                 0.0000                 0.0000   \n",
       "241            identity                 0.0001                 0.0001   \n",
       "..                  ...                    ...                    ...   \n",
       "153            identity                 0.0001                 0.0000   \n",
       "432            identity                 0.0000                 0.0000   \n",
       "297            identity                 0.0000                 0.0000   \n",
       "18             identity                 0.0001                 0.0000   \n",
       "99             identity                 0.0001                 0.0000   \n",
       "\n",
       "     last_activation     lr  \n",
       "295          sigmoid  0.001  \n",
       "304          sigmoid  0.001  \n",
       "397          sigmoid  0.001  \n",
       "244          sigmoid  0.001  \n",
       "241          sigmoid  0.001  \n",
       "..               ...    ...  \n",
       "153          sigmoid  0.010  \n",
       "432          sigmoid  0.010  \n",
       "297          sigmoid  0.010  \n",
       "18           sigmoid  0.010  \n",
       "99           sigmoid  0.010  \n",
       "\n",
       "[486 rows x 24 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c8805eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of kernel_regularizer_l1')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_regularizer_l1'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e6404c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of kernel_regularizer_l2')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_regularizer_l2'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "759d4d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of bias_regularizer')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'bias_regularizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d7688d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of activity_regularizer')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'activity_regularizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93ae1fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of dropout')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'dropout'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15139849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of lr')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaEklEQVR4nO3df5xddX3n8dc7k0yy/khEEliYBBJLaM1aHovMI6C2lRbdDgihNV0MFSxWYdHFYAV8QLWUUt21j7W2pKKWsgrByo8l+9C0xsFuARVBkkkVa4LBEEgzAwkjJIFASTLJZ/8435Cb60xyZ3LPPTPzfT8fj/vIvefH937OPZP7vufX9ygiMDOzfE2ougAzM6uWg8DMLHMOAjOzzDkIzMwy5yAwM8ucg8DMLHMOAhuUpJB0Qnr+JUl/0si0I3if90r69kjrHM8kfUjSFkk7JB3Zwvf9Y0k3t+r9at73dyVtSst78iDjR/x3ZgcnX0cwPknqBlZGxLV1w88F/haYGREDB5k/gLkRsb6B92poWkmzgSeASQd772aQdDrw1YiYWeb7lEXSJOB54LSIeKTE9zmdUfI5SXoc+FhEfGOI8Q3/TdrweItg/LoVuECS6oZfCPx92V/EdtiOBqYAa6oupIWOZ4TLK6mtybVkxUEwfn0dOBL49X0DJB0BnA0slTRf0kOStkl6WtLnJbUP1pCkWyR9qub1VWmepyT9Yd2075L0Q0nPp83862pGfzf9uy1t/r9F0kWSHqiZ/62SVknanv59a824+yX9uaTvS3pB0rclTR/uByPpjamtbZLWSFpQM+4sSWtT+32SrkzDp0v6xzTPc5K+J2nQ/z+SbkjL/ryk1ZJq18F8ST1p3BZJnxtk/hOBdTWf1b2SZqddIxPrPo8PpucXSXpA0mclbZX0hKQza6Z9vaSvpHW2VdLXJb0a+BZwbFofOyQdK+k6SV+tmXdB+py2pfd8Y824JyVdKenHaZ3dKWnKEJ/LBEmflLRR0jOSlkqaJmmypB1AG/BI2jI4qPQ3+UVJKyS9CPzmoeaxg4gIP8bpA/g74Oaa1/8N+FF6fgpwGjARmA08Cny0ZtoATkjPbwE+lZ53AVuANwGvBr5WN+3pwK9S/Mg4KU37O2nc7DTtxJr3uQh4ID1/PbCVYqtlInB+en1kGn8/8DhwIvAf0uvPDLHspwO9gwyfBKwH/hhoB34LeAH45TT+aeDX0/MjgDen5/8T+FKafxJFwGqI976AIoQnAlcAm4EpadxDwIXp+Wsodv0M1sYBn9UQn939wAdrPsfdwMUUX6gfAp5i/+7fbwJ3pmWaBLx9qM8JuI5idxHps34ReGea7+Pp82tP458EVgLHpvX3KHDpEMv0h2neN6Rl/7/AbYP9zQ0xf/3f5HbgbRR/a1Oq/v82lh/eIhjfbgV+r+YX2vvSMCJidUT8ICIGIuJJiuMGb2+gzfOAr0TETyLiRYovjVdExP0R8a8RsTcifgzc3mC7AO8CfhYRt6W6bgd+CpxTM81XIuKxiPh34C7gPzfY9j6nUXwJfSYidkXEvcA/UoQOFF+m8yRNjYitEfEvNcOPAY6PiN0R8b1I30j1IuKrEfFsWoa/BCYDv1zTzgmSpkfEjoj4wTDrP5iNEfF3EbGHYj0fAxwt6RjgTIov6K2p/u802OZ7gG9GxD9FxG7gsxQh/NaaaZZExFMR8RzwDwy9Tt4LfC4iNkTEDuAaYFHtVs4wfSMivp/+1l4eYRuGdw2NaxHxAPBz4Hck/RIwn+IXPJJOTLs6Nkt6HvgfQCO7WY4FNtW83lg7UtKpku6T1C9pO3Bpg+3ua3tj3bCNQEfN6801z1+i+FIfjmOBTRGxd4j3WAicBWyU9B1Jb0nD/xfFr9lvS9og6eqh3iDtKnk07SrZBkxj/2fwAYpf2T9Nu77OHmb9B/PKZxMRL6WnrwFmAc9FxNYRtHnAOkmf2yZGtk7q1+9Giq2mo0dQFxz4d2iHwUEw/i2l2BK4ALgnIrak4V+k+LU9NyKmUuwqqT+wPJinKb5Y9jmubvzXgOXArIiYRrE7ZV+7hzpF7SmKA4a1jgP6GqirUU8Bs+r277/yHhGxKiLOBY6iOM5yVxr+QkRcERFvABYAH5N0Rn3j6XjAxym2nI6IiNdR7MJQaudnEXF+av8vgLvTvvpDeTH9+6qaYf+xoSUuvjBfL+l1g4wb1jqRJIr1P5J1Ur9+jwMGKHYfjoRPeWwSB8H4txR4B8W+41trhr+W4vTEHZJ+hWKfciPuAi6SNE/Sq4A/rRv/Wopfny9Lmg/8fs24fmAvxT7iwawATpT0+5ImSnoPMI9i182ISJpS+6DYn/0S8HFJk1ScPnkOcIekdhXXNUxLu0GeT/Ui6WxJJ6Qvwu3Ann3jBln+gbSsEyVdC0ytqecCSTPSL+ttafBg7RwgIvopvnwvkNSm4iD9LzXyGUTE0xQHhb8g6Yi03L+RRm8BjpQ0bYjZ7wLeJekMFae0XgHsBB5s5L3r3A78kaQ5kl5DsRV6Z/gMtso5CMa5tP//QYoDu8trRl1J8SX9AsVB5TsbbO9bwF8D91LsKrm3bpIPA9dLegG4lvSLOs37EvBp4PvpDJTT6tp+luKspiuAZyl+WZ8dET9vpLZBdAD/XveYRfHFfybFbrMvAO+LiJ+meS4Enky7yy6l2K8NMBf4f8AOigO+X4iI+wZ5z3uAbuAxil0fL3PgLowuYE06S+YGYFE63tGIi4GrKD6b/8TwvowvpDg+8VPgGeCjAGm5bwc2pHVybO1MEbGOYmvybyg+r3OAcyJi1zDee58vA7dRnD32BMVn85ERtGNN5gvKzMwy5y0CM7PMOQjMzDLnIDAzy5yDwMwscyO9oq9S06dPj9mzZ1ddhpnZmLJ69eqfR8SM+uFjMghmz55NT09P1WWYmY0pkuqv3Ae8a8jMLHsOAjOzzDkIzMwyV3oQSOqStE7S+sF6bJR0vKR/Tje2uF9S5bfMMzPLSalBoOL2cTdS9OsyDzhf0ry6yT4LLI2Ik4DrKW4AYmbWUtu3b+eGG27g+eefr7qUlit7i2A+sD7diGIXcAdwbt0089jfcdl9g4w3Mytdd3c3GzZsoLu7u+pSWq7sIOjgwJ4XeznwhhYAjwDvTs9/F3itpCNLrsvM7BXbt29n5cqVRAQPP/xwdlsFo+Fg8ZXA2yX9kOKWhn0Ufb0fQNIlKm763dPf39/qGs1sHOvu7mbv3uK2EHv37s1uq6DsIOjjwLtZzaTuzkbpXqfvjoiTgU+kYdvqG4qImyKiMyI6Z8z4hQvjzMxGbPXq1ezZU/z+3LNnT3YXrJYdBKuAuemORO3AIg68OQqSptfcNvAaiptXmJm1zCmnnEJbWxsAbW1tdHZ2VlxRa5UaBOkWdJdR3LXpUeCuiFgj6XpJC9JkpwPrJD1GcRPrT5dZk5lZva6uLiZMKL4OJ0yYQFdXV8UVtVbpfQ1FxAqKe9HWDru25vndwN1l12FmNpRp06Yxf/58HnzwQU499VSmTp166JnGkTHZ6ZyZWbN1dXWxefPm7LYGwEFgZgYUWwWXX3551WVUYjScPmpmZhVyEJiZ4S4mzMyy5y4mzMwy5i4mzMwy5y4mzMwy5y4mzMwy5y4mzMwyl3sXEw4CM8vevi4mJLmLCTOzXLmLCTOzzLmLCTOzzPnKYjOzzPnKYjOzjPnKYjOzzPnKYjOzzPnKYjOzzPnKYjOzzPnKYjOzzPnKYjOzMWTZsmX09fU1vd0tW7YwYcIEent7WbJkSVPb7ujoYOHChU1ts5m8RWBmBuzevZtJkyYxcWJ+v4/zW2IzG9PK+mW9bytg8eLFpbQ/mnmLwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMuYuJESir0yuA/v5+AGbMmNH0tkd7x1dmVg0HwSizc+fOqksws8w4CEagzF/VOXd8ZWbV8DECM7PMOQjMzDLnIDAzy1zpQSCpS9I6SeslXT3I+OMk3Sfph5J+LOmssmsyM7P9Sg0CSW3AjcCZwDzgfEnz6ib7JHBXRJwMLAK+UGZNZmZ2oLK3COYD6yNiQ0TsAu4Azq2bJoCp6fk04KmSazIzsxplB0EHsKnmdW8aVus64AJJvcAK4CODNSTpEkk9knr2XXRlZmaHbzQcLD4fuCUiZgJnAbdJ+oW6IuKmiOiMiM4yrro1M8tV2UHQB8yqeT0zDav1AeAugIh4CJgCTC+5LjMzS8oOglXAXElzJLVTHAxeXjfNvwFnAEh6I0UQeN+PmVmLlBoEETEAXAbcAzxKcXbQGknXS1qQJrsCuFjSI8DtwEUREWXWZWZm+5Xe11BErKA4CFw77Nqa52uBt5Vdh9k+ZfUeW2bPseDeY6087nTOrEncc6yNVQ4Cy05Zv6rdc6yNVaPh9FEzM6uQg8DMLHMOAjOzzI3rYwRl3lu4LL29vcD+/c1jgc9mMRvbxnUQ9PX1sWnD4xzdPnYWc9LuPQDs6t1YcSWN2bJroOoSzOwwjZ1vyBE6un0i7zvmiKrLGLeWPr216hLM7DD5GIGZWeYcBGZmmXMQmJllbtwfIzCz1vMZe63TjLP2HARm1nQ+Y681mnXW3thZS2Y2pviMvfI166w9HyMwM8ucg8DMLHMOAjOzzDkIzMwy5yAwM8ucg8DMLHMOAjOzzDkIzMwy5yAwM8ucg8DMLHMOAjOzzDkIzMwy5yAwM8ucg8DMLHPuhtrMmq6/v5+Xdw40rZtkG9yWnQNM6e8/7Ha8RWBmlrmGtggk/VegOyJekPRJ4M3ApyLiX0qtzszGpBkzZrBr50u+MU3Jlj69lfYZMw67nUa3CP4khcCvAe8A/jfwxcN+dzMzq1yjQbAn/fsu4KaI+CbQXk5JZmbWSo0GQZ+kvwXeA6yQNHkY85qZ2SjW6Jf5ecA9wG9HxDbg9cBVZRVlZmat0+jpo8cA34yInZJOB04ClpZVlJmZtU6jQbAM6JR0AnAT8A3ga8BZZRXWDD6XuXzNOo/ZzKrT6K6hvRExALwb+JuIuIpiK8HMzMa4RrcIdks6H3gfcE4aNqmckprH5zKXr1nnMZtZdRoNgvcDlwKfjognJM0BbmtkRkldwA1AG3BzRHymbvxfAb+ZXr4KOCoiXtdgXWY2Sm3ZNbZ2y27dXZwlf8SktooradyWXQPMakI7DQVBRKyVdCVwoqQ3Aesi4i8ONZ+kNuBG4J1AL7BK0vKIWFvT9h/VTP8R4ORhLoOZjTIdHR1VlzBsu3t7AWifObPiSho3i+Z81o12MXE6cCvwJCBglqQ/iIjvHmLW+cD6iNiQ2rkDOBdYO8T05wN/2khNZjZ6LVy4sOoShm3JkiUALF68uOJKWq/RXUN/CfyXiFgHIOlE4HbglEPM1wFsqnndC5w62ISSjgfmAPcOMf4S4BKA4447rsGyzczsUBo9a2jSvhAAiIjHaP7B4kXA3RGxZ7CREXFTRHRGROcMH5w0M2uaRrcIeiTdDHw1vX4v0NPAfH1wwLGMmWnYYBYB/73BeszMrEka3SL4EMV+/cXpsTYNO5RVwFxJcyS1U3zZL6+fSNKvAEcADzVYj5mZNUmjZw3tBD6XHg2LiAFJl1H0U9QGfDki1ki6HuiJiH2hsAi4IyJiOO2bmdnhO2gQSPpXYMgv54g46VBvEBErgBV1w66te33dodqx/Cxbtoy+vqH2JI4+ven0w31nn4wVHR0dY/IsH2ueQ20RnN2SKswG0dfXx6YNj3N0+9i4tfakdEHSrt6NFVfSuC27BqouwUaBg/4Pi4iG/qIlPRQRb2lOSWb7Hd0+0V2ElGgsXflr5WnWzWWmNKkdMzNrsWYFgQ/ympmNUb7dpJlZ5poVBGpSO2Zm1mLNCoILm9SOmZm12KGuI3iBwff/C4iImErx5Ccl1GZmZi1wqNNHX9uqQszMrBrDulJH0lHUnCoaEf/W9IrMzKylGjpGIGmBpJ8BTwDfobhBzbdKrMvMzFqk0YPFfw6cBjwWEXOAM4AflFaVmZm1TKNBsDsingUmSJoQEfcBnSXWZWZmLdLoMYJtkl4DfA/4e0nPAC+WV5YZ9Pf38/LOAfeHU6ItOweY0t9fdRlWsUaD4D5gGnA5cEF6fn1ZRTXTll1j64tka+rB8ohJbRVX0pgtuwYOuAWdmY09jQbBRODbwHPAncCdaVfRqNbR0VF1CcO2O/Vp3z5zZsWVNGYW5X3OM2bMYNfOl9z7aImWPr2Vdt8DPHuN3qHsz4A/k3QS8B7gO5J6I+IdpVZ3mMbizTb23dRk8eLFFVdiZrkYbhcTzwCbgWeBo5pfjpmZtVqj1xF8WNL9wD8DRwIXN3KbSjMzG/0aPUYwC/hoRPyoxFrMzKwCjR4juKbsQszMrBq+MY2ZWeYcBGZmmXMQmJllzkFgZpY5B4GZWeYcBGZmmXMQmJllzkFgZpa5Yd2z2MysasuWLaOvr6/p7famnn/3dfzYTB0dHaO6E0wHgZkZMHny5KpLqIyDwMzGlNH8y3qs8jECM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy1zpQSCpS9I6SeslXT3ENOdJWitpjaSvlV2TmZntV+oFZZLagBuBdwK9wCpJyyNibc00c4FrgLdFxFZJR5VZk5mZHajsK4vnA+sjYgOApDuAc4G1NdNcDNwYEVsBIuKZkms6bGX1dQJ593diZtUoe9dQB7Cp5nVvGlbrROBESd+X9ANJXYM1JOkSST2Sevr7+0sqt3qTJ0/Ous8TM2u90dDX0ERgLnA6MBP4rqRfjYhttRNFxE3ATQCdnZ3R4hoP4F/VZjaelL1F0AfMqnk9Mw2r1Qssj4jdEfEE8BhFMJiZWQuUHQSrgLmS5khqBxYBy+um+TrF1gCSplPsKtpQcl1mZpaUGgQRMQBcBtwDPArcFRFrJF0vaUGa7B7gWUlrgfuAqyLi2TLrMjOz/Uo/RhARK4AVdcOurXkewMfSw8zMWmw0HCw2G9KWXQMsfXpr1WU0ZOvuPQAcMamt4koat2XXwAEH8XK2fft2brnlFt7//vczderUqstpKQeBjVodHfVnGo9uu9M1IO0zZ1ZcSeNmMfY+57J0d3ezYcMGuru7Oe+886oup6UcBDZqjbXTdPddBLh48eKKK7Hh2r59OytXriQiePjhh+nq6spqq8CdzplZ9rq7u9m7dy8Ae/fupbu7u+KKWstBYGbZW716NXv2FMd49uzZQ09PT8UVtZaDwMyyd8opp9DWVhzkb2tro7Ozs+KKWstBYGbZ6+rqYsKE4utwwoQJdHUN2uXZuOUgMLPsTZs2jfnz5yOJU089NasDxeCzhszMgGKrYPPmzdltDYCDwMwMKLYKLr/88qrLqIR3DZmZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZa70IJDUJWmdpPWSrh5k/EWS+iX9KD0+WHZNZma238QyG5fUBtwIvBPoBVZJWh4Ra+smvTMiLiuzFjMzG1zZWwTzgfURsSEidgF3AOeW/J5mZjYMZQdBB7Cp5nVvGlZvoaQfS7pb0qzBGpJ0iaQeST39/f1l1GpmlqXRcLD4H4DZEXES8E/ArYNNFBE3RURnRHTOmDGjpQWamY1nZQdBH1D7C39mGvaKiHg2InamlzcDp5Rck5mZ1Sg7CFYBcyXNkdQOLAKW104g6ZialwuAR0uuyczMapR61lBEDEi6DLgHaAO+HBFrJF0P9ETEcmCxpAXAAPAccFGZNZmZ2YFKDQKAiFgBrKgbdm3N82uAa8quw8zMBld6EJiNNsuWLaOvr+/QEw5Tb28vAEuWLGl62wAdHR0sXLiwlLYtbw4CsyaZPHly1SWYjYiDwLLjX9VmBxoN1xGYmVmFHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOUVE1TUMm6R+YGPVdZRoOvDzqouwEfG6G9vG+/o7PiJ+4YYuYzIIxjtJPRHRWXUdNnxed2NbruvPu4bMzDLnIDAzy5yDYHS6qeoCbMS87sa2LNefjxGYmWXOWwRmZplzEJiZZc5BUAJJXZLWSVov6epBxk+WdGca/7Ck2TXjrknD10n67UO1KemyNCwkTS994TJT0rr8sqRnJP2kRYthjHxdSjpS0n2Sdkj6fMsLb4WI8KOJD6ANeBx4A9AOPALMq5vmw8CX0vNFwJ3p+bw0/WRgTmqn7WBtAicDs4EngelVL/94epSxLtO43wDeDPyk6mXM5XGY6/LVwK8BlwKfr3pZynh4i6D55gPrI2JDROwC7gDOrZvmXODW9Pxu4AxJSsPviIidEfEEsD61N2SbEfHDiHiy7IXKVBnrkoj4LvBcKxbAXjHidRkRL0bEA8DLrSu3tRwEzdcBbKp53ZuGDTpNRAwA24EjDzJvI21a85WxLq0ah7Muxz0HgZlZ5hwEzdcHzKp5PTMNG3QaSROBacCzB5m3kTat+cpYl1aNw1mX456DoPlWAXMlzZHUTnHQaXndNMuBP0jPfw+4N4qjUsuBRenshTnAXGBlg21a85WxLq0ah7Mux7+qj1aPxwdwFvAYxVkKn0jDrgcWpOdTgP9DcQBxJfCGmnk/keZbB5x5sDbT8MUU+zsHgKeAm6te/vH0KGld3g48DexO6+4DVS9nDo/DXJdPUhzg35HW2bxW11/mw11MmJllzruGzMwy5yAwM8ucg8DMLHMOAjOzzDkIzMwy5yAwawJJO6quwWykHARmJUlXp5qNeg4CsyaSdLqk70laDqytuh6zRvgXi1nzvRl4UxTdT5uNet4iMGu+lQ4BG0scBGbN92LVBZgNh4PAzCxzDgIzs8y591Ezs8x5i8DMLHMOAjOzzDkIzMwy5yAwM8ucg8DMLHMOAjOzzDkIzMwy9/8BE+0GbAU23YMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'lr'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92a3ac",
   "metadata": {},
   "source": [
    "## Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85ffa125",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron':[55],  #Done\n",
    "     'hidden_neuron':[50], #Done\n",
    "\n",
    "     'hidden_layers':[2], #Done  \n",
    "\n",
    "     \n",
    "    'epochs': [100000], # never touch it\n",
    "\n",
    "\n",
    "    'last_activation': ['sigmoid'], #never touch it\n",
    "\n",
    "\n",
    "    'batch_size': [64], #Done\n",
    "\n",
    "    'lr':[0.01,0.005,0.001,0.0005,0.0001],\n",
    "    \n",
    "    'kernel_regularizer_l1':[0.1,0.01,0.001,0.0001],\n",
    "    'kernel_regularizer_l2':[0.1,0.01,0.001,0.0001],\n",
    "    'bias_regularizer':[0.1,0.01,0.001,0.0001],\n",
    "    'activity_regularizer':[0.1,0.01,0.001,0.0001],\n",
    "\n",
    "  #  'dropout': [0,0.1,0.2,0.3,0.4],\n",
    "  'dropout': [0],\n",
    "\n",
    "  \n",
    "    'kernel_initializer': ['identity'],\n",
    "\n",
    "    'activation_layer':['tanh'],\n",
    " \n",
    "    'batc_normalization':[False], #Done\n",
    " \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a3ce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = ta.Scan(x=train_df, y=train_label,\n",
    "            x_val=test_df, y_val=test_label,\n",
    "            model=numerai_model,\n",
    "            params=p,  \n",
    "            experiment_name='Predykcja klasy M - Weighted binary cross-entropy (nowe)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "833e627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/Marze/OneDrive/Dokumenty/Jarek/Magisterka/Predykcja klasy M - Weighted binary cross-entropy (nowe)/050722160303.csv\", encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67dcf9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>1.973409</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.945398</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>1.328530</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.306939</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>0.837536</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.819942</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>569</td>\n",
       "      <td>0.777718</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759237</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1734</td>\n",
       "      <td>0.747680</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.728891</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>51</td>\n",
       "      <td>0.639333</td>\n",
       "      <td>[0.3082569]</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.706048</td>\n",
       "      <td>[0.29411766]</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>60</td>\n",
       "      <td>0.616276</td>\n",
       "      <td>[0.3159851]</td>\n",
       "      <td>0.188053</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.732050</td>\n",
       "      <td>[0.2962963]</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>150</td>\n",
       "      <td>0.588511</td>\n",
       "      <td>[0.34398034]</td>\n",
       "      <td>0.218069</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.613052</td>\n",
       "      <td>[0.18181817]</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>245</td>\n",
       "      <td>0.544577</td>\n",
       "      <td>[0.4311377]</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.590321</td>\n",
       "      <td>[0.34042552]</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>143</td>\n",
       "      <td>0.674269</td>\n",
       "      <td>[0.2981818]</td>\n",
       "      <td>0.176724</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.673283</td>\n",
       "      <td>[0.31007752]</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "0               78  1.973409          [0.]   0.000000  0.000000  1.945398   \n",
       "1              113  1.328530          [0.]   0.000000  0.000000  1.306939   \n",
       "2              353  0.837536          [0.]   0.000000  0.000000  0.819942   \n",
       "3              569  0.777718          [0.]   0.000000  0.000000  0.759237   \n",
       "4             1734  0.747680          [0.]   0.000000  0.000000  0.728891   \n",
       "...            ...       ...           ...        ...       ...       ...   \n",
       "1275            51  0.639333   [0.3082569]   0.183007  0.976744  0.706048   \n",
       "1276            60  0.616276   [0.3159851]   0.188053  0.988372  0.732050   \n",
       "1277           150  0.588511  [0.34398034]   0.218069  0.813953  0.613052   \n",
       "1278           245  0.544577   [0.4311377]   0.290323  0.837209  0.590321   \n",
       "1279           143  0.674269   [0.2981818]   0.176724  0.953488  0.673283   \n",
       "\n",
       "     val_fbeta_score  val_precision  val_recall activation_layer  ...  \\\n",
       "0               [0.]       0.000000    0.000000             tanh  ...   \n",
       "1               [0.]       0.000000    0.000000             tanh  ...   \n",
       "2               [0.]       0.000000    0.000000             tanh  ...   \n",
       "3               [0.]       0.000000    0.000000             tanh  ...   \n",
       "4               [0.]       0.000000    0.000000             tanh  ...   \n",
       "...              ...            ...         ...              ...  ...   \n",
       "1275    [0.29411766]       0.175439    0.909091             tanh  ...   \n",
       "1276     [0.2962963]       0.176991    0.909091             tanh  ...   \n",
       "1277    [0.18181817]       0.272727    0.136364             tanh  ...   \n",
       "1278    [0.34042552]       0.320000    0.363636             tanh  ...   \n",
       "1279    [0.31007752]       0.186916    0.909091             tanh  ...   \n",
       "\n",
       "      dropout  epochs  first_neuron  hidden_layers  hidden_neuron  \\\n",
       "0           0  100000            55              2             50   \n",
       "1           0  100000            55              2             50   \n",
       "2           0  100000            55              2             50   \n",
       "3           0  100000            55              2             50   \n",
       "4           0  100000            55              2             50   \n",
       "...       ...     ...           ...            ...            ...   \n",
       "1275        0  100000            55              2             50   \n",
       "1276        0  100000            55              2             50   \n",
       "1277        0  100000            55              2             50   \n",
       "1278        0  100000            55              2             50   \n",
       "1279        0  100000            55              2             50   \n",
       "\n",
       "      kernel_initializer  kernel_regularizer_l1  kernel_regularizer_l2  \\\n",
       "0               identity                 0.1000                 0.1000   \n",
       "1               identity                 0.1000                 0.1000   \n",
       "2               identity                 0.1000                 0.1000   \n",
       "3               identity                 0.1000                 0.1000   \n",
       "4               identity                 0.1000                 0.1000   \n",
       "...                  ...                    ...                    ...   \n",
       "1275            identity                 0.0001                 0.0001   \n",
       "1276            identity                 0.0001                 0.0001   \n",
       "1277            identity                 0.0001                 0.0001   \n",
       "1278            identity                 0.0001                 0.0001   \n",
       "1279            identity                 0.0001                 0.0001   \n",
       "\n",
       "      last_activation      lr  \n",
       "0             sigmoid  0.0100  \n",
       "1             sigmoid  0.0050  \n",
       "2             sigmoid  0.0010  \n",
       "3             sigmoid  0.0005  \n",
       "4             sigmoid  0.0001  \n",
       "...               ...     ...  \n",
       "1275          sigmoid  0.0100  \n",
       "1276          sigmoid  0.0050  \n",
       "1277          sigmoid  0.0010  \n",
       "1278          sigmoid  0.0005  \n",
       "1279          sigmoid  0.0001  \n",
       "\n",
       "[1280 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd71395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stare_wart=df['val_fbeta_score']\n",
    "nowe_wart=[]\n",
    "for x in stare_wart:\n",
    "    wart=x.replace('[','')\n",
    "    wart=wart.replace(']','')\n",
    "    wart=float(wart)\n",
    "    nowe_wart.append(wart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae673a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['val_fbeta_score']=nowe_wart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77e61463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values('val_loss',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6948938b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>178</td>\n",
       "      <td>0.577092</td>\n",
       "      <td>[0.41916165]</td>\n",
       "      <td>0.282258</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>187</td>\n",
       "      <td>0.576626</td>\n",
       "      <td>[0.43046358]</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.549616</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>185</td>\n",
       "      <td>0.587778</td>\n",
       "      <td>[0.42682928]</td>\n",
       "      <td>0.289256</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.551359</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>158</td>\n",
       "      <td>0.634653</td>\n",
       "      <td>[0.33718243]</td>\n",
       "      <td>0.210375</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.556054</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>243</td>\n",
       "      <td>0.608775</td>\n",
       "      <td>[0.42402828]</td>\n",
       "      <td>0.304569</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.565900</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>72</td>\n",
       "      <td>2.369912</td>\n",
       "      <td>[0.26299694]</td>\n",
       "      <td>0.151408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.624780</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>68</td>\n",
       "      <td>2.499672</td>\n",
       "      <td>[0.26299694]</td>\n",
       "      <td>0.151408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.698787</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>68</td>\n",
       "      <td>2.452354</td>\n",
       "      <td>[0.22155689]</td>\n",
       "      <td>0.149194</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>2.699582</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>76</td>\n",
       "      <td>2.438512</td>\n",
       "      <td>[0.22077921]</td>\n",
       "      <td>0.135638</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>2.733719</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>76</td>\n",
       "      <td>2.505921</td>\n",
       "      <td>[0.]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.743856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "1032           178  0.577092  [0.41916165]   0.282258  0.813953  0.532189   \n",
       "1118           187  0.576626  [0.43046358]   0.300926  0.755814  0.549616   \n",
       "557            185  0.587778  [0.42682928]   0.289256  0.813953  0.551359   \n",
       "551            158  0.634653  [0.33718243]   0.210375  0.848837  0.556054   \n",
       "558            243  0.608775  [0.42402828]   0.304569  0.697674  0.565900   \n",
       "...            ...       ...           ...        ...       ...       ...   \n",
       "1205            72  2.369912  [0.26299694]   0.151408  1.000000  2.624780   \n",
       "1120            68  2.499672  [0.26299694]   0.151408  1.000000  2.698787   \n",
       "1040            68  2.452354  [0.22155689]   0.149194  0.430233  2.699582   \n",
       "960             76  2.438512  [0.22077921]   0.135638  0.593023  2.733719   \n",
       "1200            76  2.505921          [0.]   0.000000  0.000000  2.743856   \n",
       "\n",
       "      val_fbeta_score  val_precision  val_recall activation_layer  ...  \\\n",
       "1032         0.368421       0.437500    0.318182             tanh  ...   \n",
       "1118         0.410256       0.470588    0.363636             tanh  ...   \n",
       "557          0.187500       0.300000    0.136364             tanh  ...   \n",
       "551          0.206897       0.428571    0.136364             tanh  ...   \n",
       "558          0.421053       0.500000    0.363636             tanh  ...   \n",
       "...               ...            ...         ...              ...  ...   \n",
       "1205         0.268293       0.154930    1.000000             tanh  ...   \n",
       "1120         0.268293       0.154930    1.000000             tanh  ...   \n",
       "1040         0.268293       0.154930    1.000000             tanh  ...   \n",
       "960          0.268293       0.154930    1.000000             tanh  ...   \n",
       "1200         0.000000       0.000000    0.000000             tanh  ...   \n",
       "\n",
       "      dropout  epochs  first_neuron  hidden_layers  hidden_neuron  \\\n",
       "1032        0  100000            55              2             50   \n",
       "1118        0  100000            55              2             50   \n",
       "557         0  100000            55              2             50   \n",
       "551         0  100000            55              2             50   \n",
       "558         0  100000            55              2             50   \n",
       "...       ...     ...           ...            ...            ...   \n",
       "1205        0  100000            55              2             50   \n",
       "1120        0  100000            55              2             50   \n",
       "1040        0  100000            55              2             50   \n",
       "960         0  100000            55              2             50   \n",
       "1200        0  100000            55              2             50   \n",
       "\n",
       "      kernel_initializer  kernel_regularizer_l1  kernel_regularizer_l2  \\\n",
       "1032            identity                 0.0001                 0.0010   \n",
       "1118            identity                 0.0001                 0.0001   \n",
       "557             identity                 0.0001                 0.0001   \n",
       "551             identity                 0.0001                 0.0010   \n",
       "558             identity                 0.0001                 0.0001   \n",
       "...                  ...                    ...                    ...   \n",
       "1205            identity                 0.1000                 0.0100   \n",
       "1120            identity                 0.1000                 0.1000   \n",
       "1040            identity                 0.1000                 0.1000   \n",
       "960             identity                 0.1000                 0.1000   \n",
       "1200            identity                 0.1000                 0.1000   \n",
       "\n",
       "      last_activation      lr  \n",
       "1032          sigmoid  0.0010  \n",
       "1118          sigmoid  0.0005  \n",
       "557           sigmoid  0.0010  \n",
       "551           sigmoid  0.0050  \n",
       "558           sigmoid  0.0005  \n",
       "...               ...     ...  \n",
       "1205          sigmoid  0.0100  \n",
       "1120          sigmoid  0.0100  \n",
       "1040          sigmoid  0.0100  \n",
       "960           sigmoid  0.0100  \n",
       "1200          sigmoid  0.0100  \n",
       "\n",
       "[1280 rows x 24 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b87572",
   "metadata": {},
   "source": [
    " ## 5.1 lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37df8a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of lr')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeg0lEQVR4nO3df5xddX3n8dc7mfxoBcaEBAKTaACxCoIxmQQw1rJrfwyKg7thESoEbDWr4ga3oFutRdfqbmtbdomsUmoFQUXEuHaqOGoXVKACmUn5YYIov7JMyI+RhBkCJGGST/84ZzJ3xpk7d+7cc8+9c9/Px+M+5n7Pz8/93jvnc77nfM85igjMzKyxTcs7ADMzy5+TgZmZORmYmZmTgZmZ4WRgZmY4GZiZGU4GNgZJIelV6ftrJf15KdOWsZ53SfpBuXFOZZLeL2mHpD2Sjqziej8m6YvVWl/Bev+DpKfSz/uGUcaX/Tuz8cnXGUxNkjqB+yLiyhHDzwH+DlgYEQNF5g/gxIh4tIR1lTStpMXAE8CMYuuuBElnAl+JiIVZricrkmYA/cDpEfFAhus5kxqpJ0mPAX8SEf84xviSf5M2cW4ZTF1fBi6UpBHDLwK+mvXG2CbtaGA2sCnvQKrolZT5eSVNr3AsDcfJYOr6NnAk8NuDAyTNAc4GbpS0QtJPJT0raZukayTNHG1Bkm6Q9OmC8ofTeZ6W9Ecjpn2bpH+V1J82+T9ZMPon6d9n00MBZ0i6RNJdBfO/UdIGSX3p3zcWjPuRpL+QdLek5yT9QNK8iVaMpNemy3pW0iZJ7QXj3ippc7r8rZKuSIfPk/SddJ5dku6UNOr/j6Sr08/eL6lbUuF3sEJSVzpuh6SrRpn/1cAjBXV1u6TF6WGSphH18Z70/SWS7pL0N5J2S3pC0lkF086VdH36ne2W9G1JLwO+Bxybfh97JB0r6ZOSvlIwb3taT8+m63xtwbgnJV0h6cH0O7tF0uwx6mWapI9L2iJpp6QbJTVLmiVpDzAdeCBtIRSV/ia/IOk2Sc8D/268eWwcEeHXFH0Bfw98saD8n4H70/fLgNOBJmAx8DDwoYJpA3hV+v4G4NPp+zZgB/A64GXA10ZMeyZwCsmOxqnptO9Ixy1Op20qWM8lwF3p+7nAbpLWSxNwQVo+Mh3/I+Ax4NXAb6Tlvxzjs58J9IwyfAbwKPAxYCbw74HngN9Kx28Dfjt9PwdYmr7/n8C16fwzSJKsxlj3hSSJuAm4HNgOzE7H/RS4KH1/GMlhoNGWMayuxqi7HwHvKajHl4D3kmxU3w88zdCh4O8Ct6SfaQbwO2PVE/BJkkNHpHX9PPB76XwfSetvZjr+SeA+4Nj0+3sYeN8Yn+mP0nmPTz/7t4CbRvvNjTH/yN9kH7CS5Lc2O+//t3p/uWUwtX0ZOLdgT211OoyI6I6IeyJiICKeJDmP8DslLPM84PqI+FlEPE+y4TgkIn4UEQ9FxMGIeBC4ucTlArwN+GVE3JTGdTPwc+DtBdNcHxG/iIgXgW8AS0pc9qDTSTZEfxkR+yPiduA7JIkHkg3qSZKOiIjdEbGxYPgxwCsj4qWIuDPSrdJIEfGViHgm/Qx/C8wCfqtgOa+SNC8i9kTEPROMv5gtEfH3EXGA5Hs+Bjha0jHAWSQb6d1p/D8ucZnvBL4bET+MiJeAvyFJxG8smGZdRDwdEbuAf2Ls7+RdwFUR8XhE7AE+Cpxf2NqZoH+MiLvT39reMpdhKSeDKSwi7gJ+BbxD0gnACpI9eSS9Oj3ssV1SP/A/gFIOuRwLPFVQ3lI4UtJpku6Q1CupD3hficsdXPaWEcO2AC0F5e0F718g2bBPxLHAUxFxcIx1rALeCmyR9GNJZ6TD/5pkr/YHkh6X9KdjrSA9bPJwetjkWaCZoTr4Y5K97Z+nh8HOnmD8xRyqm4h4IX17GLAI2BURu8tY5rDvJK23pyjvOxn5/W4haT0dXUZcMPx3aJPkZDD13UjSIrgQ+H5E7EiHf4Fkr/vEiDiC5LDJyJPNo9lGsnEZ9IoR478GdACLIqKZ5NDK4HLH67r2NMlJxEKvALaWEFepngYWjTjef2gdEbEhIs4BjiI57/KNdPhzEXF5RBwPtAN/IuktIxeenh/4CEkLak5EvJzkcIbS5fwyIi5Il/9XwDfTY/fjeT79+5sFwxaU9ImTjeZcSS8fZdyEvhNJIvn+y/lORn6/rwAGSA4llsNdISvIyWDquxH4XZJjyV8uGH44SdfFPZJeQ3KMuRTfAC6RdJKk3wQ+MWL84SR7oXslrQD+sGBcL3CQ5JjxaG4DXi3pDyU1SXoncBLJYZyySJpd+CI5vv0C8BFJM5R0rXw78HVJM5Vc99CcHhLpT+NF0tmSXpVuDPuAA4PjRvn8A+lnbZJ0JXBEQTwXSpqf7mE/mw4ebTnDREQvyQb4QknTlZy4P6GUOoiIbSQnij8vaU76ud+cjt4BHCmpeYzZvwG8TdJblHR3vRzYB/xLKese4Wbgv0o6TtJhJK3RW8I922qCk8EUl54P+BeSk70dBaOuINlQP0dyovmWEpf3PeB/A7eTHDa5fcQkHwA+Jek54ErSPet03heAzwB3pz1TTh+x7GdIejtdDjxDsod9dkT8qpTYRtECvDjitYhk438WySG0zwOrI+Ln6TwXAU+mh87eR3KcG+BE4J+BPSQngT8fEXeMss7vA53AL0gOg+xl+OGMNmBT2nvmauD89PxHKd4LfJikbk5mYhvki0jOV/wc2Al8CCD93DcDj6ffybGFM0XEIyStys+R1NfbgbdHxP4JrHvQl4CbSHqVPUFSN/+ljOVYBnzRmZmZuWVgZmZOBmZmhpOBmZnhZGBmZiQXfNSdefPmxeLFi/MOw8ysrnR3d/8qIuaPNq4uk8HixYvp6urKOwwzs7oiaeQV/of4MJGZmTkZmJmZk4GZmeFkYGZmOBmYmWWqr6+Pq6++mv7+/rxDKcrJwMwsQx0dHTz22GN0dHSMP3GOnAzMzDLS19dHd3c3AF1dXTXdOnAyMDPLSEdHBwcPJo+rOHjwYE23DpwMzMwysnHjxmHlwVZCLXIyMDMzJwMzs6y85jWvGVZ+7Wtfm1Mk43MyMDPLyM6dO4eVd+zYkVMk43MyMDPLSG9vb9FyLXEyMDPLyIIFC4qWa4mTgZlZRlavXj2sfPHFF+cUyficDMzMMrJw4ULmz0+eJXPUUUfR0tKSc0RjczIwM8vQscceO+xvrXIyMDPLSF9fH5s3bwZg06ZNvh2FmVkj6uzsHHY7is7OzpwjGpuTgZlZRrq7uzlw4AAABw4cqOlntzsZmJllZNmyZUgCQBKtra05RzQ2JwMzs4ysXLmSiAAgIli5cmXOEY3NycDMLCN333130XItcTIwM8vIyFtW+5yBmVkDOuWUU4aVTz311JwiGZ+TgZmZORmYmWXlwQcfHFZ+4IEHcopkfJkmA0mLJN0habOkTZIuG2WaMyX1Sbo/fV2ZZUxmZtVy2GGHFS3XkqaMlz8AXB4RGyUdDnRL+mFEbB4x3Z0RcXbGsZiZVdUzzzxTtFxLMm0ZRMS2iNiYvn8OeBio3dv2mZk1qKqdM5C0GHgDcO8oo8+Q9ICk70k6eYz510jqktRVy08LMjMbNGvWrKLlWlKVZCDpMGA98KGIGHnbvo3AKyPi9cDngG+PtoyIuC4iWiOidfD+4GZmtWz//v1Fy7Uk82QgaQZJIvhqRHxr5PiI6I+IPen724AZkuZlHZeZWdamTZtWtFxLsu5NJOAfgIcj4qoxplmQToekFWlMtXuWxcysREuXLh1WXrZsWU6RjC/r3kQrgYuAhyTdnw77GPAKgIi4FjgXeL+kAeBF4PwYvLOTmVkda29vp6uri4hAEu3t7XmHNKZMk0FE3AVonGmuAa7JMg4zszw0NzfT2trKhg0bWL58OUcccUTeIY2pdg9gmZlNAcuXL0cSy5cvzzuUopwMzMwydOuttxIR3HrrrXmHUpSTgZlZRnp6ehi8Lmrnzp1s3bo154jG5mRgZpaR66+/vmi5ljgZmJllZOTdEnbu3JlTJONzMjAzMycDM7OsvP71rx9WXrJkST6BlMDJwMwsI+eee27Rci1xMjAzy0hzc/Oh1sGSJUtq+qKzrG9HYWbW0M4991z27NlT060CcDIwMyvZ+vXrJ3ytwGCPohtuuGHC62tpaWHVqlUTnq8cTgZmZhnat29f3iGUxMnAzKxE5eylr1u3DoC1a9dWOpyK8glkMzNzMjAzMycDMzPDycDMzHAyMDMznAzMzAwnAzMzw8nAzMxwMjAzM5wMzMwMJwMzM8PJwMzMcDIwMzOcDMzMDCcDMzPDycDMzHAyMDMznAzMzAwnAzMzw8nAzMxwMjAzM5wMzMwMJwMzMyPjZCBpkaQ7JG2WtEnSZaNMI0nrJD0q6UFJS7OMyczMfl1TxssfAC6PiI2SDge6Jf0wIjYXTHMWcGL6Og34QvrXzMyqJNOWQURsi4iN6fvngIeBlhGTnQPcGIl7gJdLOibLuMzMbLiqnTOQtBh4A3DviFEtwFMF5R5+PWEgaY2kLkldvb29mcVpZtaIqpIMJB0GrAc+FBH95SwjIq6LiNaIaJ0/f35lAzQza3CZJwNJM0gSwVcj4lujTLIVWFRQXpgOMzOzKsm6N5GAfwAejoirxpisA1id9io6HeiLiG1ZxmVmZsNl3ZtoJXAR8JCk+9NhHwNeARAR1wK3AW8FHgVeAN6dcUxmZjZCpskgIu4CNM40AVyaZRxmZlacr0A2MzMnAzMzczIwMzOcDMzMDCcDMzPDycDMzHAyMDMznAzMzAwnAzMzI/vbUZhZnVu/fj1bt07s3pGDt5kv5w7DLS0trFq1asLz2eSU1DKQ9J/SJ5Uh6eOSvuXHU5rZWPbt28e+ffvyDsMmoNSWwZ9HxK2S3gT8LvDX+PGUZg2hnL30devWAbB27dpKh2MZKfWcwYH079uA6yLiu8DMbEIyM7NqKzUZbJX0d8A7gdskzZrAvGZmVuNK3aCfB3wf+IOIeBaYC3w4q6DMzKy6Sj1ncAzw3YjYJ+lM4FTgxqyCMjOz6iq1ZbAeOCDpVcB1JM8s/lpmUZmZWVWVmgwORsQA8B+Bz0XEh0laC2ZmNgWUmgxeknQBsBr4TjpsRjYhmZlZtZWaDN4NnAF8JiKekHQccFN2YZmZWTWVlAwiYjNwBfCQpNcBPRHxV5lGZmZmVVNSb6K0B9GXgScBAYskXRwRP8ksMjMzq5pSu5b+LfD7EfEIgKRXAzcDy7IKzMzMqqfUcwYzBhMBQET8Ap9ANjObMkptGXRJ+iLwlbT8LqArm5DMzKzaSk0G7wcuBQZvQXgn8PlMIjIzs6orKRlExD7gqvRlZmZTTNFkIOkhIMYaHxGnVjwiMzOruvFaBmdXJQozM8tV0WQQEVtKWYikn0bEGZUJyczMqq1SD6iZXaHlmJlZDiqVDMY8r2BmZrXPj640M7OKJQNVaDlmZpaDSiWDiyq0HDMzy0HRZCDpOUn9o7yek9Q/OF1E/GyM+b8kaaekscafKalP0v3p68rJfRwzMyvHeF1LD5/k8m8ArgFuLDLNnRHh6xnMzHJU6r2JAJB0FAXdSCPi/xebPiJ+ImlxeaGZmVm1lHTOQFK7pF8CTwA/JnnIzfcqFMMZkh6Q9D1JJxeJYY2kLkldvb29FVq1mZlB6SeQ/wI4HfhFRBwHvAW4pwLr3wi8MiJeD3wO+PZYE0bEdRHRGhGt8+fPr8CqzcxsUKnJ4KWIeAaYJmlaRNwBtE525RHRHxF70ve3ATMkzZvscs3MbGJKPWfwrKTDSJ5j8FVJO4HnJ7tySQuAHRERklaQJKdnJrtcMzObmFKTwR1AM3AZcGH6/lPjzSTpZuBMYJ6kHuATpI/LjIhrgXOB90saAF4Ezo8I39rCzKzKSk0GTcAPgF3ALcAt6WGjoiLignHGX0PS9dTMzHJU0jmDiPjvEXEyyaMvjwF+LOmfM43MzMyqZqK3o9gJbCc5rn9U5cMxM7M8lHqdwQck/Qj4f8CRwHv9yEszs6mj1HMGi4APRcT9GcZiZmY5KSkZRMRHsw7EzMzyM6F7E5mZTRXr169n69atma+np6cHgHXr1mW+LoCWlhZWrVo14fmcDMysIW3dupWnHn+Mo2dmuxmc8dIBAPb3bMl0PQA79g+UPa+TgZk1rKNnNrH6mDl5h1ExN27bXfa8fgaymZk5GZiZmZOBmZnhZGBmZjgZmJkZTgZmFdXX18fVV19Nf39/3qGYTYiTgVkFdXZ28vjjj9PZ2Zl3KGYT4usMzCqkr6+Pe++9l4jgnnvuoa2tjSOOOCLvsIbxVbc2FicDswrp7OzkwIHkatMDBw7Q2dnJeeedl3NUw/mqWxuLk4FZhXR1dTH41NaIYMOGDTWXDMBX3drofM7AJs0nTRNz5swpWjarZU4GZfIGcIhPmiZ2795dtGxWy5wMyuQNYKKvr4/77ruPiODee+9t6OTY2to6rLx8+fKcIjGbOCeDMngDOKSzs5ODBw8CcPDgwYZOjm1tbTQ1JafhmpqaaGtryzkis9I5GZTBG8Ah3d3dw3rQdHV15RxRfpqbmznttNOQxOmnn15z3UrNinEyKIM3gEOWLVuGJAAk/dqhkkbT1tbG8ccf71aB1R0ngzJ4Azhk5cqVw7pTrly5MueI8tXc3Mxll13mVoHVHSeDMngDOOTuu+8uWjaz+uBkUAZvAId0d3cPKzfyITOzeuZkUAZvAIcsW7aM6dOnAzB9+vSGPmRmVs+cDMrgDeCQtrY2pk1LfkbTpk3ziVOzOuVkUAZvAIc0NzezYsUKJHHaaaf5xKlZnXIyKIM3gMO5O6VZ/fNdS8vU1tbG9u3bvQFkqDulmdUvJ4MyeQNoZlOJDxOVyXctNbOpxMmgTL5rqZlNJU4GZfBdS81sqsk0GUj6kqSdkn42xnhJWifpUUkPSlqaZTyV4ruWDudDZmb1L+uWwQ1Ase42ZwEnpq81wBcyjqcifNfS4To6Onjsscfo6OjIOxQzK1OmySAifgLsKjLJOcCNkbgHeLmkY7KMqRJ8BfKQvr6+Q7fn6OrqavjWgVtJVq/yPmfQAjxVUO5Jh/0aSWskdUnq6u3trUpwY2lraxt219JGvtago6Nj2CGzRm8duGOB1au8k0HJIuK6iGiNiNb58+fnHc6wZNDINm7cOKw88iZ+jcQdC6ye5Z0MtgKLCsoL02E1rbOzc9jDbbwXaOCOBVbf8k4GHcDqtFfR6UBfRGzLOaZxdXd3D/unb+QTyEuXDu8AtmzZspwiyZ87Flg9y/R2FJJuBs4E5knqAT4BzACIiGuB24C3Ao8CLwDvzjKeSjnllFPYsGHDofKpp56aYzT5am9vp6uri4hAEu3t7XmHVBHr169n69aJNVJnzpzJ3r17h5XXrVtX0rwtLS2sWrVqQuszq6RMk0FEXDDO+AAuzTKGLLzwwgtFy42kubmZefPm0dvby7x58xr6Dq5z5849dJ5AEnPnzs05IrPS+UZ1Zdi8efOw8qZNm3KKJH99fX3s2pX0Ht61axf9/f1TIiGUu5f+8Y9/nP7+flauXMl5551X4ajMspP3OYO6NLIHUSP3KOrs7Bx2nLzRT5rOnTuX2bNnN3R3Y6tPTgZlmD17dtFyIyk8dwJw33335RRJbWhqamLhwoVTonVkjcXJoAwDAwNFy41k8ErsscpmVh+cDMrQ1NRUtNxIXnzxxaJlM6sPTgZlKOw+OFq5kSxYsKBo2czqg5OBTcrq1auHlS+++OKcIjGzyXAysElZuHDhodbAggULaGkZ9T6DZlbjnAzKMPJioiOPPDKnSGrD6tWrmT17tlsFZnWscc98TsLu3buHlQcvumpUCxcu5LOf/WzeYZjZJDgZlMEXndWXcu4zVK6enh6Aku9JNBm+n5FVkpOBTXlbt27lqccf4+iZ2f/cZ7yUXI29v2dLpuvZsb9xr22plN7eXvbuG+DGbbvHn7hO7Ng3wOwyH/7lZGCHlLsHPfjkuYk+dKiae7ZHz2xi9TFzqrKuaphKGzCrDQ2fDCp1CKGRb1W8b9++vEMwm7D58+ezf98LU24nYWaZT4Js+GRgQ8pNUoOJcO3atZUMx8yqqOGTQTkbwCuvvJJnn332UHnOnDk1tyH0SVMbjY+T21gaPhmUY82aNcO6Uq5ZsybHaEbnk6ZmNhFTKhlUc2940LRp01i/fn2m6yh3b9gnTW0kHye3sUypZFDNveHfELwYcFSTMt0j9t6wmVXDlEoGvb29UKXrv+bPmlGdFcVQ182J8LHhIa4LG8uO/dn/Lnanh1HnzMj+WR879g+wqMx5p1QyANgfwY592e9ND6RXHTdJma5nfwTlPkfNdTF8XtdFwhvARLVuqvhS2sFi5sKFma9rEeV/rimVDJYsWVL1HjQLq/AFl/Plui6GuC4mN0856mEDWK1eafXS9XpKJYNqdjm86qqr2L59O5dccklNPu+2mnVR6z9218UQbwBtLL6FdZl27drF3r176ezszDsUM7NJm1Itg3KU0x11YGCA/v5+AO666y56enpKfg6yL5oyq1/lbC8mc1FmNbcXbhmUYeTzCxr9eQYDAwP09PQcSpBmNmTWrFnMmjUr7zDG1fAtg3Ky7hVXXDGsvHfv3oY+Nrp9+3b27t3LTTfdxKWXXpp3OGaZmcqtercMyqAR3QZHlhtJX18fe/fuBeCRRx5x68CsTjV8y6AcI2/ZPFVu4TyZ46GDPv3pT5fcrdLnT8xqh1sGNimDrYKxymZWH9wysEPK2Usf7VxJI58/MatXbhmYmZmTQTmmTZtWtGxmVm98mKgMy5YtY8OGDYfKra2tOUZjlq2pfKGVDfEubRna29uLls0aXb1caGVD3DIoQ3NzM8uXL2fDhg2sWLGiJm9UVy0nnXQSmzdvPlQ++eSTc4ymcsp9al65e8S1vDdcq3FZZWXeMpDUJukRSY9K+tNRxl8iqVfS/enrPVnHVAnt7e2ccMIJDd8quOCCC4qWG433iK1eZdoykDQd+D/A7wE9wAZJHRGxecSkt0TEB7OMpdKam5u57LLL8g4jd83NzYdaByeffPKUaSV5b9gaTdYtgxXAoxHxeETsB74OnJPxOq3KLrjgAk444YSGbxWY1bOsk0EL8FRBuScdNtIqSQ9K+qakUZ9gJ2mNpC5JXeU8E9iyM9hKmiqtArNGVAu9if4JWBwRpwI/BL482kQRcV1EtEZE6/z586saoJnZVJd1MtgKw55VvTAddkhEPBMRg3d6+yKwLOOYzMxshKyTwQbgREnHSZoJnA90FE4g6ZiCYjvwcMYxmZnZCJn2JoqIAUkfBL4PTAe+FBGbJH0K6IqIDmCtpHZgANgFXJJlTGZm9usUEXnHMGGtra3R1dWVdxhmZnVFUndEjHr/nFo4gWxmZjmry5aBpF5gS95xAPOAX+UdRI1wXQxxXSRcD0NqpS5eGRGjdsesy2RQKyR1jdXkajSuiyGui4TrYUg91IUPE5mZmZOBmZk5GUzWdXkHUENcF0NcFwnXw5CarwufMzAzM7cMzMzMycDMzGjwZFDCU9hmSbolHX+vpMUF4z6aDn9E0h+Mt0xJH0yHhaR5mX+4CapyXdwg6YmCp9styfrzlSujevmSpJ2Sflalj1ERGdXFk5IeSn8HdXlbgXLrRdKRku6QtEfSNVUPfKSIaMgXyb2SHgOOB2YCDwAnjZjmA8C16fvzSZ7IBnBSOv0s4Lh0OdOLLRN4A7AYeBKYl/fnz7kubgDOzftz51Ev6bg3A0uBn+X9GWugLmru/6GK9fIy4E3A+4Br8v4sjdwyKOUpbOcw9HyFbwJvkaR0+NcjYl9EPAE8mi5vzGVGxL9GxJNZf6gyVbUu6kgW9UJE/ITkpoz1JJO6mALKrpeIeD4i7gL2Vi/csTVyMijlKWyHpomIAaAPOLLIvKU+2a3W5FEXn0mfbve/JNXqE+SzqJd6lVVdBPADSd2S1mQQd9YmUy81pZGTgeXno8BrgOXAXOC/5RuO5ehNEbEUOAu4VNKb8w6oUTVyMhj3KWyF00hqApqBZ4rMW8oya1FV6yIitkViH3A9tXvIIIt6qVeZ1EVEDP7dCfxfave3MJbJ1EtNaeRkMO5T2NLyxen7c4HbIznz0wGcn/YSOA44EbivxGXWoqrWhdKn26XHk98B1GqvmizqpV5VvC4kvUzS4QCSXgb8PrX7WxjLZOqltuR9BjvPF/BW4BckvQH+LB32KaA9fT8buJXkhNd9wPEF8/5ZOt8jwFnFlpkOX0tyPHEAeBr4Yt6fP8e6uB14iOQf/yvAYXl//irXy83ANuCl9Dfxx3l/zjzqgqQHzgPpa1Phb6SeXpOslydJOhPsSX8LJ1U7/sGXb0dhZmYNfZjIzMxSTgZmZuZkYGZmTgZmZoaTgZmZ4WRgVhGS9uQdg9lkOBmYZSS92tSsLjgZmFWQpDMl3SmpA9icdzxmpfKei1nlLQVeF8ntms3qglsGZpV3nxOB1RsnA7PKez7vAMwmysnAzMycDMzMDN+11MzM3DIwMzOcDMzMDCcDMzPDycDMzHAyMDMznAzMzAwnAzMzA/4NyGiDDdyp1gIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'lr'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "475c2ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 1.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgmklEQVR4nO3de5zddX3n8dc7M0lYgYwhF4FJENCgZZVCMiRobKWrdg9eghVWwSpiVdYLglbtekWb1tW6li6poEUWBW25rOm205oOdkvwVpDMIBcDBmMAM4HAEMJAkNw//eP3m8yZ48zk/M7Mb87l934+HvOY87t/ft85cz7ne/n9fooIzMysuKbVOwAzM6svJwIzs4JzIjAzKzgnAjOzgnMiMDMrOCcCM7OCcyKwUUkKSS9MX39N0meqWbeG4/yhpO/VGmcrk/Q+SY9K2iFpzhQe95OSrpqq45Ud9w8kbU7P95RRltf8PrPxydcRtCZJPcDtEXFJxfwzgb8BFkTE3nG2D2BRRGys4lhVrSvpWOABYPp4x54Mkk4Hvh0RC/I8Tl4kTQeeAk6LiLtyPM7pNEg5Sfol8McR8Y9jLK/6PWnZuEbQuq4B3iZJFfPfDvxt3h/ENmHPAw4B1tc7kCn0fGo8X0ltkxxLoTgRtK5/AOYAvzM0Q9Js4PXAtZKWSrpV0pOSHpH0FUkzRtuRpG9K+vOy6Y+l2zws6Y8q1n2dpJ9Keiqt5n+ubPEP0t9PptX/l0k6X9KPyrZ/uaR1kgbT3y8vW3aLpD+T9GNJT0v6nqS5WQtG0m+l+3pS0npJK8qWvVbSven+t0j6aDp/rqR/Trd5QtIPJY36/yPpsvTcn5LUJ6n8b7BUUm+67FFJl46y/QnAhrKyulnSsWnTSHtFebw7fX2+pB9J+rKk7ZIekHRG2bpHSPpG+jfbLukfJB0K/AtwdPr32CHpaEmfk/Ttsm1XpOX0ZHrM3ypb9qCkj0q6O/2b3SDpkDHKZZqkT0t6SNJjkq6V1CFppqQdQBtwV1ozGFf6nvyqpDWSngF+72Db2Dgiwj8t+gN8HbiqbPq/A3emr5cApwHtwLHAfcCHytYN4IXp628Cf56+LgGPAi8BDgX+rmLd04GXknzJOCld943psmPTddvLjnM+8KP09RHAdpJaSztwbjo9J11+C/BL4ATgP6XTXxzj3E8H+keZPx3YCHwSmAH8F+Bp4EXp8keA30lfzwYWp6+/AHwt3X46SYLVGMd+G0kSbgc+AmwFDkmX3Qq8PX19GEnTz2j7GFFWY5TdLcC7y8pxD/Aekg/U9wEPM9z8+13ghvScpgOvHKucgM+RNBeRlvUzwGvS7f4kLb8Z6fIHgduBo9O/333Ae8c4pz9Ktz0+Pfe/B7412ntujO0r35ODwHKS99oh9f5/a+Yf1wha2zXA2WXf0M5L5xERfRFxW0TsjYgHSfoNXlnFPt8MfCMifhYRz5B8aBwQEbdExD0RsT8i7gauq3K/AK8DfhER30rjug74OfCGsnW+ERH3R8SzwI3AyVXue8hpJB9CX4yI3RFxM/DPJEkHkg/TEyXNiojtEXFH2fyjgOdHxJ6I+GGkn0iVIuLbEbEtPYe/BGYCLyrbzwslzY2IHRFxW8b4x/NQRHw9IvaR/J2PAp4n6SjgDJIP6O1p/N+vcp9vAb4bEf8aEXuAL5Mk4ZeXrbMqIh6OiCeAf2Lsv8kfApdGxKaI2AF8AjinvJaT0T9GxI/T99rOGvdhuGmopUXEj4DHgTdKegGwlOQbPJJOSJs6tkp6CvifQDXNLEcDm8umHypfKGmZpLWSBiQNAu+tcr9D+36oYt5DQGfZ9Nay178m+VDP4mhgc0TsH+MYZwGvBR6S9H1JL0vn/y+Sb7Pfk7RJ0sfHOkDaVHJf2lTyJNDBcBm8i+Rb9s/Tpq/XZ4x/PAfKJiJ+nb48DFgIPBER22vY54i/SVpum6ntb1L5932IpNb0vBrigpHvQ5sAJ4LWdy1JTeBtwE0R8Wg6/6sk37YXRcQskqaSyo7l0TxC8sEy5JiK5X8HdAMLI6KDpDllaL8HG6L2MEmHYbljgC1VxFWth4GFFe37B44REesi4kxgPkk/y43p/Kcj4iMRcTywAvhjSa+q3HnaH/AnJDWn2RHxXJImDKX7+UVEnJvu/y+A76Rt9QfzTPr7OWXzjqzqjJMPzCMkPXeUZZn+JpJE8vev5W9S+fc9BthL0nxYCw95nCROBK3vWuDVJG3H15TNP5xkeOIOSS8maVOuxo3A+ZJOlPQc4LMVyw8n+fa5U9JS4K1lywaA/SRtxKNZA5wg6a2S2iW9BTiRpOmmJpIOKf8hac/+NfAnkqYrGT75BuB6STOUXNfQkTaDPJXGi6TXS3ph+kE4COwbWjbK+e9Nz7Vd0iXArLJ43iZpXvrN+sl09mj7GSEiBkg+fN8mqU1JJ/0LqimDiHiEpFP4Ckmz0/P+3XTxo8AcSR1jbH4j8DpJr1IypPUjwC7g36s5doXrgA9LOk7SYSS10BvCI9jqzomgxaXt//9O0rHbXbbooyQf0k+TdCrfUOX+/gX438DNJE0lN1es8n5gpaSngUtIv1Gn2/4a+Dzw43QEymkV+95GMqrpI8A2km/Wr4+Ix6uJbRSdwLMVPwtJPvjPIGk2uwI4LyJ+nm7zduDBtLnsvSTt2gCLgP8P7CDp8L0iItaOcsybgB7gfpKmj52MbMIoAevTUTKXAeek/R3VeA/wMZKy+c9k+zB+O0n/xM+Bx4APAaTnfR2wKf2bHF2+UURsIKlN/jVJeb0BeENE7M5w7CFXA98iGT32AEnZfLCG/dgk8wVlZmYF5xqBmVnB5ZoIJF2dXjjyszGWS9IqSRvTC1IW5xmPmZn9prxrBN8kaRMdyxkkba+LgAtIRrKYmdkUyjURRMQPgCfGWeVM4NpI3AY8N734xczMpkitV/RNlk5GjqjoT+c9UrmipAtIag0ceuihS1784hdPSYA2vu3bt7Njxw4OO+wwZs+eXe9w7CAee+wxYvdu5kxvnXu0bduzD82Ywfz58zNtV8Sy6Ovrezwi5lXOr3ciqFpEXAlcCdDV1RW9vb11jsgGBwdZuXIle/bsYfr06Xz2s59l1qxZB9/Q6mbVqlXs7n+I845qnaR97SPbmbHg+Vx00UWZtitiWUiqvHIfqP+ooS2MvEp1AZN7FanlqKenh/37k2uh9u/fT09PT50jMrNa1DsRdAPnpaOHTgMG06sgrQn09fWxb98+APbt24draWbNKe/ho9eRXIX5Ikn9kt4l6b2S3puusgbYRHKF6tdJrkq1JrFkyRLa2pL21ba2Nrq6uuockZnVItc+gvTmWuMtD+ADecZg+SmVStx6661A8lyLUmm8kcJm1qjq3TRkTW7oFiW+VUnSeX7ZZZfx1FNP1TsUs0ycCKxmPT09KH0ksqTCdxb39PSwadOmwpeDNR8nAqtZX1/fiFFDRe4sHhwc5Pbbbyci+MlPfuJagTUVJ4IauAkg4c7iYR5Ka83MiaAGbgJIlEolpk1L3kLTpk0rdGexh9JaM3MiyMhNAMM6OjpYunQpkli2bFmhryp27ciamRNBRm4CGKlUKnH88ccXujYArh1Zc3MiyMhNACN1dHRw8cUXF7o2AK4dWXNzIsjITQA2FteOrFk5EWTkJgAbi2tH1qycCDJyE4CZtZqmeR5BIymVSmzdutW1ATNrCU4ENRhqAjAzawVuGqqBryw2s1biGkENyq8sfvOb31zvcCwHq1evZsuWbA/LGxgYAGDevN94JOxBdXZ2ctZZZ2XezmwyuEaQka8strHs2rWLXbt21TsMs8xcI8hotCuLXStoPbV8O1+1ahVA5oeom9WbawQZ+cpiM2s1TgQZ+cpiM2s1TgQZlUqlEY9n9LUEZtbsnAhq4Of0mlkrcSLIqKenZ0QiKPptqM2s+TkRZFTZObxu3bo6RdIYfHGdWfNzIsho9uzZ404XjR/badb8nAgy2r59+7jTReKL68xagxNBRpXDRU899dQ6RVJ/fmynWWtwIsioVCrR3p5ckN3e3l7o4aO+uM6sNeSeCCSVJG2QtFHSx0dZ/nxJ/ybpbkm3SFqQd0wT0dHRwSmnnALA4sWLC/1gGl9cZ9Yack0EktqAy4EzgBOBcyWdWLHal4FrI+IkYCXwhTxjssnjx3aatYa8awRLgY0RsSkidgPXA2dWrHMicHP6eu0oyxvK4OAgd955JwA//elPC91B6sd2mrWGvBNBJ7C5bLo/nVfuLuBN6es/AA6XNCfnuGrmDtKRli9fzsyZM1m+fHm9QzGzGjVCZ/FHgVdK+inwSmALsK9yJUkXSOqV1Dv0AJB6cAfpSGvXrmXnzp2sXbu23qGYWY3yTgRbgIVl0wvSeQdExMMR8aaIOAX4VDrvycodRcSVEdEVEV21PAFqsriDdNjg4CB9fX1AcsV1kZvJzJpZ3olgHbBI0nGSZgDnAN3lK0iaK2kojk8AV+cc04S4g3RYd3f3iGay7u7ug2xhZo0o10QQEXuBC4GbgPuAGyNivaSVklakq50ObJB0P/A84PN5xjRR7iAddscdd4yYHqodmFlzyf1RlRGxBlhTMe+SstffAb6TdxyTafny5fT19bmD1MxaQiN0Fjcdd5AmFi9ePGJ6yZIldYrEzCbCiSAjd5AOW7FiBZIAkMSKFSsOsoWZNSIngozcQTqso6PjwKipU089tdD9JWbNzIkgI3eQjrRixQpe8IIXuDZg1sRy7yxuNZXPKS76c4s7Ojq4+OKL6x2GmU2AawQZzZkzZ9xpM7Nm40SQUWXncJE7i82sNTgRZOQnlJlZq3EiyMhPKDOzVuNEkJGfUGZmrcaJwMys4JwIMvITysys1TgRZOQnlJlZq3EiyMhPKDOzVuNEkJGfUGZmrcaJIKNSqTTijpsePmpmzc6JIKOOjg7mzp0LwNy5cz181MyanhNBRoODgzz++OMAPP744x41ZGZNz4kgo56engN3HI0Ijxoys6bnRJCRRw2ZWatxIsjIo4bMrNU4EWTkUUNm1mqcCDLyqCEzazVOBBkNDg4yMDAAwMDAgEcNmVnTcyLIyPcaMrNW40SQUW9v74jho+vWratzRGZmE+NEkNHs2bPHnTYzazZOBBlt27Zt3Gkzs2bTnvcBJJWAy4A24KqI+GLF8mOAa4Dnput8PCLW5B1Xrdrb29mzZ8+IaWtsq1evZsuWLbkfp7+/H4BVq1blfiyAzs5OzjrrrCk5lrW2XD/FJLUBlwOvAfqBdZK6I+LestU+DdwYEV+VdCKwBjg2z7gm4tlnnx132hrPli1b2LzplzxvRr5Je/qe5Irz3f0P5XocgEd37839GK1uYGCAnbv2cu0j2+sdyqR5dNdeDklHNWaR99fZpcDGiNgEIOl64EygPBEEMDQYvwN4OOeYJuTII49k69atI6at8T1vRjvnHdU6/Tmt9OFl9Zd3IugENpdN9wPLKtb5HPA9SR8EDgVePdqOJF0AXABwzDHHTHqg1XrTm97EFVdccWDaVXOz5jRv3jx27/p1y31BmDFvXubtGqGz+FzgmxGxAHgt8C1JvxFXRFwZEV0R0TWvhhOdLJXDRT181MyaXd6JYAuwsGx6QTqv3LuAGwEi4lbgEGBuznHVrK+vb8S07z5qZs0u70SwDlgk6ThJM4BzgO6KdX4FvApA0m+RJILsvR1TZOiq4rGmzcyaTa59BBGxV9KFwE0kQ0Ovjoj1klYCvRHRDXwE+LqkD5N0HJ8fQ5fuNiBJlIc3dCfSVlDLMMuh+y7V0lzn4Y9mjSH3QfDpNQFrKuZdUvb6XmB53nFMlhkzZrBr164R00VWXhZm1px8NVRGlR98rfRBWMu386GLpy666KLJDsfMpkjhE8FkXHWa5UpSN4eYWaNphOGjTeU5z3nOuNNmZs2m8DWCrN/OBwcH+cxnPnNg+pOf/KSfUmZmTc01gow6OjoO1AJOPvlkJwEza3pOBDWYP38+hxxyCGeffXa9QzEzmzAnghq0t7ezYMEC1wbMrCU4EZiZFZwTgZlZwTkRmJkVXOGHj5oViZ/KZaNxImhRfk6vmVXLiaBF+Tm9Nho/lctG40TQwvycXjOrRlWdxZL+m6TD09eflvT3khbnG5qZmU2FakcNfSYinpb0CpKHy/8f4Kv5hWVmZlOl2kSwL/39OuDKiPguUOwnspiZtYhqE8EWSX8DvAVYI2lmhm3NzKyBVdtZ/GagBHw5Ip6UdBTwsfzCqo2HTJqZZVdtIjgK+G5E7JJ0OnAScG1eQdXKQybNzLKr9hNzNdAl6YXAlcA/An8HvDavwGrlIZNmZtlU286/PyL2Am8C/joiPkZSSzAzsyZXbSLYI+lc4Dzgn9N50/MJyczMplK1ieCdwMuAz0fEA5KOA76VX1hmZjZVqkoEEXEv8FHgHkkvAfoj4i9yjczMzKZEVZ3F6Uiha4AHAQELJb0jIn6QW2Q18C12zcyyq3bU0F8Cvx8RGwAknQBcByzJKzAzM5sa1SaC6UNJACAi7pdUVWexpBJwGdAGXBURX6xY/lfA76WTzwHmR8Rzq4xrBN9id5hrR8NcFjaWR3fn/77Ynl53NHt6W67HgeR8FtawXbWJoFfSVcC30+k/BHoPtpGkNuBy4DVAP7BOUnfa5wBARHy4bP0PAqdUGZOZWc06Ozun5Dh70jsRzFiwIPdjLaS286o2EbwP+ABwUTr9Q+CKKrZbCmyMiE0Akq4HzgTuHWP9c4HPVhnTqJzhE64dDXNZjOT/kcRU3bZl6FY0F1100UHWrJ+qEkFE7AIuTX+y6AQ2l033A8tGW1HS84HjgJvHWH4BcAHAMcccM/rBnOHNxuX/ERvNuIlA0j1AjLU8Ik6axFjOAb4TEftGWxgRV5Lc3oKurq5RY3KGH8nf/EZu67Lw/4iN7mA1gtdPcP9bYMT7dUE6bzTnkDQ/2STwN79hLguz8Y2bCCKiqttrSro1Il42yqJ1wKL0SuQtJB/2bx1l+xcDs4FbqzmeHZy/+Q1zWZiNb7IeLnPIaDPTG9VdCNwE3AfcGBHrJa2UtKJs1XOA6yNizGYoMzPLx2TduH+8foQ1wJqKeZdUTH9ukuIwM7OM/LhJM7OCm6xEoEnaj5mZTbHJSgRvn6T9mJnZFDvYdQRPM3r7v4CIiFkkL36WQ2xmZjYFDjZ89PCpCsTMzOoj06ghSfMpGyoaEb+a9IjMzGxKVdVHIGmFpF8ADwDfJ3lAzb/kGJeZmU2RajuL/ww4Dbg/Io4DXgXclltUZmY2ZapNBHsiYhswTdK0iFgLdOUYl5mZTZFq+wielHQYyXMI/lbSY8Az+YVlZmZTpdpEsBboAC4G3pa+XplXUFNp9erVbNky1g1RR7d582Z2797NpZdeSnt7trt0dHZ2TtlN0MxsctXyedGf3pV26KaEWUzV50W1TUPtwPeAW4DDgRvSpqJCiggigieeeKLeoZhZg5s5cyYzZ86sdxjjqvYJZX8K/Kmkk4C3AN+X1B8Rr841uimQNdsODg6ycmVSGXr22Wc5//zzmTVrVh6hmVmDadXafNZbTDwGbAW2AfMnP5zG19PTw/79+wHYv38/PT09dY7IzGxiqr2O4P2SbgH+DZgDvGeSH1PZNPr6+ti3L3kk4b59++jt7a1zRGZmE1NtT+dC4EMRcWeOsTSFJUuWcNttt7Fv3z7a2tro6vIoWjNrblXVCCLiE04CiVKpxLRpSbFNmzaNUqlU54jMzCbGD6bJqKOjg6VLlyKJZcuWuaPYzJqeE0ENli9fzsyZM1m+fHm9QzEzmzAnghqsXbuWnTt3snbt2nqHYmY2YU4EGQ0ODtLX1wdAb28vTz31VJ0jMjObGCeCjLq7u0dcR9Dd3V3niMzMJsaJIKM77rhjxPRQ7cDMrFk5EWQUEeNOm5k1GyeCjGbMmDHudNHs3buX/v5+95WYNbFs91A2du7cOe50M6vlFru/+tWv2L9/P1/4whc46qijMm3rW3KbNQbXCDI68sgjx50ukr179x7oOH/mmWfYu3dvnSMys1rkXiOQVAIuA9qAqyLii6Os82bgc0AAd0XEW/OOq1bnnXceX/rSlw5Mv+Md76hjNJMr67fzq6++esT07Nmzeec73zmZIZnZFMg1EUhqAy4HXgP0A+skdUfEvWXrLAI+ASyPiO2SGvr21gsWLGDevHkMDAwwf/58Ojs76x1S3dx1110jpu+88876BGJmE5J309BSYGNEbIqI3cD1wJkV67wHuDwitgNExGM5xzRhRx999IjfReURVGatIe9E0AlsLpvuT+eVOwE4QdKPJd2WNiX9BkkXSOqV1DswMJBTuAc3ODjIvfcmFZr169cXerRM5eP3Gv1xfGY2ukboLG4HFgGnA+cCX5f03MqVIuLKiOiKiK558+ZNbYRl/ISyYbt37x532syaQ96JYAvJQ22GLEjnlesHuiNiT0Q8ANxPkhgakp9QNkzSuNNm1hzyTgTrgEWSjpM0AzgHqLw5zz+Q1AaQNJekqWhTznHV7KUvfemI6ZNOKuQTOwFfXGfWKnJNBBGxF7gQuAm4D7gxItZLWilpRbraTcA2SfcCa4GPRcS2POOyydHKF9eZFUnu1xFExBpgTcW8S8peB/DH6U/Du+eee0ZM33333XWKpP6OPPJItm7dOmLazJpPI3QWNxU3DQ0777zzRky30sV1ZkXiRGA1G7q4Dij8xXVmzcyJICM3DY00e/bsEb/NrPk4EWS0ZMkSpk1Lim3atGl0dXXVOaL6GRwc5P777wdgw4YNhb64zqyZORFkVCqVaGtrA6CtrY1SadQLoQth9erV406bWXNwIsioo6ODpUuXIolly5Yxa9aseodUN77pnFlr8INpalAqldi6dWuhawPgm86ZtQonghp0dHRw8cUX1zsMM7NJ4aYhq9lv//Zvj5g++eST6xOImU2IawRWs7PPPntEP8HZZ59dx2gsL7U8y7q/vx+AVatWZT6en2U99VwjsJp1dHRwxBFHADBnzpxCd5zbSDNnzvTzKZqIawRWs8HBwQPXDgy9djJoPf523vpcI7Ca9fT0HBgpFBGFfkiPWTNzIrCa+SE9Zq3BicBqtmTJkhFXWRf5dhtmzcyJwGpWKpVG3Hep6BfYmTUrJwKrmW+3YdYaPGrIJsS32zBrfmrG+8N0dXWFOyYtTxO5iGrBggWZj+eLqGwqSOqLiN/ozHONwGyS+AIqa1ZOBGaj8LdzKxJ3FpuZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcHlnggklSRtkLRR0sdHWX6+pAFJd6Y/7847JjMzG5brdQSS2oDLgdcA/cA6Sd0RcW/FqjdExIV5xmJmZqPLu0awFNgYEZsiYjdwPXBmzsc0M7MM8k4EncDmsun+dF6lsyTdLek7khbmHJOZmZVphM7ifwKOjYiTgH8FrhltJUkXSOqV1DswMDClAZqZtbK8E8EWoPwb/oJ03gERsS0idqWTVwFLRttRRFwZEV0R0TVv3rxcgjUzK6K8E8E6YJGk4yTNAM4BustXkHRU2eQK4L6cYzIzszK5jhqKiL2SLgRuAtqAqyNivaSVQG9EdAMXSVoB7AWeAM7PMyYzMxvJD6YxMyuIsR5M0widxWZmVkdOBGZmBedEYGZWcE4EZmYF50RgZlZwTgRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZmYF50RgZlZwTgRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZmYF50RgZlZwTgRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZmYF50RgZlZwTgRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZmYFl3sikFSStEHSRkkfH2e9sySFpK68YzIzs2G5JgJJbcDlwBnAicC5kk4cZb3DgYuBn+QZj5mZ/aa8awRLgY0RsSkidgPXA2eOst6fAX8B7Mw5HjMzq9Ce8/47gc1l0/3AsvIVJC0GFkbEdyV9bKwdSboAuCCd3CFpw2QHm9Fc4PE6x9AoXBbDXBbDXBbDGqUsnj/azLwTwbgkTQMuBc4/2LoRcSVwZd4xVUtSb0S4PwOXRTmXxTCXxbBGL4u8m4a2AAvLphek84YcDrwEuEXSg8BpQLc7jM3Mpk7eiWAdsEjScZJmAOcA3UMLI2IwIuZGxLERcSxwG7AiInpzjsvMzFK5JoKI2AtcCNwE3AfcGBHrJa2UtCLPY0+BhmmmagAui2Eui2Eui2ENXRaKiHrHYGZmdeQri83MCs6JwMys4AqdCA52+wtJMyXdkC7/iaRjy5Z9Ip2/QdJ/Pdg+JV2YzgtJc3M/uYymuCy+KekBSXemPyfnfX61yqlcrpb0mKSfTdFpTIqcyuJBSfek74OmHCRSa7lImiNpraQdkr4y5YGXi4hC/gBtwC+B44EZwF3AiRXrvB/4Wvr6HOCG9PWJ6fozgePS/bSNt0/gFOBY4EFgbr3Pv85l8U3g7Hqfdz3KJV32u8Bi4Gf1PscGKIuG+3+YwnI5FHgF8F7gK/U8jyLXCKq5/cWZwDXp6+8Ar5KkdP71EbErIh4ANqb7G3OfEfHTiHgw75Oq0ZSWRRPJo1yIiB8AT0zFCUyiXMqiBdRcLhHxTET8iAa4tU6RE8Fot7/oHGudSIbCDgJzxtm2mn02onqUxecl3S3pryTNnIyTyEEe5dKs8iqLAL4nqS+9jUyzmUi5NIwiJwKrn08ALwZOBY4A/kd9w7E6ekVELCa5Q/EHJP1uvQMqoiIngoPd/mLEOpLagQ5g2zjbVrPPRjSlZRERj0RiF/ANGreZII9yaVa5lEVEDP1+DPh/NO57YSwTKZeGUeREMO7tL1LdwDvS12cDN0fSy9MNnJOOBjgOWATcXuU+G9GUloWko9LfAt4INOromTzKpVlNellIOlTJs0iQdCjw+zTue2EsEymXxlHvXvd6/gCvBe4n6fX/VDpvJcn9jgAOAf4vSefW7cDxZdt+Kt1uA3DGePtM519E0n64F3gYuKre51/HsrgZuIfkn/7bwGH1Pv8pLpfrgEeAPel74l31Ps96lAXJSJu70p/15e+RZvqZYLk8SDJwYEf6XjhxquOPCN9iwsys6IrcNGRmZjgRmJkVnhOBmVnBORGYmRWcE4GZWcE5EZhNAkk76h2DWa2cCMxykl5FatbwnAjMJpGk0yX9UFI3cG+94zGrhr+xmE2+xcBLIrnlslnDc43AbPLd7iRgzcSJwGzyPVPvAMyycCIwMys4JwIzs4Lz3UfNzArONQIzs4JzIjAzKzgnAjOzgnMiMDMrOCcCM7OCcyIwMys4JwIzs4L7D9BCjlJ9x22GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'lr'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n",
    "plt.ylim(0.4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e98fe5",
   "metadata": {},
   "source": [
    "## 5.2 reg l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a60e398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of kernel_regularizer_l1')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_regularizer_l1'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28a2c1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 1.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_regularizer_l1'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n",
    "plt.ylim(0.4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60feed38",
   "metadata": {},
   "source": [
    "## 5.3 reg l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "169ffe92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of kernel_regularizer_l2')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_regularizer_l2'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b3ef253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 1.0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_regularizer_l2'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n",
    "plt.ylim(0.4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e841d",
   "metadata": {},
   "source": [
    "## 5.4 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09669121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of bias_regularizer')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'bias_regularizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b3d8966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 1.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'bias_regularizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n",
    "plt.ylim(0.4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f81776",
   "metadata": {},
   "source": [
    "## 5.5 activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "89c0a22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of activity_regularizer')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'activity_regularizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25ba930f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 1.0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'activity_regularizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n",
    "plt.ylim(0.4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152af61",
   "metadata": {},
   "source": [
    "## Part 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6944cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron':[55],  #Done\n",
    "     'hidden_neuron':[50], #Done\n",
    "\n",
    "     'hidden_layers':[0,1,2],   \n",
    "\n",
    "     \n",
    "    'epochs': [100000], # never touch it\n",
    "\n",
    "\n",
    "    'last_activation': ['sigmoid'], #never touch it\n",
    "\n",
    "\n",
    "    'batch_size': [64], #Done\n",
    "\n",
    "    'lr':[0.005,0.001],\n",
    "    \n",
    "    'kernel_regularizer_l1':[0.001,0.0001],\n",
    "    'kernel_regularizer_l2':[0.1,0.01],\n",
    "    'bias_regularizer':[0.001,0.0001],\n",
    "    'activity_regularizer':[0.001],\n",
    "\n",
    "    'dropout': [0,0.1,0.2,0.3,0.4],\n",
    "\n",
    "    'kernel_initializer': ['identity'], #Done\n",
    "\n",
    "    'activation_layer':['tanh'], #Done\n",
    " \n",
    "    'batc_normalization':[False], #Done\n",
    " \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed035de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                 | 1/240 [00:05<22:27,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 210.\n",
      "Epoch 260: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                                 | 2/240 [00:16<34:46,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Epoch 124: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                                 | 3/240 [00:22<30:19,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 183.\n",
      "Epoch 233: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                                | 4/240 [00:32<33:50,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Epoch 126: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                                | 5/240 [00:39<30:06,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 212.\n",
      "Epoch 262: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██                                                                                | 6/240 [00:49<34:13,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 87: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                               | 7/240 [00:54<28:52,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 176.\n",
      "Epoch 226: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▋                                                                               | 8/240 [01:04<31:22,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███                                                                               | 9/240 [01:09<27:51,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 211.\n",
      "Epoch 261: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▍                                                                             | 10/240 [01:20<32:41,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "Epoch 120: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▋                                                                             | 11/240 [01:27<29:46,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 201.\n",
      "Epoch 251: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████                                                                             | 12/240 [01:38<33:24,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Epoch 106: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▍                                                                            | 13/240 [01:43<29:38,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 207.\n",
      "Epoch 257: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                            | 14/240 [01:55<33:33,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "Epoch 107: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████                                                                            | 15/240 [02:00<29:43,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 189.\n",
      "Epoch 239: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▍                                                                           | 16/240 [02:11<32:28,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Epoch 134: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▋                                                                           | 17/240 [02:18<30:27,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 231.\n",
      "Epoch 281: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████                                                                           | 18/240 [02:31<35:19,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "Epoch 129: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                          | 19/240 [02:37<32:06,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 201.\n",
      "Epoch 251: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▊                                                                          | 20/240 [02:49<35:01,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████                                                                          | 21/240 [02:55<30:46,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 217.\n",
      "Epoch 267: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▍                                                                         | 22/240 [03:07<34:40,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Epoch 124: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▊                                                                         | 23/240 [03:13<31:25,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 213.\n",
      "Epoch 263: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 24/240 [03:25<34:39,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Epoch 100: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▍                                                                        | 25/240 [03:30<29:45,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 209.\n",
      "Epoch 259: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▊                                                                        | 26/240 [03:41<32:23,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Epoch 93: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████                                                                        | 27/240 [03:46<27:49,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 187.\n",
      "Epoch 237: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▍                                                                       | 28/240 [03:57<30:17,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▊                                                                       | 29/240 [04:02<26:38,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 203.\n",
      "Epoch 253: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▏                                                                      | 30/240 [04:13<29:47,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Epoch 112: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▍                                                                      | 31/240 [04:18<26:36,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 184.\n",
      "Epoch 234: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▊                                                                      | 32/240 [04:29<29:28,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▏                                                                     | 33/240 [04:35<26:35,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 215.\n",
      "Epoch 265: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▍                                                                     | 34/240 [04:47<30:52,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Epoch 99: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▊                                                                     | 35/240 [04:52<27:17,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 183.\n",
      "Epoch 233: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▏                                                                    | 36/240 [05:03<30:00,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Epoch 95: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                    | 37/240 [05:08<26:24,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 236.\n",
      "Epoch 286: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▊                                                                    | 38/240 [05:21<31:24,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▏                                                                   | 39/240 [05:27<27:25,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 173.\n",
      "Epoch 223: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▌                                                                   | 40/240 [05:37<29:42,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Epoch 109: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                   | 41/240 [05:44<27:06,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 222.\n",
      "Epoch 272: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▏                                                                  | 42/240 [05:57<31:56,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Epoch 92: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▌                                                                  | 43/240 [06:03<27:50,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 202.\n",
      "Epoch 252: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▊                                                                  | 44/240 [06:15<31:21,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▏                                                                 | 45/240 [06:21<27:35,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 228.\n",
      "Epoch 278: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▌                                                                 | 46/240 [06:34<32:04,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Epoch 112: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                                 | 47/240 [06:41<28:38,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 180.\n",
      "Epoch 230: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 48/240 [06:52<30:46,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Epoch 93: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                | 49/240 [06:57<26:10,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 219.\n",
      "Epoch 269: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▉                                                                | 50/240 [07:08<28:55,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▏                                                               | 51/240 [07:15<26:14,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 198.\n",
      "Epoch 248: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▌                                                               | 52/240 [07:25<28:08,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Epoch 111: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▉                                                               | 53/240 [07:31<24:47,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 204.\n",
      "Epoch 254: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▏                                                              | 54/240 [07:41<27:17,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Epoch 98: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▌                                                              | 55/240 [07:46<23:41,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 204.\n",
      "Epoch 254: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▉                                                              | 56/240 [07:57<26:38,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▏                                                             | 57/240 [08:03<23:36,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 218.\n",
      "Epoch 268: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▌                                                             | 58/240 [08:15<27:31,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Epoch 109: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████▉                                                             | 59/240 [08:21<24:34,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 185.\n",
      "Epoch 235: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▎                                                            | 60/240 [08:32<26:49,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "Epoch 106: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▌                                                            | 61/240 [08:38<23:54,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 258.\n",
      "Epoch 308: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▉                                                            | 62/240 [08:51<28:46,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "Epoch 133: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▎                                                           | 63/240 [08:58<26:07,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 163.\n",
      "Epoch 213: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▌                                                           | 64/240 [09:08<26:58,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▉                                                           | 65/240 [09:14<23:54,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 218.\n",
      "Epoch 268: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▎                                                          | 66/240 [09:27<27:53,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Epoch 128: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▌                                                          | 67/240 [09:34<25:37,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 188.\n",
      "Epoch 238: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▉                                                          | 68/240 [09:46<28:17,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▎                                                         | 69/240 [09:53<25:06,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 224.\n",
      "Epoch 274: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▋                                                         | 70/240 [10:06<28:38, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▉                                                         | 71/240 [10:12<25:00,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 196.\n",
      "Epoch 246: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                        | 72/240 [10:24<27:21,  9.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Epoch 100: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▋                                                        | 73/240 [10:29<23:21,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 206.\n",
      "Epoch 256: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████▉                                                        | 74/240 [10:40<25:15,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "Epoch 119: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▎                                                       | 75/240 [10:46<22:21,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 179.\n",
      "Epoch 229: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▋                                                       | 76/240 [10:55<23:34,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Epoch 93: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▉                                                       | 77/240 [11:00<20:25,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 215.\n",
      "Epoch 265: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▎                                                      | 78/240 [11:12<23:13,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 84: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▋                                                      | 79/240 [11:16<19:52,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 151.\n",
      "Epoch 201: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████                                                      | 80/240 [11:25<20:50,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▎                                                     | 81/240 [11:30<18:49,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 212.\n",
      "Epoch 262: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▋                                                     | 82/240 [11:42<22:25,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 87: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████                                                     | 83/240 [11:47<19:36,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 190.\n",
      "Epoch 240: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▎                                                    | 84/240 [11:58<22:20,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Epoch 95: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▋                                                    | 85/240 [12:04<19:45,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 213.\n",
      "Epoch 263: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████                                                    | 86/240 [12:16<22:52,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Epoch 109: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▎                                                   | 87/240 [12:22<20:27,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 182.\n",
      "Epoch 232: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▋                                                   | 88/240 [12:32<22:19,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████                                                   | 89/240 [12:38<20:05,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 231.\n",
      "Epoch 281: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▍                                                  | 90/240 [12:52<23:59,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▋                                                  | 91/240 [12:58<21:10,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 201.\n",
      "Epoch 251: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████                                                  | 92/240 [13:10<23:41,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▍                                                 | 93/240 [13:16<20:48,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 221.\n",
      "Epoch 271: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▋                                                 | 94/240 [13:29<23:55,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                 | 95/240 [13:35<21:01,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 246.\n",
      "Epoch 296: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▍                                                | 96/240 [13:49<24:40, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Epoch 94: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▋                                                | 97/240 [13:54<20:44,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 211.\n",
      "Epoch 261: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████                                                | 98/240 [14:05<22:37,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "Epoch 146: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▍                                               | 99/240 [14:12<20:31,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 177.\n",
      "Epoch 227: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▎                                              | 100/240 [14:22<21:05,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 82.\n",
      "Epoch 132: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▋                                              | 101/240 [14:28<19:02,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 216.\n",
      "Epoch 266: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████                                              | 102/240 [14:39<20:55,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Epoch 95: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▎                                             | 103/240 [14:46<18:57,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 149.\n",
      "Epoch 199: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▋                                             | 104/240 [14:55<19:06,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████                                             | 105/240 [15:00<17:10,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 224.\n",
      "Epoch 274: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▎                                            | 106/240 [15:13<20:08,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Epoch 114: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████▋                                            | 107/240 [15:19<18:03,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 208.\n",
      "Epoch 258: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████                                            | 108/240 [15:30<20:16,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▎                                           | 109/240 [15:36<17:42,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 210.\n",
      "Epoch 260: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▋                                           | 110/240 [15:47<19:41,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Epoch 110: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████                                           | 111/240 [15:53<17:27,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 175.\n",
      "Epoch 225: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▎                                          | 112/240 [16:03<18:33,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Epoch 98: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▋                                          | 113/240 [16:09<16:32,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 233.\n",
      "Epoch 283: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████                                          | 114/240 [16:22<19:41,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Epoch 98: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▎                                         | 115/240 [16:28<17:17,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 213.\n",
      "Epoch 263: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▋                                         | 116/240 [16:40<19:36,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "Epoch 126: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████                                         | 117/240 [16:47<17:48,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 224.\n",
      "Epoch 274: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▎                                        | 118/240 [17:00<20:04,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Epoch 128: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▋                                        | 119/240 [17:06<18:05,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 204.\n",
      "Epoch 254: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                        | 120/240 [17:18<19:39,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Epoch 92: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▎                                       | 121/240 [17:23<16:23,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 231.\n",
      "Epoch 281: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▋                                       | 122/240 [17:34<17:54,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "Epoch 88: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████████████████████████████████████████                                       | 123/240 [17:38<15:05,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 241.\n",
      "Epoch 291: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▎                                      | 124/240 [17:50<17:08,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Epoch 94: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▋                                      | 125/240 [17:55<14:35,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 197.\n",
      "Epoch 247: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████                                      | 126/240 [18:05<15:48,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Epoch 148: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▎                                     | 127/240 [18:11<14:38,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 179.\n",
      "Epoch 229: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▋                                     | 128/240 [18:20<15:23,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Epoch 98: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████                                     | 129/240 [18:26<13:30,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 210.\n",
      "Epoch 260: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▎                                    | 130/240 [18:36<15:21,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Epoch 127: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▋                                    | 131/240 [18:43<13:59,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 192.\n",
      "Epoch 242: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████                                    | 132/240 [18:53<15:12,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Epoch 95: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▎                                   | 133/240 [18:58<13:13,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 215.\n",
      "Epoch 265: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▋                                   | 134/240 [19:09<14:58,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "Epoch 127: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████                                   | 135/240 [19:15<13:34,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 167.\n",
      "Epoch 217: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▎                                  | 136/240 [19:24<14:13,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Epoch 99: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▋                                  | 137/240 [19:29<12:38,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 223.\n",
      "Epoch 273: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████                                  | 138/240 [19:41<14:48,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Epoch 137: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▎                                 | 139/240 [19:48<13:42,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 193.\n",
      "Epoch 243: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▋                                 | 140/240 [19:59<14:56,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████                                 | 141/240 [20:05<13:05,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 224.\n",
      "Epoch 274: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▎                                | 142/240 [20:16<14:50,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Epoch 99: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▋                                | 143/240 [20:22<12:55,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 183.\n",
      "Epoch 233: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████                                | 144/240 [20:32<13:55,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▎                               | 145/240 [20:37<12:03,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 218.\n",
      "Epoch 268: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▋                               | 146/240 [20:48<13:26,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Epoch 130: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████████████████████████████                               | 147/240 [20:54<12:05,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 170.\n",
      "Epoch 220: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▎                              | 148/240 [21:03<12:37,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Epoch 109: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▋                              | 149/240 [21:09<11:08,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 209.\n",
      "Epoch 259: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████                              | 150/240 [21:19<12:27,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "Epoch 87: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▎                             | 151/240 [21:24<10:39,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 172.\n",
      "Epoch 222: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▋                             | 152/240 [21:33<11:26,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "Epoch 110: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████                             | 153/240 [21:39<10:26,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 244.\n",
      "Epoch 294: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▎                            | 154/240 [21:51<12:38,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Epoch 89: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████████████████████████████▋                            | 155/240 [21:56<10:52,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 204.\n",
      "Epoch 254: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████                            | 156/240 [22:07<12:13,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Epoch 95: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▎                           | 157/240 [22:13<10:38,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 217.\n",
      "Epoch 267: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▋                           | 158/240 [22:24<12:07,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Epoch 117: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████                           | 159/240 [22:30<10:49,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 184.\n",
      "Epoch 234: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▎                          | 160/240 [22:41<11:36,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▋                          | 161/240 [22:46<10:14,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 218.\n",
      "Epoch 268: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████                          | 162/240 [23:08<15:41, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "Epoch 89: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▎                         | 163/240 [23:14<12:54, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 237.\n",
      "Epoch 287: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▋                         | 164/240 [23:27<13:53, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████                         | 165/240 [23:33<11:43,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 217.\n",
      "Epoch 267: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▎                        | 166/240 [23:45<12:39, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Epoch 135: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▋                        | 167/240 [23:52<11:21,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 211.\n",
      "Epoch 261: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████                        | 168/240 [24:04<12:12, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "Epoch 93: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▎                       | 169/240 [24:09<10:07,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 209.\n",
      "Epoch 259: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▋                       | 170/240 [24:20<10:40,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Epoch 100: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|█████████████████████████████████████████████████████████                       | 171/240 [24:25<09:06,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 193.\n",
      "Epoch 243: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▎                      | 172/240 [24:34<09:39,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▋                      | 173/240 [24:41<08:43,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 224.\n",
      "Epoch 274: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████████                      | 174/240 [24:52<09:51,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Epoch 130: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▎                     | 175/240 [24:58<08:45,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 247.\n",
      "Epoch 297: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▋                     | 176/240 [25:10<09:49,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████                     | 177/240 [25:15<08:25,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 210.\n",
      "Epoch 260: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▎                    | 178/240 [25:27<09:18,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████▋                    | 179/240 [25:32<08:04,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 198.\n",
      "Epoch 248: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████                    | 180/240 [25:43<08:50,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████▎                   | 181/240 [25:49<07:41,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 209.\n",
      "Epoch 259: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▋                   | 182/240 [26:00<08:34,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "Epoch 114: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████                   | 183/240 [26:06<07:38,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 194.\n",
      "Epoch 244: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▎                  | 184/240 [26:17<08:14,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Epoch 125: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▋                  | 185/240 [26:23<07:32,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 259.\n",
      "Epoch 309: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████                  | 186/240 [26:37<08:56,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "Epoch 98: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▎                 | 187/240 [26:43<07:39,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 243.\n",
      "Epoch 293: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▋                 | 188/240 [26:56<08:42, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Epoch 112: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████                 | 189/240 [27:03<07:34,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 235.\n",
      "Epoch 285: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▎                | 190/240 [27:16<08:28, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 85.\n",
      "Epoch 135: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▋                | 191/240 [27:23<07:33,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 239.\n",
      "Epoch 289: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 192/240 [27:36<08:26, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▎               | 193/240 [27:41<06:56,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 229.\n",
      "Epoch 279: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▋               | 194/240 [27:53<07:21,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 152.\n",
      "Epoch 202: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████████               | 195/240 [28:01<06:56,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 152.\n",
      "Epoch 202: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▎              | 196/240 [28:10<06:39,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Epoch 92: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▋              | 197/240 [28:15<05:34,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 224.\n",
      "Epoch 274: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████████████████████████████████              | 198/240 [28:26<06:08,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 80: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▎             | 199/240 [28:30<05:04,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 155.\n",
      "Epoch 205: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▋             | 200/240 [28:39<05:11,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████             | 201/240 [28:44<04:37,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 247.\n",
      "Epoch 297: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▎            | 202/240 [28:57<05:33,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Epoch 92: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████▋            | 203/240 [29:02<04:44,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 182.\n",
      "Epoch 232: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████            | 204/240 [29:12<05:04,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Epoch 95: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████▎           | 205/240 [29:17<04:22,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 210.\n",
      "Epoch 260: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▋           | 206/240 [29:29<04:53,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "Epoch 108: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████████████████████████████████████           | 207/240 [29:34<04:15,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 174.\n",
      "Epoch 224: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▎          | 208/240 [29:44<04:29,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Epoch 99: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▋          | 209/240 [29:50<03:55,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 219.\n",
      "Epoch 269: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████          | 210/240 [30:02<04:31,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▎         | 211/240 [30:08<03:54,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 190.\n",
      "Epoch 240: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▋         | 212/240 [30:20<04:13,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████         | 213/240 [30:25<03:36,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 225.\n",
      "Epoch 275: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▎        | 214/240 [30:38<04:04,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Epoch 99: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▋        | 215/240 [30:44<03:27,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 210.\n",
      "Epoch 260: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 216/240 [30:56<03:46,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "Epoch 115: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▎       | 217/240 [31:01<03:09,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 217.\n",
      "Epoch 267: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▋       | 218/240 [31:12<03:18,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Epoch 91: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████       | 219/240 [31:17<02:41,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 158.\n",
      "Epoch 208: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▎      | 220/240 [31:25<02:39,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "Epoch 94: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▋      | 221/240 [31:30<02:13,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 211.\n",
      "Epoch 261: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|██████████████████████████████████████████████████████████████████████████      | 222/240 [31:41<02:25,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "Epoch 136: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 223/240 [31:47<02:08,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 184.\n",
      "Epoch 234: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▋     | 224/240 [31:57<02:10,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████     | 225/240 [32:02<01:49,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 215.\n",
      "Epoch 265: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▎    | 226/240 [32:13<02:00,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Epoch 92: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|███████████████████████████████████████████████████████████████████████████▋    | 227/240 [32:18<01:37,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 174.\n",
      "Epoch 224: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████    | 228/240 [32:28<01:38,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 96: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████▎   | 229/240 [32:34<01:20,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 215.\n",
      "Epoch 265: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▋   | 230/240 [32:45<01:25,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "Epoch 90: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████████████████████████████████████   | 231/240 [32:50<01:07,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 1, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "Restoring model weights from the end of the best epoch: 216.\n",
      "Epoch 266: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▎  | 232/240 [33:02<01:09,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Epoch 111: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 233/240 [33:08<00:55,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 221.\n",
      "Epoch 271: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████  | 234/240 [33:20<00:55,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "Epoch 109: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▎ | 235/240 [33:26<00:41,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 203.\n",
      "Epoch 253: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▋ | 236/240 [33:38<00:37,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Epoch 100: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████ | 237/240 [33:44<00:24,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.1, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 222.\n",
      "Epoch 272: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████▎| 238/240 [33:56<00:19,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.005}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Epoch 105: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 239/240 [34:02<00:08,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.0001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 2, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "adding layer 1\n",
      "adding layer 2\n",
      "Restoring model weights from the end of the best epoch: 188.\n",
      "Epoch 238: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [34:13<00:00,  8.56s/it]\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=train_df, y=train_label,\n",
    "            x_val=test_df, y_val=test_label,\n",
    "            model=numerai_model,\n",
    "            params=p,  \n",
    "            experiment_name='Predykcja klasy M - Weighted binary cross-entropy (nowe)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dee873e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/Marze/OneDrive/Dokumenty/Jarek/Magisterka/Predykcja klasy M - Weighted binary cross-entropy (nowe)/050822123005.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef26126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stare_wart=df['val_fbeta_score']\n",
    "nowe_wart=[]\n",
    "for x in stare_wart:\n",
    "    wart=x.replace('[','')\n",
    "    wart=wart.replace(']','')\n",
    "    wart=float(wart)\n",
    "    nowe_wart.append(wart)\n",
    "df['val_fbeta_score']=nowe_wart\n",
    "df=df.sort_values('val_loss',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "355f82cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>112</td>\n",
       "      <td>0.656584</td>\n",
       "      <td>[0.26544625]</td>\n",
       "      <td>0.165242</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.650931</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>117</td>\n",
       "      <td>0.677076</td>\n",
       "      <td>[0.24343675]</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.671463</td>\n",
       "      <td>0.268908</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>291</td>\n",
       "      <td>0.654362</td>\n",
       "      <td>[0.3153989]</td>\n",
       "      <td>0.187638</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.673656</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>136</td>\n",
       "      <td>0.689072</td>\n",
       "      <td>[0.25887266]</td>\n",
       "      <td>0.157761</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.674600</td>\n",
       "      <td>0.313433</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>226</td>\n",
       "      <td>0.652959</td>\n",
       "      <td>[0.30965394]</td>\n",
       "      <td>0.183585</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.675887</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>238</td>\n",
       "      <td>0.692230</td>\n",
       "      <td>[0.3016158]</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.712019</td>\n",
       "      <td>0.291971</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>92</td>\n",
       "      <td>0.707267</td>\n",
       "      <td>[0.27096772]</td>\n",
       "      <td>0.166227</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.713894</td>\n",
       "      <td>0.281879</td>\n",
       "      <td>0.165354</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>135</td>\n",
       "      <td>0.685124</td>\n",
       "      <td>[0.2851782]</td>\n",
       "      <td>0.170022</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.714279</td>\n",
       "      <td>0.291971</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>296</td>\n",
       "      <td>0.687659</td>\n",
       "      <td>[0.3076923]</td>\n",
       "      <td>0.182609</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.715451</td>\n",
       "      <td>0.291971</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>251</td>\n",
       "      <td>0.697768</td>\n",
       "      <td>[0.3016158]</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.727523</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "30            112  0.656584  [0.26544625]   0.165242  0.674419  0.650931   \n",
       "158           117  0.677076  [0.24343675]   0.153153  0.593023  0.671463   \n",
       "123           291  0.654362   [0.3153989]   0.187638  0.988372  0.673656   \n",
       "222           136  0.689072  [0.25887266]   0.157761  0.720930  0.674600   \n",
       "7             226  0.652959  [0.30965394]   0.183585  0.988372  0.675887   \n",
       "..            ...       ...           ...        ...       ...       ...   \n",
       "239           238  0.692230   [0.3016158]   0.178344  0.976744  0.712019   \n",
       "226            92  0.707267  [0.27096772]   0.166227  0.732558  0.713894   \n",
       "166           135  0.685124   [0.2851782]   0.170022  0.883721  0.714279   \n",
       "95            296  0.687659   [0.3076923]   0.182609  0.976744  0.715451   \n",
       "19            251  0.697768   [0.3016158]   0.178344  0.976744  0.727523   \n",
       "\n",
       "     val_fbeta_score  val_precision  val_recall activation_layer  ...  \\\n",
       "30          0.380952       0.400000    0.363636             tanh  ...   \n",
       "158         0.268908       0.164948    0.727273             tanh  ...   \n",
       "123         0.303030       0.181818    0.909091             tanh  ...   \n",
       "222         0.313433       0.187500    0.954545             tanh  ...   \n",
       "7           0.303030       0.181818    0.909091             tanh  ...   \n",
       "..               ...            ...         ...              ...  ...   \n",
       "239         0.291971       0.173913    0.909091             tanh  ...   \n",
       "226         0.281879       0.165354    0.954545             tanh  ...   \n",
       "166         0.291971       0.173913    0.909091             tanh  ...   \n",
       "95          0.291971       0.173913    0.909091             tanh  ...   \n",
       "19          0.283688       0.168067    0.909091             tanh  ...   \n",
       "\n",
       "     dropout  epochs  first_neuron  hidden_layers  hidden_neuron  \\\n",
       "30       0.1  100000            55              0             50   \n",
       "158      0.1  100000            55              1             50   \n",
       "123      0.0  100000            55              0             50   \n",
       "222      0.4  100000            55              0             50   \n",
       "7        0.0  100000            55              0             50   \n",
       "..       ...     ...           ...            ...            ...   \n",
       "239      0.4  100000            55              2             50   \n",
       "226      0.4  100000            55              1             50   \n",
       "166      0.1  100000            55              2             50   \n",
       "95       0.3  100000            55              2             50   \n",
       "19       0.0  100000            55              2             50   \n",
       "\n",
       "     kernel_initializer  kernel_regularizer_l1  kernel_regularizer_l2  \\\n",
       "30             identity                 0.0001                   0.01   \n",
       "158            identity                 0.0001                   0.01   \n",
       "123            identity                 0.0010                   0.01   \n",
       "222            identity                 0.0001                   0.01   \n",
       "7              identity                 0.0001                   0.01   \n",
       "..                  ...                    ...                    ...   \n",
       "239            identity                 0.0001                   0.01   \n",
       "226            identity                 0.0010                   0.01   \n",
       "166            identity                 0.0001                   0.01   \n",
       "95             identity                 0.0001                   0.01   \n",
       "19             identity                 0.0010                   0.01   \n",
       "\n",
       "     last_activation     lr  \n",
       "30           sigmoid  0.005  \n",
       "158          sigmoid  0.005  \n",
       "123          sigmoid  0.001  \n",
       "222          sigmoid  0.005  \n",
       "7            sigmoid  0.001  \n",
       "..               ...    ...  \n",
       "239          sigmoid  0.001  \n",
       "226          sigmoid  0.005  \n",
       "166          sigmoid  0.005  \n",
       "95           sigmoid  0.001  \n",
       "19           sigmoid  0.001  \n",
       "\n",
       "[240 rows x 24 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa03c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of hidden_layers')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'hidden_layers'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43b09565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of lr')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'lr'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "472827b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of kernel_regularizer_l1')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_regularizer_l1'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a984031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of kernel_regularizer_l2')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_regularizer_l2'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ececef6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of bias_regularizer')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'bias_regularizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2c10857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of dropout')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'dropout'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab55afbc",
   "metadata": {},
   "source": [
    "## Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27def762",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron':[55],  #Done\n",
    "     'hidden_neuron':[50], #Done\n",
    "\n",
    "     'hidden_layers':[0],   \n",
    "\n",
    "     \n",
    "    'epochs': [100000], # never touch it\n",
    "\n",
    "\n",
    "    'last_activation': ['sigmoid'], #never touch it\n",
    "\n",
    "\n",
    "    'batch_size': [64], #Done\n",
    "\n",
    "    'lr':[0.0001,0.001],\n",
    "    \n",
    "    'kernel_regularizer_l1':[0.0001],\n",
    "    'kernel_regularizer_l2':[0.01],\n",
    "    'bias_regularizer':[0.001],\n",
    "    'activity_regularizer':[0.001],\n",
    "\n",
    "    'dropout': [0,0.1,0.2,0.3,0.4],\n",
    "\n",
    "    'kernel_initializer': ['identity'], #Done\n",
    "\n",
    "    'activation_layer':['tanh'], #Done\n",
    " \n",
    "    'batc_normalization':[False], #Done\n",
    " \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b135db19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "Restoring model weights from the end of the best epoch: 861.\n",
      "Epoch 911: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                      | 0/6250 [21:34:44<?, ?it/s]\n",
      "\n",
      "\n",
      " 10%|████████▎                                                                          | 1/10 [00:42<06:20, 42.27s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 191.\n",
      "Epoch 241: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:53<03:12, 24.09s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "Restoring model weights from the end of the best epoch: 991.\n",
      "Epoch 1041: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|████████████████████████▉                                                          | 3/10 [01:38<03:53, 33.37s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.1, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 165.\n",
      "Epoch 215: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:48<02:27, 24.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "Restoring model weights from the end of the best epoch: 895.\n",
      "Epoch 945: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [02:34<02:41, 32.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.2, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 155.\n",
      "Epoch 205: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [02:45<01:38, 24.73s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "Restoring model weights from the end of the best epoch: 815.\n",
      "Epoch 865: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [03:22<01:26, 28.92s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.3, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 167.\n",
      "Epoch 217: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [03:33<00:46, 23.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.0001}\n",
      "Restoring model weights from the end of the best epoch: 885.\n",
      "Epoch 935: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [04:13<00:28, 28.43s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'tanh', 'activity_regularizer': 0.001, 'batc_normalization': False, 'batch_size': 64, 'bias_regularizer': 0.001, 'dropout': 0.4, 'epochs': 100000, 'first_neuron': 55, 'hidden_layers': 0, 'hidden_neuron': 50, 'kernel_initializer': 'identity', 'kernel_regularizer_l1': 0.0001, 'kernel_regularizer_l2': 0.01, 'last_activation': 'sigmoid', 'lr': 0.001}\n",
      "Restoring model weights from the end of the best epoch: 166.\n",
      "Epoch 216: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [04:23<00:00, 26.39s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=train_df, y=train_label,\n",
    "            x_val=test_df, y_val=test_label,\n",
    "            model=numerai_model,\n",
    "            params=p,  \n",
    "            experiment_name='Predykcja klasy M - Weighted binary cross-entropy (nowe)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc0b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"D:/STUDIA/ROK_II/Magisterka/Modele/Dane pierwotne/M/Predykcja klasy M - podejscie z Focal-loss (nowe)/050822133608.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f75ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stare_wart=df['val_fbeta_score']\n",
    "nowe_wart=[]\n",
    "for x in stare_wart:\n",
    "    wart=x.replace('[','')\n",
    "    wart=wart.replace(']','')\n",
    "    wart=float(wart)\n",
    "    nowe_wart.append(wart)\n",
    "df['val_fbeta_score']=nowe_wart\n",
    "df=df.sort_values('val_loss',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1413ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>fbeta_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_fbeta_score</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>...</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_regularizer_l1</th>\n",
       "      <th>kernel_regularizer_l2</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241</td>\n",
       "      <td>0.651360</td>\n",
       "      <td>[0.30965394]</td>\n",
       "      <td>0.183585</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.667851</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.184466</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>216</td>\n",
       "      <td>0.654363</td>\n",
       "      <td>[0.31758034]</td>\n",
       "      <td>0.189616</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.669149</td>\n",
       "      <td>0.310078</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>205</td>\n",
       "      <td>0.655579</td>\n",
       "      <td>[0.3082569]</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.675522</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>[0.3145631]</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.676960</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>217</td>\n",
       "      <td>0.655860</td>\n",
       "      <td>[0.30601093]</td>\n",
       "      <td>0.181425</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.677174</td>\n",
       "      <td>0.300752</td>\n",
       "      <td>0.180180</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041</td>\n",
       "      <td>0.676652</td>\n",
       "      <td>[0.3113553]</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>945</td>\n",
       "      <td>0.694485</td>\n",
       "      <td>[0.3159851]</td>\n",
       "      <td>0.188053</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.711898</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>935</td>\n",
       "      <td>0.699515</td>\n",
       "      <td>[0.310219]</td>\n",
       "      <td>0.183983</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.712790</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>911</td>\n",
       "      <td>0.699801</td>\n",
       "      <td>[0.30965394]</td>\n",
       "      <td>0.183585</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.721145</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>865</td>\n",
       "      <td>0.711871</td>\n",
       "      <td>[0.3108614]</td>\n",
       "      <td>0.185268</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.725317</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>tanh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100000</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs      loss   fbeta_score  precision    recall  val_loss  \\\n",
       "1           241  0.651360  [0.30965394]   0.183585  0.988372  0.667851   \n",
       "9           216  0.654363  [0.31758034]   0.189616  0.976744  0.669149   \n",
       "5           205  0.655579   [0.3082569]   0.183007  0.976744  0.675522   \n",
       "3           215  0.653905   [0.3145631]   0.188811  0.941860  0.676960   \n",
       "7           217  0.655860  [0.30601093]   0.181425  0.976744  0.677174   \n",
       "2          1041  0.676652   [0.3113553]   0.184783  0.988372  0.698442   \n",
       "4           945  0.694485   [0.3159851]   0.188053  0.988372  0.711898   \n",
       "8           935  0.699515    [0.310219]   0.183983  0.988372  0.712790   \n",
       "0           911  0.699801  [0.30965394]   0.183585  0.988372  0.721145   \n",
       "6           865  0.711871   [0.3108614]   0.185268  0.965116  0.725317   \n",
       "\n",
       "   val_fbeta_score  val_precision  val_recall activation_layer  ...  dropout  \\\n",
       "1         0.304000       0.184466    0.863636             tanh  ...      0.0   \n",
       "9         0.310078       0.186916    0.909091             tanh  ...      0.4   \n",
       "5         0.303030       0.181818    0.909091             tanh  ...      0.2   \n",
       "3         0.296296       0.176991    0.909091             tanh  ...      0.1   \n",
       "7         0.300752       0.180180    0.909091             tanh  ...      0.3   \n",
       "2         0.296296       0.176991    0.909091             tanh  ...      0.1   \n",
       "4         0.298507       0.178571    0.909091             tanh  ...      0.2   \n",
       "8         0.298507       0.178571    0.909091             tanh  ...      0.4   \n",
       "0         0.296296       0.176991    0.909091             tanh  ...      0.0   \n",
       "6         0.307692       0.185185    0.909091             tanh  ...      0.3   \n",
       "\n",
       "   epochs  first_neuron  hidden_layers  hidden_neuron  kernel_initializer  \\\n",
       "1  100000            55              0             50            identity   \n",
       "9  100000            55              0             50            identity   \n",
       "5  100000            55              0             50            identity   \n",
       "3  100000            55              0             50            identity   \n",
       "7  100000            55              0             50            identity   \n",
       "2  100000            55              0             50            identity   \n",
       "4  100000            55              0             50            identity   \n",
       "8  100000            55              0             50            identity   \n",
       "0  100000            55              0             50            identity   \n",
       "6  100000            55              0             50            identity   \n",
       "\n",
       "   kernel_regularizer_l1  kernel_regularizer_l2  last_activation      lr  \n",
       "1                 0.0001                   0.01          sigmoid  0.0010  \n",
       "9                 0.0001                   0.01          sigmoid  0.0010  \n",
       "5                 0.0001                   0.01          sigmoid  0.0010  \n",
       "3                 0.0001                   0.01          sigmoid  0.0010  \n",
       "7                 0.0001                   0.01          sigmoid  0.0010  \n",
       "2                 0.0001                   0.01          sigmoid  0.0001  \n",
       "4                 0.0001                   0.01          sigmoid  0.0001  \n",
       "8                 0.0001                   0.01          sigmoid  0.0001  \n",
       "0                 0.0001                   0.01          sigmoid  0.0001  \n",
       "6                 0.0001                   0.01          sigmoid  0.0001  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154a05c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of lr')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'lr'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b63b3168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of dropout')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'dropout'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f94942",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron':[55],  #Done\n",
    "     'hidden_neuron':[50], #Done\n",
    "\n",
    "     'hidden_layers':[0],   \n",
    "\n",
    "     \n",
    "    'epochs': [100000], # never touch it\n",
    "\n",
    "\n",
    "    'last_activation': ['sigmoid'], #never touch it\n",
    "\n",
    "\n",
    "    'batch_size': [64], #Done\n",
    "\n",
    "    'lr':[0.001], #Done\n",
    "    \n",
    "    'kernel_regularizer_l1':[0.0001],#Done\n",
    "    'kernel_regularizer_l2':[0.01],#Done\n",
    "    'bias_regularizer':[0.001],#Done\n",
    "    'activity_regularizer':[0.001],#Done\n",
    "\n",
    "    'dropout': [0.1], #Done\n",
    "\n",
    "    'kernel_initializer': ['identity'], #Done\n",
    "\n",
    "    'activation_layer':['tanh'], #Done\n",
    " \n",
    "    'batc_normalization':[False], #Done\n",
    " \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
